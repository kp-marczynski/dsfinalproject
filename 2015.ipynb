{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Final Project - EE 379k - sp18 - \n",
    "\n",
    "# Shahshank Kambhampati - skk834, Shrikara Murthy - svm456, Pranav Harathi - , Neil Charles - \n",
    "\n",
    "# Job Satisfaction Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "### All hail lord and savior XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, LogisticRegression, Ridge, Lasso, HuberRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomTreesEmbedding, AdaBoostClassifier, AdaBoostRegressor, RandomForestRegressor, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectKBest,  chi2\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from __future__ import print_function\n",
    "%config inlinebackend.figure_format = 'retina' \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Observations about the Data and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number = re.compile('[\\d,]+')\n",
    "def get_first_number(val):\n",
    "    matched = number.match(str(val))\n",
    "    if matched:\n",
    "        return int(matched.group())\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "satisfaction_strs = {\n",
    "    'I love my job': 10,\n",
    "    'I\\'m somewhat satisfied with my job': 7.5,\n",
    "    'I\\'m neither satisfied nor dissatisfied with my job': 5,\n",
    "    'I\\'m somewhat dissatisfied with my job': 2.5,\n",
    "    'I hate my job': 0,\n",
    "}\n",
    "\n",
    "binary_labels = [\n",
    "    'Lang & Tech',\n",
    "    'Training & Education',\n",
    "    'How can companies improve interview process',\n",
    "    'Why try Stack Overflow Careers',\n",
    "    'Most important aspect of new job opportunity',\n",
    "    'Most annoying about job search',\n",
    "    'Appealing message traits',\n",
    "    'Most urgent info about job opportunity',\n",
    "    'Who do you want to communicate with about a new job opportunity',\n",
    "    'Why use Stack Overflow',\n",
    "    'Why answer',\n",
    "    'Source control used',\n",
    "]\n",
    "\n",
    "numeric_labels = [\n",
    "    'Age',\n",
    "    'Years IT / Programming Experience',\n",
    "    'Compensation: midpoint'\n",
    "]\n",
    "\n",
    "yes_no_labels = [\n",
    "    'Changed Jobs in last 12 Months'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\dsfinalproject2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3172: DtypeWarning: Columns (5,108,121,196,197,198) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaNs:\n",
      "Age\n",
      "Years IT / Programming Experience\n",
      "Compensation: midpoint\n",
      "Filling with mean of column\n"
     ]
    }
   ],
   "source": [
    "# 2015 preproc\n",
    "data = pd.read_csv('data/2015.csv')\n",
    "to_drop = [label for label in data if 'write-in' in label.lower()]\n",
    "\n",
    "data['Job Satisfaction'] = data['Job Satisfaction']\\\n",
    "                                    .map(satisfaction_strs).astype('float')\n",
    "data = data[data['Job Satisfaction'].notnull()]\n",
    "to_drop.append('Country')\n",
    "to_drop.append('Compensation')\n",
    "\n",
    "data['Age'] = data['Age'].map(get_first_number).astype('float')\n",
    "data['gender_M'] = (data['Gender'] == 'Male').astype('int8')\n",
    "data['gender_F'] = (data['Gender'] == 'Female').astype('int8')\n",
    "to_drop.append('Gender')\n",
    "to_drop.append('Prefered Source Control')\n",
    "\n",
    "bin_labels = [key for key in data if any(label in key for label in binary_labels)]\n",
    "data[bin_labels] = data[bin_labels].apply(lambda col: col.notnull().astype('int8'))\n",
    "\n",
    "data[numeric_labels] = data[numeric_labels].applymap(get_first_number)\n",
    "data[yes_no_labels] = data[yes_no_labels]\\\n",
    "                                .apply(lambda col: col.map({'Yes': 1, 'No': 0}))\\\n",
    "                                .fillna(0)\n",
    "\n",
    "data.drop(to_drop, axis=1, inplace=True)\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "print(\"Columns with NaNs:\")\n",
    "\n",
    "for key in data:\n",
    "    if data[key].isnull().any():\n",
    "        print (key)\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "print ('Filling with mean of column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data contains a DataFrame with no NaNs, all numbers.\n",
    "# We're trying to predict the \"Job Satisfaction\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = data[['Compensation: midpoint','Purchasing Power_I have no say in purchasing what I need or want at work','Remote Status_Never','Changed Jobs in last 12 Months']]\n",
    "X = data.drop('Job Satisfaction',axis=1)\n",
    "y = data['Job Satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)#stratify=y\n",
    "scoring = {'mean': make_scorer(mean_squared_error)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Years IT / Programming Experience  Current Lang & Tech: Android  \\\n",
      "0  25.0                                2.0                             0   \n",
      "1  20.0                                1.0                             0   \n",
      "2  20.0                                1.0                             0   \n",
      "3  25.0                                6.0                             0   \n",
      "4  30.0                                2.0                             0   \n",
      "\n",
      "   Current Lang & Tech: Arduino  Current Lang & Tech: AngularJS  \\\n",
      "0                             0                               0   \n",
      "1                             0                               0   \n",
      "2                             0                               0   \n",
      "3                             0                               0   \n",
      "4                             0                               0   \n",
      "\n",
      "   Current Lang & Tech: C  Current Lang & Tech: C++  \\\n",
      "0                       0                         0   \n",
      "1                       0                         0   \n",
      "2                       0                         0   \n",
      "3                       0                         0   \n",
      "4                       0                         0   \n",
      "\n",
      "   Current Lang & Tech: C++11  Current Lang & Tech: C#  \\\n",
      "0                           0                        0   \n",
      "1                           0                        1   \n",
      "2                           0                        1   \n",
      "3                           0                        0   \n",
      "4                           0                        1   \n",
      "\n",
      "   Current Lang & Tech: Cassandra  ...  Preferred text editor_XEmacs  \\\n",
      "0                               0  ...                             0   \n",
      "1                               0  ...                             0   \n",
      "2                               0  ...                             1   \n",
      "3                               0  ...                             0   \n",
      "4                               0  ...                             0   \n",
      "\n",
      "   Preferred text editor_atom.io  Prefered IDE theme_Dark  \\\n",
      "0                              0                        1   \n",
      "1                              0                        0   \n",
      "2                              0                        1   \n",
      "3                              0                        1   \n",
      "4                              0                        1   \n",
      "\n",
      "   Prefered IDE theme_I don't use an IDE  Prefered IDE theme_Light  \\\n",
      "0                                      0                         0   \n",
      "1                                      0                         1   \n",
      "2                                      0                         0   \n",
      "3                                      0                         0   \n",
      "4                                      0                         0   \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Always  \\\n",
      "0                                                  0       \n",
      "1                                                  0       \n",
      "2                                                  0       \n",
      "3                                                  0       \n",
      "4                                                  0       \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Never  \\\n",
      "0                                                  0      \n",
      "1                                                  0      \n",
      "2                                                  0      \n",
      "3                                                  0      \n",
      "4                                                  0      \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Rarely  \\\n",
      "0                                                  0       \n",
      "1                                                  0       \n",
      "2                                                  1       \n",
      "3                                                  0       \n",
      "4                                                  0       \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Sometimes  \\\n",
      "0                                                  0          \n",
      "1                                                  0          \n",
      "2                                                  0          \n",
      "3                                                  0          \n",
      "4                                                  0          \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Usually  \n",
      "0                                                  1       \n",
      "1                                                  1       \n",
      "2                                                  0       \n",
      "3                                                  1       \n",
      "4                                                  1       \n",
      "\n",
      "[5 rows x 347 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Age  Years IT / Programming Experience  \\\n",
      "count  16004.000000                       16004.000000   \n",
      "mean      28.478348                           5.839325   \n",
      "std        6.955481                           3.850501   \n",
      "min       20.000000                           1.000000   \n",
      "25%       25.000000                           2.000000   \n",
      "50%       25.000000                           6.000000   \n",
      "75%       30.000000                          11.000000   \n",
      "max       51.000000                          11.000000   \n",
      "\n",
      "       Current Lang & Tech: Android  Current Lang & Tech: Arduino  \\\n",
      "count                  16004.000000                  16004.000000   \n",
      "mean                       0.173269                      0.061110   \n",
      "std                        0.378492                      0.239539   \n",
      "min                        0.000000                      0.000000   \n",
      "25%                        0.000000                      0.000000   \n",
      "50%                        0.000000                      0.000000   \n",
      "75%                        0.000000                      0.000000   \n",
      "max                        1.000000                      1.000000   \n",
      "\n",
      "       Current Lang & Tech: AngularJS  Current Lang & Tech: C  \\\n",
      "count                    16004.000000            16004.000000   \n",
      "mean                         0.147713                0.131280   \n",
      "std                          0.354826                0.337717   \n",
      "min                          0.000000                0.000000   \n",
      "25%                          0.000000                0.000000   \n",
      "50%                          0.000000                0.000000   \n",
      "75%                          0.000000                0.000000   \n",
      "max                          1.000000                1.000000   \n",
      "\n",
      "       Current Lang & Tech: C++  Current Lang & Tech: C++11  \\\n",
      "count              16004.000000                16004.000000   \n",
      "mean                   0.171270                    0.069733   \n",
      "std                    0.376756                    0.254704   \n",
      "min                    0.000000                    0.000000   \n",
      "25%                    0.000000                    0.000000   \n",
      "50%                    0.000000                    0.000000   \n",
      "75%                    0.000000                    0.000000   \n",
      "max                    1.000000                    1.000000   \n",
      "\n",
      "       Current Lang & Tech: C#  Current Lang & Tech: Cassandra  ...  \\\n",
      "count             16004.000000                    16004.000000  ...   \n",
      "mean                  0.334416                        0.010122  ...   \n",
      "std                   0.471801                        0.100103  ...   \n",
      "min                   0.000000                        0.000000  ...   \n",
      "25%                   0.000000                        0.000000  ...   \n",
      "50%                   0.000000                        0.000000  ...   \n",
      "75%                   1.000000                        0.000000  ...   \n",
      "max                   1.000000                        1.000000  ...   \n",
      "\n",
      "       Preferred text editor_XEmacs  Preferred text editor_atom.io  \\\n",
      "count                  16004.000000                   16004.000000   \n",
      "mean                       0.002374                       0.021995   \n",
      "std                        0.048672                       0.146670   \n",
      "min                        0.000000                       0.000000   \n",
      "25%                        0.000000                       0.000000   \n",
      "50%                        0.000000                       0.000000   \n",
      "75%                        0.000000                       0.000000   \n",
      "max                        1.000000                       1.000000   \n",
      "\n",
      "       Prefered IDE theme_Dark  Prefered IDE theme_I don't use an IDE  \\\n",
      "count             16004.000000                           16004.000000   \n",
      "mean                  0.428268                               0.059548   \n",
      "std                   0.494843                               0.236654   \n",
      "min                   0.000000                               0.000000   \n",
      "25%                   0.000000                               0.000000   \n",
      "50%                   0.000000                               0.000000   \n",
      "75%                   1.000000                               0.000000   \n",
      "max                   1.000000                               1.000000   \n",
      "\n",
      "       Prefered IDE theme_Light  \\\n",
      "count              16004.000000   \n",
      "mean                   0.343227   \n",
      "std                    0.474801   \n",
      "min                    0.000000   \n",
      "25%                    0.000000   \n",
      "50%                    0.000000   \n",
      "75%                    1.000000   \n",
      "max                    1.000000   \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Always  \\\n",
      "count                                       16004.000000       \n",
      "mean                                            0.079668       \n",
      "std                                             0.270786       \n",
      "min                                             0.000000       \n",
      "25%                                             0.000000       \n",
      "50%                                             0.000000       \n",
      "75%                                             0.000000       \n",
      "max                                             1.000000       \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Never  \\\n",
      "count                                       16004.000000      \n",
      "mean                                            0.000812      \n",
      "std                                             0.028490      \n",
      "min                                             0.000000      \n",
      "25%                                             0.000000      \n",
      "50%                                             0.000000      \n",
      "75%                                             0.000000      \n",
      "max                                             1.000000      \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Rarely  \\\n",
      "count                                       16004.000000       \n",
      "mean                                            0.003687       \n",
      "std                                             0.060607       \n",
      "min                                             0.000000       \n",
      "25%                                             0.000000       \n",
      "50%                                             0.000000       \n",
      "75%                                             0.000000       \n",
      "max                                             1.000000       \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Sometimes  \\\n",
      "count                                       16004.000000          \n",
      "mean                                            0.108660          \n",
      "std                                             0.311222          \n",
      "min                                             0.000000          \n",
      "25%                                             0.000000          \n",
      "50%                                             0.000000          \n",
      "75%                                             0.000000          \n",
      "max                                             1.000000          \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Usually  \n",
      "count                                       16004.000000       \n",
      "mean                                            0.634404       \n",
      "std                                             0.481612       \n",
      "min                                             0.000000       \n",
      "25%                                             0.000000       \n",
      "50%                                             1.000000       \n",
      "75%                                             1.000000       \n",
      "max                                             1.000000       \n",
      "\n",
      "[8 rows x 347 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open to new job opportunities_I am actively looking for a new job              -0.261420\n",
      "Open to new job opportunities_I am open to new job opportunities               -0.176831\n",
      "Purchasing Power_I have no say in purchasing what I need or want at work       -0.164541\n",
      "Remote Status_Never                                                            -0.137992\n",
      "Perception of recruiter contact_I wish more recruiters contacted me!           -0.135077\n",
      "                                                                                  ...   \n",
      "Remote Status_Full-time Remote                                                  0.074636\n",
      "Compensation: midpoint                                                          0.085901\n",
      "Purchasing Power_I can buy anything I want without asking anyone                0.122394\n",
      "Open to new job opportunities_I am not interested in other job opportunities    0.335079\n",
      "Job Satisfaction                                                                1.000000\n",
      "Name: Job Satisfaction, Length: 347, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "c = data.corr()\n",
    "print(c['Job Satisfaction'].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\dsfinalproject2\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=50, step=2 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "rfe = RFE(model, 50,2)\n",
    "rfe = rfe.fit(X_train,y_train)\n",
    "X_train = rfe.transform(X_train)\n",
    "X_test = rfe.transform(X_test)\n",
    "#rfe_preds = rfe.predict(X_test)\n",
    "#print mean_squared_error(y_test,rfe_preds)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "print rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "{'n_estimators': 160}\n",
      "8.993272252815737\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators':[160]\n",
    "}\n",
    "modelETC = ExtraTreesRegressor()\n",
    "gridETC = GridSearchCV(modelETC, param_grid=parameters,scoring = scoring, cv=5, refit = 'mean',verbose=1)\n",
    "gridETC.fit(X_train,y_train)\n",
    "print(gridETC.best_params_)\n",
    "#print(modelETC.feature_importances_)\n",
    "etc_preds = gridETC.predict(X_test)\n",
    "print (mean_squared_error(y_test,etc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.993272252815737\n"
     ]
    }
   ],
   "source": [
    "print (mean_squared_error(y_test,etc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3809194641466047\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "#gridXGB = GridSearchCV(xgb_model, param_grid=parameters,scoring = scoring, cv=3, verbose=2, refit = 'mean')\n",
    "#gridXGB.fit(X_train, y_train,eval_metric='rmse')\n",
    "#print(gridXGB.best_params_)\n",
    "#xgb_preds = gridXGB.predict(X_test)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "print (mean_squared_error(y_test,xgb_preds)**.5)\n",
    "#xgb_copy = list(xgb_preds)\n",
    "xgb_model.fit(X, y)\n",
    "xgb_model._Booster.save_model('output2015.model')\n",
    "xgb.plot_importance(xgb_model,max_num_features = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input data can not be a list.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_15032/3455133185.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mxgb_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Booster\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mxgb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDMatrix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0.0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0.0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0.0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0.0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeature_names\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34mu'Compensation: midpoint'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mu'Purchasing Power_I have no say in purchasing what I need or want at work'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mu'Remote Status_Never'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mu'Changed Jobs in last 12 Months'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\code\\dsfinalproject2\\venv\\lib\\site-packages\\xgboost\\core.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, enable_categorical)\u001B[0m\n\u001B[0;32m    486\u001B[0m         \"\"\"\n\u001B[0;32m    487\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 488\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Input data can not be a list.'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    489\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    490\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmissing\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmissing\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mmissing\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnan\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Input data can not be a list."
     ]
    }
   ],
   "source": [
    "xgb_model._Booster.predict(xgb.DMatrix([0.0,0.0,0.0,0.0], feature_names=[u'Compensation: midpoint', u'Purchasing Power_I have no say in purchasing what I need or want at work', u'Remote Status_Never', u'Changed Jobs in last 12 Months']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = { #when use hyperthread, xgboost may become slower\n",
    "              'booster':['gbtree'],# dart is nice but far too slow\n",
    "              'learning_rate': [.01], #\n",
    "              'max_depth': [7],#1,3,5,6,7,8,10\n",
    "              'min_child_weight': [8],#1,3,5,7,8,9,10\n",
    "              'reg_alpha':[.01],#.0001,.001,.01,.1,1,10\n",
    "              'silent': [0],\n",
    "              'subsample': [.6],#.6,.7,.8,.9\n",
    "              'gamma':[.001],#.1,.01,.001.,.005,0\n",
    "              'colsample_bytree': [.8],#.6,.7,.8,.9\n",
    "              'n_estimators': [10000], \n",
    "              'seed': [1337]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[15:49:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END booster=gbtree, colsample_bytree=0.8, gamma=0.001, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=10000, reg_alpha=0.01, seed=1337, silent=0, subsample=0.6; total time= 1.6min\n",
      "[15:50:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END booster=gbtree, colsample_bytree=0.8, gamma=0.001, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=10000, reg_alpha=0.01, seed=1337, silent=0, subsample=0.6; total time= 1.7min\n",
      "[15:52:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END booster=gbtree, colsample_bytree=0.8, gamma=0.001, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=10000, reg_alpha=0.01, seed=1337, silent=0, subsample=0.6; total time= 1.6min\n",
      "[15:53:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "2.4934516558110786\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "gridXGB = GridSearchCV(xgb_model, param_grid=parameters,scoring = scoring, cv=3, verbose=2, refit = 'mean')\n",
    "gridXGB.fit(X_train, y_train,eval_metric='rmse')\n",
    "#print(gridXGB.best_params_)\n",
    "xgb_preds = gridXGB.predict(X_test)\n",
    "#xgb_model.fit(X_train, y_train)\n",
    "#xgb_preds = xgb_model.predict(X_test)\n",
    "print (mean_squared_error(y_test,xgb_preds)**.5)\n",
    "#xgb_copy = list(xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gridXGB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-fed3b56b9277>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgridXGB\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_params_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'gridXGB' is not defined"
     ]
    }
   ],
   "source": [
    "print(gridXGB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.322300794571225\n"
     ]
    }
   ],
   "source": [
    "print (mean_squared_error(y_test,xgb_preds)**.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "7.492633136249195\n"
     ]
    }
   ],
   "source": [
    "print (sum(y_test)/len(y_test))\n",
    "print (sum(xgb_preds)/len(xgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.580892773519512\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators':[1],\n",
    "    'learning_rate':[.1]\n",
    "   # 'base_estimator':[ExtraTreesClassifier(160,class_weight='balanced')]\n",
    "   # 'base_estimator':[grid]\n",
    "}\n",
    "modelABC = AdaBoostRegressor(base_estimator=xgb.XGBRegressor(reg_alpha=.01, colsample_bytree=.8, \n",
    "                                silent=0, learning_rate=.01, min_child_weight=8, n_estimators=10000, \n",
    "                                            subsample=.6, max_depth=7,gamma=.001,booster='gbtree'),n_estimators =50)\n",
    "#gridABC = GridSearchCV(modelABC, param_grid=parameters,scoring = scoring, cv=2, refit = 'mean',verbose=2)\n",
    "modelABC.fit(X_train,y_train)\n",
    "abc_preds = modelABC.predict(X_test)\n",
    "print (mean_squared_error(y_test,abc_preds)**.5)\n",
    "#print(gridABC.best_params_)\n",
    "#print(model.feature_importances_)\n",
    "#best score 2.2432 - all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clipS(preds):\n",
    "    for pred, element in enumerate(preds):\n",
    "        if preds[pred] < 1.25:\n",
    "            preds[pred] = 0\n",
    "        elif preds[pred] < 3.75:\n",
    "            preds[pred] = 2.5\n",
    "        elif  preds[pred] < 6.25:\n",
    "            preds[pred] = 5\n",
    "        elif  preds[pred] < 8.75:\n",
    "            preds[pred] = 7.5\n",
    "        else: \n",
    "            preds[pred] = 10\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.286079 7.5 10.0\n",
      "7.927208 7.5 7.5\n",
      "6.8665676 7.5 7.5\n",
      "7.365894 7.5 7.5\n",
      "8.49939 7.5 5.0\n",
      "7.1254463 7.5 5.0\n",
      "6.702565 7.5 7.5\n",
      "5.842753 5 7.5\n",
      "8.738859 7.5 10.0\n",
      "7.841649 7.5 10.0\n",
      "6.74351 7.5 7.5\n",
      "7.807215 7.5 7.5\n",
      "9.261417 10 7.5\n",
      "7.109841 7.5 5.0\n",
      "6.8010564 7.5 7.5\n",
      "7.597346 7.5 10.0\n",
      "6.9410725 7.5 2.5\n",
      "6.5449824 7.5 0.0\n",
      "7.402582 7.5 5.0\n",
      "6.431654 7.5 0.0\n",
      "7.1956844 7.5 7.5\n",
      "7.6999984 7.5 10.0\n",
      "6.1977854 5 2.5\n",
      "7.982983 7.5 10.0\n",
      "7.190724 7.5 7.5\n",
      "6.7932687 7.5 10.0\n",
      "8.369915 7.5 7.5\n",
      "8.421787 7.5 7.5\n",
      "7.026611 7.5 7.5\n",
      "6.857605 7.5 7.5\n",
      "8.973689 10 10.0\n",
      "6.7475266 7.5 2.5\n",
      "8.897934 10 7.5\n",
      "7.8295035 7.5 10.0\n",
      "9.146121 10 10.0\n",
      "8.495934 7.5 7.5\n",
      "6.728901 7.5 7.5\n",
      "7.36117 7.5 10.0\n",
      "8.701159 7.5 10.0\n",
      "7.6483 7.5 10.0\n",
      "7.262645 7.5 7.5\n",
      "7.3512554 7.5 7.5\n",
      "7.0285273 7.5 10.0\n",
      "8.729461 7.5 7.5\n",
      "7.8325706 7.5 7.5\n",
      "8.742565 7.5 10.0\n",
      "6.331672 7.5 0.0\n",
      "8.884819 10 7.5\n",
      "7.004472 7.5 7.5\n",
      "7.0543513 7.5 5.0\n",
      "7.403653 7.5 10.0\n",
      "7.0553303 7.5 7.5\n",
      "7.1007104 7.5 7.5\n",
      "4.405138 5 5.0\n",
      "6.3311124 7.5 5.0\n",
      "7.363051 7.5 5.0\n",
      "6.0551515 5 2.5\n",
      "9.117585 10 10.0\n",
      "9.358985 10 10.0\n",
      "5.541956 5 2.5\n",
      "8.615711 7.5 10.0\n",
      "9.012321 10 7.5\n",
      "6.0414762 5 7.5\n",
      "8.579151 7.5 10.0\n",
      "8.030192 7.5 7.5\n",
      "8.855805 10 10.0\n",
      "8.832175 10 7.5\n",
      "7.6058855 7.5 5.0\n",
      "7.199923 7.5 7.5\n",
      "8.900732 10 10.0\n",
      "8.324468 7.5 10.0\n",
      "8.5223 7.5 7.5\n",
      "9.109856 10 10.0\n",
      "6.486567 7.5 2.5\n",
      "8.735019 7.5 10.0\n",
      "7.5179343 7.5 5.0\n",
      "3.6571748 2.5 2.5\n",
      "6.286259 7.5 7.5\n",
      "6.783825 7.5 2.5\n",
      "6.983751 7.5 7.5\n",
      "8.085805 7.5 2.5\n",
      "6.5495825 7.5 10.0\n",
      "7.5467052 7.5 5.0\n",
      "9.301053 10 10.0\n",
      "6.9998946 7.5 7.5\n",
      "6.4746428 7.5 7.5\n",
      "8.327482 7.5 7.5\n",
      "7.71578 7.5 7.5\n",
      "8.524395 7.5 7.5\n",
      "6.8809905 7.5 7.5\n",
      "7.17428 7.5 7.5\n",
      "6.652444 7.5 7.5\n",
      "9.1943655 10 10.0\n",
      "7.41816 7.5 2.5\n",
      "8.574999 7.5 10.0\n",
      "9.110284 10 10.0\n",
      "7.2170534 7.5 5.0\n",
      "6.7920656 7.5 7.5\n",
      "7.6146593 7.5 2.5\n",
      "7.6355267 7.5 10.0\n",
      "7.725098 7.5 7.5\n",
      "9.835834 10 10.0\n",
      "8.92887 10 7.5\n",
      "7.7761097 7.5 5.0\n",
      "7.411673 7.5 10.0\n",
      "6.9068995 7.5 10.0\n",
      "4.706843 5 5.0\n",
      "6.7363033 7.5 10.0\n",
      "7.4693766 7.5 10.0\n",
      "6.62778 7.5 10.0\n",
      "8.363657 7.5 5.0\n",
      "7.438783 7.5 7.5\n",
      "8.178367 7.5 10.0\n",
      "6.381085 7.5 2.5\n",
      "8.266884 7.5 10.0\n",
      "8.277149 7.5 7.5\n",
      "7.65782 7.5 10.0\n",
      "8.929945 10 10.0\n",
      "9.464274 10 10.0\n",
      "7.760153 7.5 7.5\n",
      "7.0397315 7.5 7.5\n",
      "7.167578 7.5 7.5\n",
      "6.8036776 7.5 5.0\n",
      "7.7189155 7.5 7.5\n",
      "7.5646496 7.5 2.5\n",
      "8.044349 7.5 5.0\n",
      "7.171184 7.5 7.5\n",
      "8.161463 7.5 7.5\n",
      "7.9289637 7.5 10.0\n",
      "7.277117 7.5 10.0\n",
      "6.609256 7.5 2.5\n",
      "5.275037 5 5.0\n",
      "7.0832453 7.5 10.0\n",
      "9.117787 10 7.5\n",
      "7.603249 7.5 7.5\n",
      "6.663688 7.5 7.5\n",
      "4.723162 5 2.5\n",
      "7.6154575 7.5 10.0\n",
      "8.043401 7.5 10.0\n",
      "8.383421 7.5 7.5\n",
      "6.9304047 7.5 5.0\n",
      "8.473858 7.5 10.0\n",
      "7.591846 7.5 7.5\n",
      "7.1693206 7.5 0.0\n",
      "7.0171704 7.5 2.5\n",
      "8.716563 7.5 10.0\n",
      "6.279488 7.5 7.5\n",
      "7.7324343 7.5 7.5\n",
      "7.218708 7.5 5.0\n",
      "7.526625 7.5 7.5\n",
      "5.372349 5 5.0\n",
      "8.66315 7.5 10.0\n",
      "7.438694 7.5 7.5\n",
      "7.6925898 7.5 10.0\n",
      "7.1397734 7.5 7.5\n",
      "7.101089 7.5 7.5\n",
      "8.670513 7.5 10.0\n",
      "7.135246 7.5 10.0\n",
      "7.6819215 7.5 2.5\n",
      "8.511471 7.5 5.0\n",
      "6.893649 7.5 7.5\n",
      "7.893755 7.5 10.0\n",
      "8.673151 7.5 7.5\n",
      "7.3726406 7.5 7.5\n",
      "5.202962 5 0.0\n",
      "7.3817315 7.5 7.5\n",
      "7.201135 7.5 10.0\n",
      "7.397476 7.5 7.5\n",
      "4.704034 5 5.0\n",
      "6.9775224 7.5 7.5\n",
      "8.79597 10 10.0\n",
      "7.282974 7.5 10.0\n",
      "8.459864 7.5 10.0\n",
      "7.0988016 7.5 7.5\n",
      "5.45099 5 7.5\n",
      "6.903828 7.5 2.5\n",
      "7.262401 7.5 7.5\n",
      "5.0595374 5 2.5\n",
      "7.8998914 7.5 7.5\n",
      "8.004835 7.5 7.5\n",
      "5.8966293 5 5.0\n",
      "4.485405 5 2.5\n",
      "5.643121 5 2.5\n",
      "8.961643 10 10.0\n",
      "7.5989194 7.5 10.0\n",
      "6.7831264 7.5 5.0\n",
      "8.754775 10 10.0\n",
      "8.347086 7.5 7.5\n",
      "6.6628594 7.5 2.5\n",
      "7.0336676 7.5 7.5\n",
      "7.366872 7.5 7.5\n",
      "6.7191534 7.5 7.5\n",
      "7.8934665 7.5 10.0\n",
      "9.191255 10 10.0\n",
      "7.557719 7.5 7.5\n",
      "6.9939127 7.5 7.5\n",
      "6.472245 7.5 5.0\n",
      "7.3428783 7.5 2.5\n",
      "6.4768124 7.5 2.5\n",
      "5.3114104 5 7.5\n",
      "7.6250925 7.5 7.5\n",
      "7.5127063 7.5 10.0\n",
      "7.503521 7.5 7.5\n",
      "8.132802 7.5 7.5\n",
      "7.9164486 7.5 7.5\n",
      "7.0198107 7.5 7.5\n",
      "7.0506005 7.5 2.5\n",
      "8.404212 7.5 7.5\n",
      "7.6292434 7.5 7.5\n",
      "6.6520014 7.5 10.0\n",
      "8.912238 10 10.0\n",
      "8.9411745 10 10.0\n",
      "7.1848226 7.5 5.0\n",
      "5.805557 5 5.0\n",
      "7.137453 7.5 7.5\n",
      "7.3466763 7.5 7.5\n",
      "7.4282475 7.5 10.0\n",
      "5.8565474 5 10.0\n",
      "6.839623 7.5 7.5\n",
      "7.060577 7.5 7.5\n",
      "9.138858 10 10.0\n",
      "6.35038 7.5 5.0\n",
      "7.7695136 7.5 10.0\n",
      "6.0542393 5 7.5\n",
      "7.2977853 7.5 10.0\n",
      "6.835838 7.5 5.0\n",
      "7.5787945 7.5 7.5\n",
      "8.911916 10 5.0\n",
      "7.544947 7.5 5.0\n",
      "8.094479 7.5 10.0\n",
      "8.853425 10 10.0\n",
      "8.564133 7.5 7.5\n",
      "7.4951167 7.5 2.5\n",
      "7.7497053 7.5 7.5\n",
      "6.557948 7.5 7.5\n",
      "7.6053023 7.5 10.0\n",
      "8.348433 7.5 7.5\n",
      "6.014029 5 5.0\n",
      "7.017941 7.5 7.5\n",
      "5.64851 5 10.0\n",
      "6.886149 7.5 5.0\n",
      "6.4640403 7.5 7.5\n",
      "5.3906755 5 10.0\n",
      "7.2654233 7.5 10.0\n",
      "9.335668 10 10.0\n",
      "6.481755 7.5 2.5\n",
      "6.017241 5 7.5\n",
      "8.043382 7.5 10.0\n",
      "9.051476 10 10.0\n",
      "6.560203 7.5 7.5\n",
      "8.62571 7.5 5.0\n",
      "8.877778 10 10.0\n",
      "7.7104654 7.5 7.5\n",
      "7.369749 7.5 7.5\n",
      "8.967628 10 10.0\n",
      "5.2159295 5 2.5\n",
      "8.635881 7.5 7.5\n",
      "7.1446714 7.5 2.5\n",
      "7.4312387 7.5 2.5\n",
      "6.711874 7.5 10.0\n",
      "8.671534 7.5 7.5\n",
      "7.5660887 7.5 2.5\n",
      "5.8431525 5 5.0\n",
      "6.714745 7.5 7.5\n",
      "7.6558537 7.5 10.0\n",
      "7.377463 7.5 7.5\n",
      "4.7338557 5 5.0\n",
      "9.316233 10 7.5\n",
      "7.186562 7.5 7.5\n",
      "8.721661 7.5 10.0\n",
      "6.9716315 7.5 10.0\n",
      "7.6170654 7.5 10.0\n",
      "4.8393083 5 7.5\n",
      "7.38621 7.5 10.0\n",
      "7.297359 7.5 7.5\n",
      "6.9779367 7.5 7.5\n",
      "8.299047 7.5 7.5\n",
      "8.64231 7.5 10.0\n",
      "9.119448 10 7.5\n",
      "4.38325 5 2.5\n",
      "9.018082 10 10.0\n",
      "7.2247763 7.5 10.0\n",
      "6.4251723 7.5 7.5\n",
      "7.1317353 7.5 10.0\n",
      "8.600432 7.5 10.0\n",
      "7.3213086 7.5 10.0\n",
      "7.583395 7.5 5.0\n",
      "8.4304905 7.5 10.0\n",
      "7.1937423 7.5 10.0\n",
      "7.2638855 7.5 7.5\n",
      "4.718356 5 2.5\n",
      "8.542231 7.5 7.5\n",
      "8.715064 7.5 10.0\n",
      "7.007884 7.5 7.5\n",
      "7.155012 7.5 10.0\n",
      "6.0820823 5 2.5\n",
      "8.476149 7.5 10.0\n",
      "6.3996363 7.5 2.5\n",
      "6.704749 7.5 5.0\n",
      "7.937782 7.5 7.5\n",
      "6.222191 5 0.0\n",
      "6.969253 7.5 7.5\n",
      "8.322651 7.5 5.0\n",
      "6.794183 7.5 7.5\n",
      "8.821465 10 10.0\n",
      "8.9155245 10 10.0\n",
      "9.655393 10 10.0\n",
      "7.691099 7.5 7.5\n",
      "8.331469 7.5 2.5\n",
      "9.57851 10 10.0\n",
      "7.8688903 7.5 10.0\n",
      "7.268002 7.5 5.0\n",
      "4.363471 5 7.5\n",
      "7.0442104 7.5 7.5\n",
      "7.034379 7.5 7.5\n",
      "8.409029 7.5 5.0\n",
      "7.3680425 7.5 10.0\n",
      "4.837284 5 2.5\n",
      "8.177069 7.5 10.0\n",
      "7.5692315 7.5 10.0\n",
      "6.857407 7.5 5.0\n",
      "8.328121 7.5 7.5\n",
      "7.276381 7.5 5.0\n",
      "7.601217 7.5 10.0\n",
      "7.3337727 7.5 7.5\n",
      "6.951588 7.5 7.5\n",
      "8.452675 7.5 5.0\n",
      "7.929223 7.5 5.0\n",
      "7.182568 7.5 7.5\n",
      "6.8402877 7.5 10.0\n",
      "6.775493 7.5 5.0\n",
      "6.1471343 5 10.0\n",
      "7.3068666 7.5 7.5\n",
      "6.7196417 7.5 7.5\n",
      "8.756385 10 5.0\n",
      "7.2793436 7.5 10.0\n",
      "5.000211 5 10.0\n",
      "6.7214365 7.5 10.0\n",
      "7.6406875 7.5 10.0\n",
      "7.3126354 7.5 7.5\n",
      "9.401726 10 10.0\n",
      "9.104323 10 10.0\n",
      "8.366888 7.5 7.5\n",
      "4.901815 5 5.0\n",
      "8.21958 7.5 10.0\n",
      "7.9752884 7.5 2.5\n",
      "7.4142094 7.5 7.5\n",
      "7.7659926 7.5 10.0\n",
      "8.70406 7.5 10.0\n",
      "7.4904323 7.5 7.5\n",
      "6.7746053 7.5 7.5\n",
      "6.530846 7.5 7.5\n",
      "8.04063 7.5 5.0\n",
      "8.221747 7.5 7.5\n",
      "7.400912 7.5 10.0\n",
      "7.7718835 7.5 7.5\n",
      "7.148913 7.5 2.5\n",
      "8.17844 7.5 10.0\n",
      "9.469219 10 10.0\n",
      "7.73892 7.5 10.0\n",
      "7.133104 7.5 7.5\n",
      "6.705155 7.5 5.0\n",
      "6.997345 7.5 7.5\n",
      "8.586482 7.5 10.0\n",
      "8.821429 10 7.5\n",
      "7.6046114 7.5 5.0\n",
      "7.3128233 7.5 10.0\n",
      "8.714591 7.5 7.5\n",
      "7.660843 7.5 7.5\n",
      "8.609051 7.5 7.5\n",
      "6.9730186 7.5 5.0\n",
      "8.670081 7.5 10.0\n",
      "8.079895 7.5 10.0\n",
      "7.9215693 7.5 7.5\n",
      "5.7190385 5 7.5\n",
      "9.331474 10 10.0\n",
      "6.8284993 7.5 7.5\n",
      "8.0086975 7.5 10.0\n",
      "7.02293 7.5 10.0\n",
      "7.0213385 7.5 7.5\n",
      "6.6029406 7.5 10.0\n",
      "7.4014792 7.5 10.0\n",
      "7.298542 7.5 0.0\n",
      "7.619708 7.5 5.0\n",
      "7.1979895 7.5 10.0\n",
      "7.448646 7.5 7.5\n",
      "8.440142 7.5 7.5\n",
      "6.9769835 7.5 7.5\n",
      "6.138256 5 7.5\n",
      "7.2245126 7.5 5.0\n",
      "6.527871 7.5 7.5\n",
      "6.8050394 7.5 7.5\n",
      "6.3317323 7.5 2.5\n",
      "6.772269 7.5 7.5\n",
      "8.76172 10 7.5\n",
      "7.0657053 7.5 7.5\n",
      "5.377063 5 10.0\n",
      "8.594167 7.5 5.0\n",
      "7.422571 7.5 10.0\n",
      "6.9281945 7.5 7.5\n",
      "5.144563 5 5.0\n",
      "7.5175185 7.5 5.0\n",
      "6.9254336 7.5 10.0\n",
      "7.3157744 7.5 7.5\n",
      "7.2429156 7.5 7.5\n",
      "4.8302307 5 2.5\n",
      "5.554353 5 2.5\n",
      "7.481337 7.5 10.0\n",
      "7.421533 7.5 7.5\n",
      "8.007649 7.5 10.0\n",
      "7.350526 7.5 2.5\n",
      "9.06644 10 10.0\n",
      "7.250871 7.5 10.0\n",
      "7.9431186 7.5 10.0\n",
      "6.920812 7.5 10.0\n",
      "6.753942 7.5 10.0\n",
      "8.611946 7.5 7.5\n",
      "7.4769297 7.5 5.0\n",
      "7.192379 7.5 10.0\n",
      "5.9402156 5 2.5\n",
      "8.96776 10 10.0\n",
      "6.6662545 7.5 2.5\n",
      "7.4262714 7.5 2.5\n",
      "8.85153 10 7.5\n",
      "8.936792 10 7.5\n",
      "7.3628335 7.5 7.5\n",
      "5.7974925 5 7.5\n",
      "7.203161 7.5 0.0\n",
      "6.0014415 5 7.5\n",
      "7.666558 7.5 7.5\n",
      "7.287009 7.5 7.5\n",
      "7.173406 7.5 5.0\n",
      "7.7139025 7.5 10.0\n",
      "6.0934787 5 7.5\n",
      "7.2690234 7.5 5.0\n",
      "8.296945 7.5 10.0\n",
      "7.9280605 7.5 7.5\n",
      "7.032693 7.5 2.5\n",
      "8.463832 7.5 10.0\n",
      "7.1000605 7.5 7.5\n",
      "8.899751 10 10.0\n",
      "7.7113748 7.5 7.5\n",
      "8.2399845 7.5 10.0\n",
      "8.778484 10 10.0\n",
      "7.807631 7.5 10.0\n",
      "7.206174 7.5 2.5\n",
      "8.808467 10 7.5\n",
      "4.1308002 5 2.5\n",
      "7.0482454 7.5 7.5\n",
      "8.931331 10 0.0\n",
      "7.2467513 7.5 7.5\n",
      "7.292097 7.5 7.5\n",
      "6.701726 7.5 7.5\n",
      "9.159873 10 7.5\n",
      "8.311512 7.5 10.0\n",
      "7.8484197 7.5 10.0\n",
      "7.418136 7.5 7.5\n",
      "6.9726777 7.5 10.0\n",
      "7.6918173 7.5 10.0\n",
      "6.9782104 7.5 7.5\n",
      "7.405746 7.5 7.5\n",
      "6.3513823 7.5 7.5\n",
      "7.091888 7.5 7.5\n",
      "9.166574 10 10.0\n",
      "7.951657 7.5 10.0\n",
      "6.0477605 5 2.5\n",
      "9.185785 10 10.0\n",
      "5.3644524 5 7.5\n",
      "7.0279727 7.5 7.5\n",
      "8.721304 7.5 10.0\n",
      "5.368986 5 0.0\n",
      "7.10423 7.5 7.5\n",
      "7.692889 7.5 10.0\n",
      "7.1589327 7.5 2.5\n",
      "9.070053 10 10.0\n",
      "6.972535 7.5 7.5\n",
      "5.3782387 5 5.0\n",
      "7.221765 7.5 7.5\n",
      "7.29352 7.5 7.5\n",
      "7.9121714 7.5 10.0\n",
      "6.5349183 7.5 5.0\n",
      "8.577447 7.5 10.0\n",
      "9.000124 10 10.0\n",
      "9.061013 10 10.0\n",
      "6.8140445 7.5 5.0\n",
      "8.715182 7.5 7.5\n",
      "7.6654744 7.5 7.5\n",
      "9.053612 10 10.0\n",
      "6.8768363 7.5 7.5\n",
      "7.7563195 7.5 7.5\n",
      "5.586463 5 5.0\n",
      "7.1503057 7.5 7.5\n",
      "7.8367867 7.5 7.5\n",
      "8.792763 10 10.0\n",
      "7.0504675 7.5 7.5\n",
      "7.165014 7.5 7.5\n",
      "7.01019 7.5 2.5\n",
      "6.183681 5 7.5\n",
      "7.369988 7.5 10.0\n",
      "8.126756 7.5 7.5\n",
      "6.9977584 7.5 2.5\n",
      "8.87244 10 10.0\n",
      "6.3783193 7.5 7.5\n",
      "8.659013 7.5 10.0\n",
      "6.876874 7.5 5.0\n",
      "9.120095 10 10.0\n",
      "7.640631 7.5 7.5\n",
      "7.764863 7.5 5.0\n",
      "7.984157 7.5 5.0\n",
      "6.3734446 7.5 10.0\n",
      "9.266925 10 10.0\n",
      "7.1606984 7.5 7.5\n",
      "7.230636 7.5 7.5\n",
      "7.7491655 7.5 7.5\n",
      "8.973715 10 7.5\n",
      "6.57913 7.5 7.5\n",
      "6.8133802 7.5 7.5\n",
      "7.585878 7.5 5.0\n",
      "6.0682187 5 2.5\n",
      "7.4714656 7.5 10.0\n",
      "8.99028 10 10.0\n",
      "6.096297 5 7.5\n",
      "7.929471 7.5 10.0\n",
      "6.6532526 7.5 7.5\n",
      "7.255486 7.5 7.5\n",
      "7.121804 7.5 7.5\n",
      "8.741817 7.5 10.0\n",
      "6.4791694 7.5 10.0\n",
      "7.16204 7.5 10.0\n",
      "7.40656 7.5 10.0\n",
      "8.835292 10 10.0\n",
      "6.354284 7.5 2.5\n",
      "7.7022524 7.5 10.0\n",
      "7.180073 7.5 7.5\n",
      "7.618295 7.5 5.0\n",
      "9.011094 10 10.0\n",
      "6.4088025 7.5 7.5\n",
      "6.851756 7.5 10.0\n",
      "6.524576 7.5 5.0\n",
      "6.737183 7.5 10.0\n",
      "7.736432 7.5 10.0\n",
      "8.675886 7.5 10.0\n",
      "7.5902305 7.5 7.5\n",
      "6.956921 7.5 7.5\n",
      "7.0642276 7.5 10.0\n",
      "7.7774615 7.5 10.0\n",
      "8.840522 10 10.0\n",
      "9.018677 10 10.0\n",
      "7.1048713 7.5 10.0\n",
      "7.5425825 7.5 10.0\n",
      "5.916163 5 10.0\n",
      "6.2203655 5 7.5\n",
      "9.624352 10 10.0\n",
      "5.7014008 5 7.5\n",
      "6.383533 7.5 5.0\n",
      "6.731 7.5 2.5\n",
      "8.903315 10 10.0\n",
      "7.2506924 7.5 10.0\n",
      "7.6655774 7.5 7.5\n",
      "7.8781333 7.5 7.5\n",
      "7.3385854 7.5 10.0\n",
      "7.295913 7.5 10.0\n",
      "7.059357 7.5 5.0\n",
      "8.175743 7.5 7.5\n",
      "7.035736 7.5 7.5\n",
      "9.075741 10 10.0\n",
      "8.659208 7.5 7.5\n",
      "7.261086 7.5 5.0\n",
      "9.128366 10 10.0\n",
      "9.201667 10 10.0\n",
      "6.909012 7.5 7.5\n",
      "8.563478 7.5 10.0\n",
      "7.7417493 7.5 7.5\n",
      "6.598126 7.5 10.0\n",
      "6.838928 7.5 7.5\n",
      "4.8229856 5 5.0\n",
      "6.9030147 7.5 7.5\n",
      "4.448558 5 7.5\n",
      "7.3287625 7.5 7.5\n",
      "8.58215 7.5 7.5\n",
      "6.9423847 7.5 7.5\n",
      "7.1722794 7.5 5.0\n",
      "7.8454676 7.5 7.5\n",
      "8.680428 7.5 7.5\n",
      "8.819686 10 7.5\n",
      "7.5887103 7.5 10.0\n",
      "9.291523 10 7.5\n",
      "8.94677 10 10.0\n",
      "7.8365974 7.5 10.0\n",
      "7.1992483 7.5 10.0\n",
      "7.6480193 7.5 10.0\n",
      "6.431595 7.5 7.5\n",
      "6.666589 7.5 2.5\n",
      "7.5594454 7.5 7.5\n",
      "7.0675583 7.5 7.5\n",
      "8.671326 7.5 10.0\n",
      "8.293993 7.5 7.5\n",
      "6.065326 5 10.0\n",
      "8.743233 7.5 10.0\n",
      "8.602865 7.5 10.0\n",
      "7.545047 7.5 5.0\n",
      "6.366297 7.5 2.5\n",
      "6.999705 7.5 7.5\n",
      "7.727626 7.5 7.5\n",
      "7.2649617 7.5 5.0\n",
      "6.262243 7.5 2.5\n",
      "6.624135 7.5 5.0\n",
      "8.509215 7.5 7.5\n",
      "7.9518967 7.5 10.0\n",
      "9.159919 10 10.0\n",
      "6.3651114 7.5 2.5\n",
      "7.2806845 7.5 10.0\n",
      "7.0947695 7.5 5.0\n",
      "4.6172037 5 0.0\n",
      "9.0803995 10 10.0\n",
      "6.4334626 7.5 5.0\n",
      "7.1046987 7.5 10.0\n",
      "8.443733 7.5 10.0\n",
      "8.841903 10 10.0\n",
      "8.612307 7.5 7.5\n",
      "8.098684 7.5 10.0\n",
      "6.9010196 7.5 2.5\n",
      "6.1703377 5 5.0\n",
      "7.5871663 7.5 7.5\n",
      "7.388483 7.5 7.5\n",
      "9.196045 10 10.0\n",
      "7.2582064 7.5 7.5\n",
      "7.027735 7.5 7.5\n",
      "7.087882 7.5 10.0\n",
      "8.592028 7.5 10.0\n",
      "7.827072 7.5 10.0\n",
      "7.3170323 7.5 7.5\n",
      "7.033129 7.5 7.5\n",
      "6.7714667 7.5 7.5\n",
      "6.588135 7.5 2.5\n",
      "6.9748836 7.5 2.5\n",
      "8.837019 10 7.5\n",
      "7.3911443 7.5 7.5\n",
      "7.607795 7.5 10.0\n",
      "9.386492 10 10.0\n",
      "7.8328876 7.5 7.5\n",
      "7.1335373 7.5 7.5\n",
      "6.209868 5 7.5\n",
      "7.228551 7.5 7.5\n",
      "7.3156276 7.5 7.5\n",
      "7.9866543 7.5 10.0\n",
      "7.741124 7.5 7.5\n",
      "7.191593 7.5 7.5\n",
      "9.061615 10 10.0\n",
      "4.8184996 5 2.5\n",
      "7.2674165 7.5 2.5\n",
      "6.645566 7.5 10.0\n",
      "7.947404 7.5 7.5\n",
      "8.051508 7.5 10.0\n",
      "5.444333 5 2.5\n",
      "7.182348 7.5 7.5\n",
      "7.5451245 7.5 7.5\n",
      "8.9796 10 7.5\n",
      "7.307333 7.5 10.0\n",
      "8.824837 10 7.5\n",
      "8.7856865 10 7.5\n",
      "4.7115307 5 7.5\n",
      "7.3474936 7.5 0.0\n",
      "9.230823 10 10.0\n",
      "7.1721816 7.5 0.0\n",
      "9.018509 10 10.0\n",
      "6.925648 7.5 7.5\n",
      "7.803427 7.5 10.0\n",
      "9.032519 10 7.5\n",
      "6.853879 7.5 7.5\n",
      "7.3689675 7.5 10.0\n",
      "6.5305805 7.5 10.0\n",
      "7.9466605 7.5 7.5\n",
      "4.0821304 5 10.0\n",
      "5.524874 5 7.5\n",
      "6.761877 7.5 7.5\n",
      "7.3257155 7.5 10.0\n",
      "7.274838 7.5 7.5\n",
      "9.0077305 10 10.0\n",
      "5.556011 5 2.5\n",
      "7.233306 7.5 7.5\n",
      "7.492793 7.5 7.5\n",
      "9.328015 10 10.0\n",
      "5.844181 5 2.5\n",
      "7.709036 7.5 10.0\n",
      "4.6909084 5 2.5\n",
      "8.109215 7.5 7.5\n",
      "8.120611 7.5 7.5\n",
      "6.494277 7.5 10.0\n",
      "8.475326 7.5 10.0\n",
      "8.678416 7.5 10.0\n",
      "7.4901304 7.5 2.5\n",
      "7.6018887 7.5 7.5\n",
      "7.0528555 7.5 7.5\n",
      "7.511163 7.5 10.0\n",
      "6.9843717 7.5 10.0\n",
      "7.0571322 7.5 10.0\n",
      "7.2764153 7.5 5.0\n",
      "8.238143 7.5 5.0\n",
      "6.9302516 7.5 5.0\n",
      "7.0490346 7.5 10.0\n",
      "7.5759425 7.5 10.0\n",
      "7.4752707 7.5 7.5\n",
      "9.279785 10 7.5\n",
      "7.3576407 7.5 10.0\n",
      "9.222765 10 7.5\n",
      "3.7707024 5 2.5\n",
      "6.655712 7.5 2.5\n",
      "5.809638 5 10.0\n",
      "8.82486 10 7.5\n",
      "5.3256445 5 7.5\n",
      "7.6264615 7.5 10.0\n",
      "7.997728 7.5 10.0\n",
      "6.646442 7.5 7.5\n",
      "7.897709 7.5 10.0\n",
      "7.041987 7.5 7.5\n",
      "7.296846 7.5 10.0\n",
      "6.7226424 7.5 7.5\n",
      "9.206126 10 10.0\n",
      "8.828104 10 10.0\n",
      "6.2329283 5 7.5\n",
      "8.983676 10 10.0\n",
      "5.994786 5 7.5\n",
      "6.218967 5 5.0\n",
      "5.8920155 5 5.0\n",
      "6.0475736 5 10.0\n",
      "7.211736 7.5 5.0\n",
      "8.815203 10 7.5\n",
      "7.504905 7.5 7.5\n",
      "8.741962 7.5 10.0\n",
      "8.915806 10 10.0\n",
      "7.541846 7.5 7.5\n",
      "3.4106596 2.5 5.0\n",
      "8.79356 10 10.0\n",
      "8.566177 7.5 7.5\n",
      "8.124886 7.5 2.5\n",
      "6.979462 7.5 7.5\n",
      "8.853748 10 10.0\n",
      "8.997233 10 7.5\n",
      "7.0251513 7.5 7.5\n",
      "7.8392673 7.5 10.0\n",
      "7.8085976 7.5 7.5\n",
      "8.683331 7.5 10.0\n",
      "8.896036 10 7.5\n",
      "8.994874 10 10.0\n",
      "7.89607 7.5 10.0\n",
      "8.616039 7.5 10.0\n",
      "8.097696 7.5 7.5\n",
      "9.043376 10 7.5\n",
      "6.682789 7.5 5.0\n",
      "8.723237 7.5 10.0\n",
      "6.4684787 7.5 7.5\n",
      "8.265588 7.5 10.0\n",
      "6.0097704 5 2.5\n",
      "9.308809 10 10.0\n",
      "6.5025406 7.5 10.0\n",
      "6.8406534 7.5 10.0\n",
      "6.926695 7.5 7.5\n",
      "7.3717694 7.5 10.0\n",
      "6.738855 7.5 7.5\n",
      "5.3507657 5 7.5\n",
      "7.85317 7.5 7.5\n",
      "7.6980686 7.5 7.5\n",
      "6.312067 7.5 7.5\n",
      "7.1721983 7.5 10.0\n",
      "6.913116 7.5 7.5\n",
      "7.600892 7.5 10.0\n",
      "5.9748197 5 10.0\n",
      "6.718238 7.5 7.5\n",
      "9.62091 10 10.0\n",
      "7.014466 7.5 7.5\n",
      "6.4093614 7.5 5.0\n",
      "8.128167 7.5 10.0\n",
      "5.95065 5 5.0\n",
      "8.686604 7.5 7.5\n",
      "7.8931046 7.5 7.5\n",
      "7.4930286 7.5 10.0\n",
      "6.5529804 7.5 0.0\n",
      "7.9078407 7.5 5.0\n",
      "8.575612 7.5 7.5\n",
      "9.971751 10 7.5\n",
      "6.828097 7.5 10.0\n",
      "6.32053 7.5 2.5\n",
      "6.0071945 5 5.0\n",
      "9.117696 10 7.5\n",
      "6.7290273 7.5 7.5\n",
      "7.487945 7.5 10.0\n",
      "7.153184 7.5 2.5\n",
      "7.1766214 7.5 7.5\n",
      "8.006289 7.5 10.0\n",
      "8.8548975 10 10.0\n",
      "5.1826515 5 10.0\n",
      "5.557401 5 2.5\n",
      "7.505442 7.5 7.5\n",
      "8.943387 10 7.5\n",
      "7.8343396 7.5 10.0\n",
      "7.5074115 7.5 7.5\n",
      "9.099901 10 7.5\n",
      "5.911309 5 10.0\n",
      "7.029959 7.5 5.0\n",
      "9.008444 10 7.5\n",
      "7.210225 7.5 10.0\n",
      "6.657603 7.5 7.5\n",
      "8.045045 7.5 7.5\n",
      "5.7507095 5 2.5\n",
      "5.902056 5 2.5\n",
      "8.480425 7.5 7.5\n",
      "4.6460853 5 7.5\n",
      "6.4929423 7.5 7.5\n",
      "7.3816013 7.5 7.5\n",
      "8.495994 7.5 10.0\n",
      "8.137367 7.5 2.5\n",
      "7.6977563 7.5 7.5\n",
      "8.839391 10 7.5\n",
      "8.6795225 7.5 10.0\n",
      "8.643074 7.5 10.0\n",
      "7.879315 7.5 7.5\n",
      "7.0873356 7.5 5.0\n",
      "9.043024 10 10.0\n",
      "7.307547 7.5 10.0\n",
      "8.444422 7.5 7.5\n",
      "7.4380927 7.5 10.0\n",
      "8.870378 10 10.0\n",
      "5.7060328 5 2.5\n",
      "6.9695334 7.5 5.0\n",
      "8.153898 7.5 10.0\n",
      "8.310602 7.5 10.0\n",
      "8.003927 7.5 7.5\n",
      "8.020667 7.5 10.0\n",
      "8.752924 10 7.5\n",
      "7.638061 7.5 7.5\n",
      "9.11074 10 10.0\n",
      "7.2740993 7.5 5.0\n",
      "7.56591 7.5 5.0\n",
      "7.749696 7.5 10.0\n",
      "7.434558 7.5 7.5\n",
      "6.910165 7.5 7.5\n",
      "8.751173 10 7.5\n",
      "7.666991 7.5 10.0\n",
      "8.362771 7.5 7.5\n",
      "6.4933314 7.5 7.5\n",
      "8.187576 7.5 7.5\n",
      "8.396187 7.5 10.0\n",
      "6.6282578 7.5 7.5\n",
      "5.4653378 5 7.5\n",
      "6.1717305 5 7.5\n",
      "7.2601748 7.5 7.5\n",
      "8.385347 7.5 7.5\n",
      "8.917405 10 10.0\n",
      "8.489651 7.5 10.0\n",
      "8.503833 7.5 10.0\n",
      "7.7287445 7.5 7.5\n",
      "6.6385245 7.5 7.5\n",
      "6.423091 7.5 10.0\n",
      "7.3621283 7.5 7.5\n",
      "6.18691 5 7.5\n",
      "8.913301 10 10.0\n",
      "7.048974 7.5 7.5\n",
      "8.951509 10 10.0\n",
      "7.1843157 7.5 7.5\n",
      "7.048867 7.5 10.0\n",
      "8.535232 7.5 10.0\n",
      "7.9645624 7.5 7.5\n",
      "7.198618 7.5 7.5\n",
      "6.9649787 7.5 7.5\n",
      "8.590393 7.5 7.5\n",
      "8.645126 7.5 10.0\n",
      "7.3044996 7.5 7.5\n",
      "8.393788 7.5 10.0\n",
      "7.1001616 7.5 7.5\n",
      "7.4772654 7.5 10.0\n",
      "6.089533 5 2.5\n",
      "5.695056 5 0.0\n",
      "7.2276936 7.5 2.5\n",
      "7.6275587 7.5 2.5\n",
      "6.3332486 7.5 5.0\n",
      "7.011819 7.5 10.0\n",
      "6.514311 7.5 5.0\n",
      "6.4802876 7.5 5.0\n",
      "6.3746715 7.5 7.5\n",
      "6.4421344 7.5 7.5\n",
      "7.1798344 7.5 7.5\n",
      "6.9129825 7.5 7.5\n",
      "6.991682 7.5 10.0\n",
      "7.338098 7.5 5.0\n",
      "7.1576395 7.5 7.5\n",
      "8.81388 10 7.5\n",
      "8.478157 7.5 7.5\n",
      "4.0456686 5 7.5\n",
      "8.933377 10 10.0\n",
      "7.0464997 7.5 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2498374 7.5 10.0\n",
      "7.0629873 7.5 10.0\n",
      "6.8996253 7.5 7.5\n",
      "6.8121514 7.5 10.0\n",
      "7.2658896 7.5 2.5\n",
      "8.852533 10 10.0\n",
      "7.584811 7.5 5.0\n",
      "8.762749 10 10.0\n",
      "6.7032113 7.5 7.5\n",
      "7.040448 7.5 7.5\n",
      "8.731287 7.5 10.0\n",
      "8.339863 7.5 10.0\n",
      "9.299665 10 10.0\n",
      "7.84971 7.5 7.5\n",
      "5.7796865 5 7.5\n",
      "5.215879 5 2.5\n",
      "6.0454664 5 5.0\n",
      "7.069505 7.5 7.5\n",
      "7.026026 7.5 10.0\n",
      "8.7816305 10 7.5\n",
      "7.6395483 7.5 10.0\n",
      "8.811912 10 7.5\n",
      "7.073048 7.5 7.5\n",
      "6.7585797 7.5 7.5\n",
      "5.5238676 5 7.5\n",
      "7.074044 7.5 7.5\n",
      "8.605527 7.5 10.0\n",
      "4.81072 5 2.5\n",
      "6.474626 7.5 10.0\n",
      "7.489467 7.5 10.0\n",
      "6.297437 7.5 7.5\n",
      "9.015276 10 10.0\n",
      "7.1141887 7.5 2.5\n",
      "8.855669 10 7.5\n",
      "7.5748086 7.5 7.5\n",
      "7.4217353 7.5 10.0\n",
      "7.6471562 7.5 7.5\n",
      "6.816087 7.5 5.0\n",
      "8.472724 7.5 10.0\n",
      "6.552516 7.5 7.5\n",
      "7.1472735 7.5 2.5\n",
      "5.7331457 5 7.5\n",
      "6.8766747 7.5 2.5\n",
      "5.6829224 5 2.5\n",
      "9.096558 10 10.0\n",
      "7.444388 7.5 7.5\n",
      "8.846415 10 7.5\n",
      "7.449927 7.5 7.5\n",
      "7.189878 7.5 7.5\n",
      "6.0751224 5 10.0\n",
      "7.364566 7.5 10.0\n",
      "5.6063213 5 10.0\n",
      "7.286406 7.5 7.5\n",
      "7.6666327 7.5 7.5\n",
      "6.3354225 7.5 10.0\n",
      "5.25561 5 10.0\n",
      "9.825521 10 10.0\n",
      "6.786795 7.5 10.0\n",
      "7.211224 7.5 7.5\n",
      "5.1729994 5 0.0\n",
      "8.658024 7.5 7.5\n",
      "7.481276 7.5 7.5\n",
      "8.141222 7.5 10.0\n",
      "7.8352633 7.5 2.5\n",
      "7.047787 7.5 7.5\n",
      "6.354513 7.5 5.0\n",
      "7.257781 7.5 7.5\n",
      "7.370767 7.5 10.0\n",
      "9.072065 10 7.5\n",
      "9.001488 10 10.0\n",
      "7.203402 7.5 7.5\n",
      "7.442974 7.5 2.5\n",
      "7.4649825 7.5 7.5\n",
      "7.3099937 7.5 7.5\n",
      "6.758963 7.5 7.5\n",
      "7.267594 7.5 2.5\n",
      "6.822842 7.5 7.5\n",
      "7.388667 7.5 10.0\n",
      "6.7713485 7.5 7.5\n",
      "9.20234 10 7.5\n",
      "6.988487 7.5 7.5\n",
      "7.457518 7.5 7.5\n",
      "7.1103916 7.5 10.0\n",
      "9.00083 10 10.0\n",
      "6.9202895 7.5 7.5\n",
      "9.033867 10 10.0\n",
      "7.7080817 7.5 10.0\n",
      "7.770261 7.5 10.0\n",
      "6.412739 7.5 10.0\n",
      "5.156807 5 2.5\n",
      "7.8048015 7.5 7.5\n",
      "7.976662 7.5 10.0\n",
      "5.4503665 5 0.0\n",
      "7.6033726 7.5 10.0\n",
      "6.092348 5 7.5\n",
      "7.874834 7.5 2.5\n",
      "6.79322 7.5 5.0\n",
      "7.040174 7.5 7.5\n",
      "6.7235327 7.5 5.0\n",
      "5.583452 5 7.5\n",
      "7.2103567 7.5 10.0\n",
      "6.54365 7.5 7.5\n",
      "5.1156597 5 7.5\n",
      "8.544493 7.5 10.0\n",
      "5.7954426 5 7.5\n",
      "7.408787 7.5 7.5\n",
      "7.061892 7.5 5.0\n",
      "7.4255366 7.5 10.0\n",
      "7.224121 7.5 10.0\n",
      "7.383934 7.5 10.0\n",
      "7.893984 7.5 10.0\n",
      "8.617469 7.5 10.0\n",
      "7.1683226 7.5 7.5\n",
      "6.9922867 7.5 7.5\n",
      "8.941133 10 10.0\n",
      "8.846904 10 7.5\n",
      "8.689668 7.5 7.5\n",
      "9.024565 10 7.5\n",
      "7.057293 7.5 7.5\n",
      "6.706053 7.5 2.5\n",
      "7.8386283 7.5 7.5\n",
      "6.367111 7.5 7.5\n",
      "9.645114 10 10.0\n",
      "5.350004 5 7.5\n",
      "5.563779 5 7.5\n",
      "7.238351 7.5 7.5\n",
      "8.127445 7.5 7.5\n",
      "7.08908 7.5 10.0\n",
      "9.023237 10 10.0\n",
      "9.000626 10 7.5\n",
      "6.821427 7.5 7.5\n",
      "7.675 7.5 7.5\n",
      "7.2775536 7.5 10.0\n",
      "9.138244 10 10.0\n",
      "7.510306 7.5 10.0\n",
      "9.392152 10 10.0\n",
      "8.145443 7.5 10.0\n",
      "7.6661754 7.5 7.5\n",
      "8.918307 10 7.5\n",
      "6.54089 7.5 7.5\n",
      "6.3692465 7.5 10.0\n",
      "8.753905 10 10.0\n",
      "8.292461 7.5 10.0\n",
      "6.9488854 7.5 7.5\n",
      "4.5113273 5 5.0\n",
      "7.3257065 7.5 7.5\n",
      "8.623052 7.5 5.0\n",
      "3.4767556 2.5 2.5\n",
      "7.4732413 7.5 2.5\n",
      "7.4558063 7.5 7.5\n",
      "6.8179145 7.5 7.5\n",
      "8.182265 7.5 7.5\n",
      "6.3605795 7.5 7.5\n",
      "8.82775 10 2.5\n",
      "6.4925985 7.5 2.5\n",
      "9.774725 10 10.0\n",
      "9.050994 10 10.0\n",
      "7.5621967 7.5 7.5\n",
      "7.7375073 7.5 10.0\n",
      "9.538564 10 10.0\n",
      "6.7260523 7.5 7.5\n",
      "6.9928975 7.5 7.5\n",
      "4.2454185 5 2.5\n",
      "8.913458 10 10.0\n",
      "5.435524 5 2.5\n",
      "7.069144 7.5 2.5\n",
      "5.191503 5 0.0\n",
      "7.4445653 7.5 7.5\n",
      "9.248551 10 10.0\n",
      "7.5086207 7.5 7.5\n",
      "8.966882 10 10.0\n",
      "7.027886 7.5 7.5\n",
      "7.498787 7.5 7.5\n",
      "6.449946 7.5 10.0\n",
      "7.8176117 7.5 10.0\n",
      "6.509526 7.5 7.5\n",
      "6.122298 5 5.0\n",
      "7.063854 7.5 10.0\n",
      "8.963464 10 10.0\n",
      "8.021267 7.5 10.0\n",
      "7.0349474 7.5 10.0\n",
      "7.732552 7.5 10.0\n",
      "7.586988 7.5 5.0\n",
      "6.085227 5 10.0\n",
      "6.929994 7.5 7.5\n",
      "7.0557137 7.5 10.0\n",
      "8.813485 10 2.5\n",
      "7.7594194 7.5 10.0\n",
      "7.205122 7.5 10.0\n",
      "9.455564 10 10.0\n",
      "7.2847705 7.5 5.0\n",
      "6.8737597 7.5 5.0\n",
      "8.735121 7.5 10.0\n",
      "5.746553 5 2.5\n",
      "7.3846097 7.5 10.0\n",
      "5.4099116 5 7.5\n",
      "9.203973 10 10.0\n",
      "6.50757 7.5 2.5\n",
      "5.785525 5 2.5\n",
      "7.429924 7.5 5.0\n",
      "8.514276 7.5 10.0\n",
      "8.714898 7.5 10.0\n",
      "7.1421967 7.5 2.5\n",
      "8.464184 7.5 10.0\n",
      "7.187747 7.5 2.5\n",
      "8.536988 7.5 10.0\n",
      "7.54845 7.5 5.0\n",
      "8.697537 7.5 10.0\n",
      "8.607667 7.5 7.5\n",
      "7.186866 7.5 10.0\n",
      "6.663266 7.5 2.5\n",
      "6.4507785 7.5 7.5\n",
      "8.296478 7.5 7.5\n",
      "7.314121 7.5 7.5\n",
      "6.8918114 7.5 7.5\n",
      "7.044851 7.5 5.0\n",
      "7.7899666 7.5 10.0\n",
      "7.09461 7.5 7.5\n",
      "4.6186843 5 2.5\n",
      "6.355214 7.5 10.0\n",
      "9.169338 10 10.0\n",
      "8.2008 7.5 7.5\n",
      "8.376865 7.5 7.5\n",
      "6.5528026 7.5 7.5\n",
      "5.987219 5 7.5\n",
      "4.9347157 5 7.5\n",
      "7.146894 7.5 7.5\n",
      "6.811525 7.5 2.5\n",
      "7.5428085 7.5 5.0\n",
      "7.453137 7.5 7.5\n",
      "7.887602 7.5 5.0\n",
      "7.151456 7.5 7.5\n",
      "7.3123374 7.5 5.0\n",
      "8.540018 7.5 7.5\n",
      "7.2549872 7.5 7.5\n",
      "6.4958644 7.5 2.5\n",
      "6.7641068 7.5 7.5\n",
      "4.5989475 5 0.0\n",
      "7.576034 7.5 10.0\n",
      "7.593365 7.5 7.5\n",
      "8.065838 7.5 7.5\n",
      "7.4106355 7.5 10.0\n",
      "6.8438683 7.5 7.5\n",
      "7.225608 7.5 10.0\n",
      "7.512239 7.5 10.0\n",
      "7.0448594 7.5 7.5\n",
      "5.268523 5 7.5\n",
      "7.466051 7.5 7.5\n",
      "8.637916 7.5 10.0\n",
      "7.1564126 7.5 7.5\n",
      "8.812299 10 5.0\n",
      "8.743115 7.5 7.5\n",
      "9.019884 10 10.0\n",
      "7.5913563 7.5 5.0\n",
      "7.7267227 7.5 10.0\n",
      "6.4716396 7.5 7.5\n",
      "6.9944367 7.5 2.5\n",
      "7.1243243 7.5 7.5\n",
      "8.703987 7.5 7.5\n",
      "8.217157 7.5 7.5\n",
      "7.5046453 7.5 7.5\n",
      "8.315876 7.5 5.0\n",
      "5.6956534 5 10.0\n",
      "8.69694 7.5 10.0\n",
      "7.385411 7.5 10.0\n",
      "8.1806555 7.5 10.0\n",
      "8.9774475 10 10.0\n",
      "6.8783274 7.5 7.5\n",
      "9.785297 10 7.5\n",
      "6.1938806 5 7.5\n",
      "6.6089344 7.5 7.5\n",
      "8.643121 7.5 10.0\n",
      "8.680582 7.5 5.0\n",
      "8.755383 10 10.0\n",
      "6.9071403 7.5 7.5\n",
      "5.2429338 5 7.5\n",
      "8.281757 7.5 10.0\n",
      "7.5964136 7.5 2.5\n",
      "7.2373586 7.5 7.5\n",
      "6.486621 7.5 7.5\n",
      "6.771817 7.5 7.5\n",
      "8.620655 7.5 7.5\n",
      "9.175645 10 5.0\n",
      "7.187366 7.5 7.5\n",
      "7.4759254 7.5 7.5\n",
      "8.1177845 7.5 10.0\n",
      "8.611422 7.5 10.0\n",
      "8.822244 10 10.0\n",
      "7.4913416 7.5 5.0\n",
      "7.407981 7.5 7.5\n",
      "7.6483407 7.5 10.0\n",
      "7.541469 7.5 10.0\n",
      "7.109718 7.5 5.0\n",
      "7.486066 7.5 10.0\n",
      "7.994737 7.5 7.5\n",
      "7.68822 7.5 10.0\n",
      "5.6646867 5 7.5\n",
      "8.6029825 7.5 10.0\n",
      "9.483179 10 10.0\n",
      "7.295296 7.5 10.0\n",
      "9.029859 10 7.5\n",
      "5.8091884 5 0.0\n",
      "5.740032 5 7.5\n",
      "5.498538 5 5.0\n",
      "6.9687257 7.5 2.5\n",
      "9.286668 10 10.0\n",
      "7.478028 7.5 7.5\n",
      "7.220284 7.5 5.0\n",
      "6.716022 7.5 5.0\n",
      "6.6826515 7.5 5.0\n",
      "8.822994 10 10.0\n",
      "8.114517 7.5 10.0\n",
      "7.451096 7.5 10.0\n",
      "7.302082 7.5 5.0\n",
      "8.558032 7.5 7.5\n",
      "8.00451 7.5 7.5\n",
      "7.9069095 7.5 10.0\n",
      "8.974684 10 7.5\n",
      "7.373004 7.5 7.5\n",
      "7.1409616 7.5 10.0\n",
      "7.3959208 7.5 7.5\n",
      "5.6613936 5 7.5\n",
      "7.6332 7.5 7.5\n",
      "7.86587 7.5 2.5\n",
      "8.94788 10 10.0\n",
      "7.5456867 7.5 7.5\n",
      "7.745742 7.5 7.5\n",
      "8.815609 10 7.5\n",
      "7.620989 7.5 7.5\n",
      "9.196998 10 10.0\n",
      "7.2991962 7.5 5.0\n",
      "7.886896 7.5 7.5\n",
      "8.167473 7.5 2.5\n",
      "7.793927 7.5 7.5\n",
      "6.8595023 7.5 7.5\n",
      "7.9327607 7.5 5.0\n",
      "9.08575 10 10.0\n",
      "7.7906137 7.5 10.0\n",
      "8.805328 10 7.5\n",
      "7.477594 7.5 10.0\n",
      "7.3080354 7.5 10.0\n",
      "7.0417 7.5 10.0\n",
      "7.1795034 7.5 2.5\n",
      "8.952321 10 10.0\n",
      "6.2882357 7.5 7.5\n",
      "8.555668 7.5 5.0\n",
      "8.493538 7.5 7.5\n",
      "8.73978 7.5 10.0\n",
      "8.429314 7.5 10.0\n",
      "7.1374307 7.5 7.5\n",
      "8.879378 10 7.5\n",
      "7.659003 7.5 10.0\n",
      "6.3142133 7.5 2.5\n",
      "7.169751 7.5 10.0\n",
      "8.2054615 7.5 10.0\n",
      "6.8600082 7.5 10.0\n",
      "8.788044 10 10.0\n",
      "6.810656 7.5 5.0\n",
      "8.93925 10 7.5\n",
      "6.626221 7.5 7.5\n",
      "7.790435 7.5 10.0\n",
      "8.750533 10 10.0\n",
      "7.784374 7.5 10.0\n",
      "7.319374 7.5 5.0\n",
      "6.8688507 7.5 7.5\n",
      "9.553318 10 10.0\n",
      "7.1464562 7.5 7.5\n",
      "8.914801 10 10.0\n",
      "4.4226484 5 7.5\n",
      "8.526663 7.5 2.5\n",
      "9.217181 10 7.5\n",
      "8.803108 10 10.0\n",
      "7.061543 7.5 7.5\n",
      "8.6854105 7.5 10.0\n",
      "8.708967 7.5 7.5\n",
      "7.427226 7.5 10.0\n",
      "8.480953 7.5 7.5\n",
      "6.412194 7.5 7.5\n",
      "8.024704 7.5 10.0\n",
      "4.946924 5 2.5\n",
      "7.828813 7.5 10.0\n",
      "8.925004 10 10.0\n",
      "5.6424537 5 5.0\n",
      "7.219738 7.5 7.5\n",
      "7.7464285 7.5 7.5\n",
      "4.7814307 5 5.0\n",
      "6.554984 7.5 7.5\n",
      "8.494024 7.5 10.0\n",
      "6.5330257 7.5 2.5\n",
      "8.953579 10 7.5\n",
      "6.7262745 7.5 5.0\n",
      "5.8080707 5 5.0\n",
      "8.200482 7.5 10.0\n",
      "6.5908813 7.5 2.5\n",
      "7.3661475 7.5 7.5\n",
      "7.3360615 7.5 7.5\n",
      "9.13434 10 10.0\n",
      "6.7171574 7.5 7.5\n",
      "8.603332 7.5 7.5\n",
      "7.074343 7.5 5.0\n",
      "6.7384787 7.5 10.0\n",
      "5.199965 5 0.0\n",
      "9.223745 10 10.0\n",
      "7.737554 7.5 5.0\n",
      "5.234888 5 7.5\n",
      "6.2234335 5 7.5\n",
      "8.678134 7.5 7.5\n",
      "6.2208266 5 7.5\n",
      "6.7712274 7.5 10.0\n",
      "5.740088 5 2.5\n",
      "7.2667933 7.5 7.5\n",
      "7.6964865 7.5 5.0\n",
      "8.2085495 7.5 10.0\n",
      "6.1386037 5 2.5\n",
      "8.527719 7.5 10.0\n",
      "6.4446654 7.5 7.5\n",
      "7.1821866 7.5 7.5\n",
      "5.479504 5 2.5\n",
      "5.3922663 5 7.5\n",
      "8.669475 7.5 10.0\n",
      "9.067867 10 10.0\n",
      "7.5673323 7.5 2.5\n",
      "6.632557 7.5 10.0\n",
      "7.230455 7.5 5.0\n",
      "7.8837194 7.5 5.0\n",
      "8.845236 10 2.5\n",
      "6.2565565 7.5 5.0\n",
      "8.344422 7.5 7.5\n",
      "6.801099 7.5 5.0\n",
      "5.749136 5 2.5\n",
      "8.002837 7.5 10.0\n",
      "7.6359105 7.5 7.5\n",
      "6.5352516 7.5 10.0\n",
      "5.3504424 5 2.5\n",
      "7.0716796 7.5 7.5\n",
      "7.93775 7.5 10.0\n",
      "7.541265 7.5 7.5\n",
      "8.935629 10 7.5\n",
      "7.793917 7.5 10.0\n",
      "6.9183064 7.5 2.5\n",
      "7.366221 7.5 2.5\n",
      "6.8426757 7.5 7.5\n",
      "7.8274326 7.5 10.0\n",
      "5.049364 5 2.5\n",
      "7.0201197 7.5 10.0\n",
      "8.233742 7.5 7.5\n",
      "8.915218 10 10.0\n",
      "7.3247695 7.5 2.5\n",
      "9.456071 10 7.5\n",
      "6.8846717 7.5 7.5\n",
      "8.792272 10 10.0\n",
      "7.1873093 7.5 5.0\n",
      "7.7473865 7.5 7.5\n",
      "8.013124 7.5 10.0\n",
      "7.1964283 7.5 7.5\n",
      "9.183392 10 10.0\n",
      "8.739866 7.5 7.5\n",
      "7.2692833 7.5 7.5\n",
      "9.072422 10 10.0\n",
      "4.4244757 5 0.0\n",
      "7.137235 7.5 7.5\n",
      "7.0545163 7.5 7.5\n",
      "6.024472 5 5.0\n",
      "8.640497 7.5 7.5\n",
      "7.149264 7.5 10.0\n",
      "7.0813375 7.5 10.0\n",
      "7.5472527 7.5 10.0\n",
      "6.8816147 7.5 10.0\n",
      "7.1109734 7.5 7.5\n",
      "7.7418427 7.5 7.5\n",
      "7.4933615 7.5 7.5\n",
      "6.8401346 7.5 7.5\n",
      "8.641765 7.5 10.0\n",
      "8.495836 7.5 10.0\n",
      "6.913295 7.5 7.5\n",
      "9.247961 10 7.5\n",
      "7.3477445 7.5 7.5\n",
      "8.371833 7.5 7.5\n",
      "7.105676 7.5 10.0\n",
      "8.610822 7.5 7.5\n",
      "9.176532 10 10.0\n",
      "6.139636 5 7.5\n",
      "7.5413303 7.5 10.0\n",
      "8.279529 7.5 10.0\n",
      "8.737379 7.5 10.0\n",
      "7.029888 7.5 7.5\n",
      "9.3458395 10 7.5\n",
      "6.0182886 5 7.5\n",
      "6.634849 7.5 7.5\n",
      "8.545707 7.5 10.0\n",
      "7.5122757 7.5 7.5\n",
      "7.973449 7.5 0.0\n",
      "9.290523 10 7.5\n",
      "6.656411 7.5 7.5\n",
      "6.5741644 7.5 7.5\n",
      "7.302179 7.5 7.5\n",
      "6.8291636 7.5 7.5\n",
      "7.8633523 7.5 10.0\n",
      "6.7097077 7.5 5.0\n",
      "8.009538 7.5 5.0\n",
      "4.436139 5 7.5\n",
      "7.2893195 7.5 2.5\n",
      "7.7883353 7.5 7.5\n",
      "7.339655 7.5 10.0\n",
      "7.6217484 7.5 10.0\n",
      "7.738951 7.5 10.0\n",
      "6.5560365 7.5 10.0\n",
      "8.728482 7.5 7.5\n",
      "5.1010313 5 5.0\n",
      "4.3613224 5 0.0\n",
      "9.5216055 10 10.0\n",
      "9.29446 10 7.5\n",
      "8.210159 7.5 10.0\n",
      "8.984551 10 7.5\n",
      "6.139171 5 7.5\n",
      "8.1457615 7.5 7.5\n",
      "8.890227 10 10.0\n",
      "7.43087 7.5 7.5\n",
      "7.1270623 7.5 7.5\n",
      "6.802337 7.5 5.0\n",
      "7.8323064 7.5 7.5\n",
      "8.99246 10 10.0\n",
      "7.029524 7.5 7.5\n",
      "6.5357003 7.5 7.5\n",
      "7.1400647 7.5 7.5\n",
      "6.397643 7.5 7.5\n",
      "8.446936 7.5 7.5\n",
      "9.142687 10 7.5\n",
      "7.1688886 7.5 10.0\n",
      "6.255579 7.5 2.5\n",
      "6.0960407 5 10.0\n",
      "7.8559084 7.5 10.0\n",
      "5.342618 5 5.0\n",
      "8.438427 7.5 7.5\n",
      "7.3734694 7.5 10.0\n",
      "6.405296 7.5 7.5\n",
      "8.155603 7.5 10.0\n",
      "8.190871 7.5 7.5\n",
      "9.0663805 10 10.0\n",
      "7.9243712 7.5 10.0\n",
      "7.620014 7.5 7.5\n",
      "7.4874115 7.5 10.0\n",
      "8.342056 7.5 7.5\n",
      "8.776154 10 10.0\n",
      "7.26893 7.5 10.0\n",
      "9.145419 10 10.0\n",
      "8.861709 10 10.0\n",
      "7.105817 7.5 10.0\n",
      "8.636096 7.5 10.0\n",
      "6.829931 7.5 5.0\n",
      "7.282233 7.5 2.5\n",
      "8.826428 10 7.5\n",
      "8.053238 7.5 10.0\n",
      "8.7493515 7.5 10.0\n",
      "8.689772 7.5 7.5\n",
      "8.869054 10 10.0\n",
      "6.188213 5 7.5\n",
      "8.557263 7.5 10.0\n",
      "7.8925877 7.5 10.0\n",
      "8.160575 7.5 10.0\n",
      "7.78371 7.5 7.5\n",
      "7.9097896 7.5 7.5\n",
      "6.996173 7.5 7.5\n",
      "8.052032 7.5 10.0\n",
      "7.4665585 7.5 10.0\n",
      "7.224904 7.5 10.0\n",
      "6.9748864 7.5 5.0\n",
      "7.4137926 7.5 2.5\n",
      "7.2851715 7.5 7.5\n",
      "7.31 7.5 7.5\n",
      "8.6545515 7.5 10.0\n",
      "8.431164 7.5 7.5\n",
      "7.219908 7.5 10.0\n",
      "6.9951906 7.5 7.5\n",
      "9.066986 10 10.0\n",
      "7.1111197 7.5 7.5\n",
      "7.3360605 7.5 10.0\n",
      "7.63771 7.5 0.0\n",
      "7.012859 7.5 7.5\n",
      "8.961229 10 10.0\n",
      "7.000494 7.5 7.5\n",
      "6.6613817 7.5 2.5\n",
      "9.101882 10 7.5\n",
      "9.059652 10 10.0\n",
      "8.604819 7.5 10.0\n",
      "8.625079 7.5 10.0\n",
      "7.5306935 7.5 7.5\n",
      "7.304101 7.5 10.0\n",
      "6.1289907 5 7.5\n",
      "7.281407 7.5 7.5\n",
      "8.888058 10 10.0\n",
      "7.274769 7.5 7.5\n",
      "8.896404 10 10.0\n",
      "9.15768 10 10.0\n",
      "8.768877 10 10.0\n",
      "5.280571 5 2.5\n",
      "6.705205 7.5 5.0\n",
      "7.762806 7.5 10.0\n",
      "6.7312284 7.5 10.0\n",
      "7.591618 7.5 7.5\n",
      "6.308951 7.5 10.0\n",
      "7.094358 7.5 7.5\n",
      "7.978814 7.5 7.5\n",
      "6.5401406 7.5 5.0\n",
      "6.9508786 7.5 10.0\n",
      "8.48898 7.5 7.5\n",
      "8.505541 7.5 10.0\n",
      "6.6333866 7.5 2.5\n",
      "6.710438 7.5 10.0\n",
      "7.039234 7.5 7.5\n",
      "7.3088984 7.5 2.5\n",
      "7.594661 7.5 7.5\n",
      "7.799756 7.5 7.5\n",
      "7.924488 7.5 7.5\n",
      "8.130526 7.5 7.5\n",
      "7.4066944 7.5 7.5\n",
      "7.270441 7.5 2.5\n",
      "7.265235 7.5 7.5\n",
      "8.737057 7.5 10.0\n",
      "5.083915 5 7.5\n",
      "7.602276 7.5 5.0\n",
      "7.356227 7.5 10.0\n",
      "8.869089 10 7.5\n",
      "7.2095714 7.5 7.5\n",
      "8.55527 7.5 7.5\n",
      "7.8641415 7.5 10.0\n",
      "6.017965 5 2.5\n",
      "6.474202 7.5 7.5\n",
      "8.801375 10 7.5\n",
      "7.997595 7.5 10.0\n",
      "8.310228 7.5 7.5\n",
      "7.712623 7.5 10.0\n",
      "8.753038 10 10.0\n",
      "7.755875 7.5 7.5\n",
      "8.469633 7.5 10.0\n",
      "8.895757 10 7.5\n",
      "7.3946657 7.5 7.5\n",
      "6.4811864 7.5 7.5\n",
      "6.4527173 7.5 2.5\n",
      "6.9135666 7.5 7.5\n",
      "7.139869 7.5 2.5\n",
      "8.39085 7.5 7.5\n",
      "7.079531 7.5 7.5\n",
      "9.039807 10 10.0\n",
      "7.822174 7.5 7.5\n",
      "7.0947776 7.5 10.0\n",
      "8.168383 7.5 10.0\n",
      "7.177552 7.5 7.5\n",
      "5.489314 5 7.5\n",
      "4.826519 5 7.5\n",
      "6.8174458 7.5 10.0\n",
      "7.8012595 7.5 10.0\n",
      "6.06841 5 7.5\n",
      "8.877749 10 7.5\n",
      "7.951837 7.5 7.5\n",
      "5.344897 5 2.5\n",
      "8.195393 7.5 10.0\n",
      "8.40124 7.5 7.5\n",
      "7.6985817 7.5 7.5\n",
      "7.8474765 7.5 5.0\n",
      "7.2066436 7.5 7.5\n",
      "8.149211 7.5 7.5\n",
      "6.9455957 7.5 5.0\n",
      "6.3098154 7.5 2.5\n",
      "6.33211 7.5 5.0\n",
      "6.40574 7.5 7.5\n",
      "6.9030623 7.5 7.5\n",
      "3.206841 2.5 2.5\n",
      "7.447324 7.5 2.5\n",
      "7.562243 7.5 7.5\n",
      "6.3648105 7.5 10.0\n",
      "4.9486704 5 7.5\n",
      "7.817934 7.5 2.5\n",
      "8.402046 7.5 10.0\n",
      "7.7464633 7.5 2.5\n",
      "8.706513 7.5 10.0\n",
      "7.3992596 7.5 5.0\n",
      "6.945388 7.5 7.5\n",
      "8.492481 7.5 10.0\n",
      "8.299252 7.5 7.5\n",
      "7.583466 7.5 10.0\n",
      "7.2872763 7.5 7.5\n",
      "8.35582 7.5 7.5\n",
      "8.030301 7.5 7.5\n",
      "9.012908 10 10.0\n",
      "7.240848 7.5 10.0\n",
      "6.959243 7.5 5.0\n",
      "8.585435 7.5 7.5\n",
      "7.555036 7.5 7.5\n",
      "8.290573 7.5 10.0\n",
      "8.799361 10 7.5\n",
      "5.264028 5 7.5\n",
      "7.9414825 7.5 7.5\n",
      "7.856016 7.5 7.5\n",
      "9.483923 10 10.0\n",
      "6.076272 5 10.0\n",
      "7.0877542 7.5 10.0\n",
      "6.9425583 7.5 2.5\n",
      "7.468598 7.5 5.0\n",
      "7.3825173 7.5 5.0\n",
      "7.115344 7.5 7.5\n",
      "8.0335045 7.5 10.0\n",
      "8.730178 7.5 10.0\n",
      "8.419784 7.5 10.0\n",
      "7.798797 7.5 7.5\n",
      "7.6943526 7.5 7.5\n",
      "6.584841 7.5 5.0\n",
      "6.7851033 7.5 7.5\n",
      "7.1537595 7.5 10.0\n",
      "7.422084 7.5 7.5\n",
      "7.165734 7.5 7.5\n",
      "3.8009396 5 2.5\n",
      "6.9972525 7.5 10.0\n",
      "8.824984 10 10.0\n",
      "7.791033 7.5 7.5\n",
      "8.141205 7.5 10.0\n",
      "4.988617 5 2.5\n",
      "7.219178 7.5 7.5\n",
      "7.0459085 7.5 10.0\n",
      "7.070277 7.5 5.0\n",
      "8.11845 7.5 7.5\n",
      "8.998032 10 10.0\n",
      "6.8798656 7.5 7.5\n",
      "6.174459 5 5.0\n",
      "4.4020157 5 0.0\n",
      "8.0084915 7.5 10.0\n",
      "7.26875 7.5 7.5\n",
      "8.78282 10 7.5\n",
      "7.0594187 7.5 0.0\n",
      "8.089159 7.5 10.0\n",
      "7.018011 7.5 7.5\n",
      "5.6199512 5 7.5\n",
      "4.4933977 5 2.5\n",
      "7.1704116 7.5 7.5\n",
      "7.3016014 7.5 5.0\n",
      "5.169882 5 2.5\n",
      "8.3884 7.5 10.0\n",
      "4.523283 5 2.5\n",
      "7.107578 7.5 7.5\n",
      "7.3936977 7.5 7.5\n",
      "7.8517084 7.5 2.5\n",
      "7.00041 7.5 7.5\n",
      "6.455077 7.5 7.5\n",
      "7.4617457 7.5 10.0\n",
      "5.392189 5 7.5\n",
      "7.701345 7.5 7.5\n",
      "8.87136 10 7.5\n",
      "8.94487 10 7.5\n",
      "8.811584 10 10.0\n",
      "7.2529273 7.5 2.5\n",
      "5.091694 5 7.5\n",
      "9.023467 10 5.0\n",
      "8.589597 7.5 10.0\n",
      "7.219659 7.5 7.5\n",
      "8.477047 7.5 10.0\n",
      "7.1748805 7.5 2.5\n",
      "7.433496 7.5 7.5\n",
      "8.793344 10 10.0\n",
      "9.211994 10 10.0\n",
      "7.1827335 7.5 7.5\n",
      "7.5120325 7.5 7.5\n",
      "7.3371315 7.5 7.5\n",
      "6.986016 7.5 5.0\n",
      "7.859622 7.5 5.0\n",
      "6.8411217 7.5 2.5\n",
      "5.3299756 5 5.0\n",
      "5.7599874 5 2.5\n",
      "7.130823 7.5 2.5\n",
      "4.8966084 5 7.5\n",
      "7.036296 7.5 5.0\n",
      "8.859753 10 10.0\n",
      "8.998312 10 10.0\n",
      "6.9230065 7.5 2.5\n",
      "6.1667223 5 5.0\n",
      "7.46657 7.5 10.0\n",
      "7.1951647 7.5 10.0\n",
      "9.417651 10 10.0\n",
      "7.1169744 7.5 10.0\n",
      "8.759647 10 10.0\n",
      "8.686352 7.5 10.0\n",
      "7.8044577 7.5 7.5\n",
      "6.2809176 7.5 10.0\n",
      "6.733169 7.5 10.0\n",
      "6.9946346 7.5 5.0\n",
      "7.5724654 7.5 10.0\n",
      "5.876876 5 7.5\n",
      "7.2717805 7.5 7.5\n",
      "7.252929 7.5 10.0\n",
      "8.265154 7.5 7.5\n",
      "8.61026 7.5 10.0\n",
      "4.2675037 5 7.5\n",
      "8.10353 7.5 7.5\n",
      "8.166803 7.5 5.0\n",
      "8.212906 7.5 7.5\n",
      "7.3442926 7.5 7.5\n",
      "5.345816 5 2.5\n",
      "7.0297627 7.5 7.5\n",
      "8.757666 10 10.0\n",
      "6.4201317 7.5 7.5\n",
      "7.4657893 7.5 7.5\n",
      "7.800231 7.5 7.5\n",
      "8.073482 7.5 2.5\n",
      "6.745623 7.5 5.0\n",
      "5.237392 5 7.5\n",
      "7.5151434 7.5 7.5\n",
      "7.7858205 7.5 7.5\n",
      "7.201031 7.5 10.0\n",
      "7.1281676 7.5 5.0\n",
      "8.2869625 7.5 7.5\n",
      "6.612165 7.5 10.0\n",
      "7.377511 7.5 10.0\n",
      "7.099855 7.5 7.5\n",
      "7.523238 7.5 7.5\n",
      "6.3083353 7.5 7.5\n",
      "7.7223873 7.5 7.5\n",
      "7.8259206 7.5 10.0\n",
      "8.568031 7.5 10.0\n",
      "7.122948 7.5 10.0\n",
      "7.7605457 7.5 10.0\n",
      "7.4238973 7.5 7.5\n",
      "6.36018 7.5 7.5\n",
      "6.642846 7.5 7.5\n",
      "7.260721 7.5 5.0\n",
      "8.953952 10 10.0\n",
      "8.366808 7.5 7.5\n",
      "7.011583 7.5 10.0\n",
      "7.934847 7.5 10.0\n",
      "6.5885687 7.5 5.0\n",
      "6.4567766 7.5 7.5\n",
      "7.671178 7.5 5.0\n",
      "8.154356 7.5 7.5\n",
      "6.404556 7.5 2.5\n",
      "5.465638 5 2.5\n",
      "6.8559866 7.5 7.5\n",
      "6.5621066 7.5 7.5\n",
      "6.2901382 7.5 10.0\n",
      "6.9750776 7.5 10.0\n",
      "7.4078064 7.5 2.5\n",
      "8.242606 7.5 7.5\n",
      "7.745081 7.5 10.0\n",
      "7.051695 7.5 7.5\n",
      "8.875136 10 7.5\n",
      "6.3689322 7.5 2.5\n",
      "6.9917083 7.5 2.5\n",
      "8.377071 7.5 10.0\n",
      "6.3208 7.5 2.5\n",
      "6.4019732 7.5 7.5\n",
      "5.8370466 5 7.5\n",
      "6.9752703 7.5 7.5\n",
      "7.8977265 7.5 7.5\n",
      "8.067947 7.5 7.5\n",
      "9.118327 10 10.0\n",
      "7.101579 7.5 10.0\n",
      "6.7159967 7.5 2.5\n",
      "7.2055264 7.5 10.0\n",
      "7.661001 7.5 7.5\n",
      "7.2205963 7.5 5.0\n",
      "6.633061 7.5 2.5\n",
      "6.6140428 7.5 10.0\n",
      "8.52115 7.5 10.0\n",
      "7.3540564 7.5 10.0\n",
      "8.627132 7.5 10.0\n",
      "6.3774414 7.5 2.5\n",
      "8.874928 10 10.0\n",
      "6.4356565 7.5 2.5\n",
      "6.4370685 7.5 2.5\n",
      "7.2858677 7.5 7.5\n",
      "7.385181 7.5 7.5\n",
      "8.027273 7.5 10.0\n",
      "7.5243363 7.5 7.5\n",
      "6.336462 7.5 10.0\n",
      "8.3227825 7.5 10.0\n",
      "7.106969 7.5 7.5\n",
      "7.195165 7.5 7.5\n",
      "7.069553 7.5 7.5\n",
      "7.480245 7.5 2.5\n",
      "6.7298155 7.5 5.0\n",
      "5.521868 5 7.5\n",
      "6.6968417 7.5 7.5\n",
      "7.3511276 7.5 0.0\n",
      "9.303144 10 10.0\n",
      "7.4655623 7.5 7.5\n",
      "5.6219034 5 0.0\n",
      "7.111885 7.5 7.5\n",
      "7.6180983 7.5 2.5\n",
      "5.714168 5 2.5\n",
      "7.4361115 7.5 7.5\n",
      "8.853647 10 7.5\n",
      "9.173534 10 10.0\n",
      "8.322689 7.5 7.5\n",
      "7.1198945 7.5 7.5\n",
      "8.685178 7.5 10.0\n",
      "7.5461574 7.5 7.5\n",
      "7.625299 7.5 10.0\n",
      "7.795294 7.5 10.0\n",
      "8.32785 7.5 10.0\n",
      "5.0081077 5 2.5\n",
      "6.4386535 7.5 7.5\n",
      "7.0277205 7.5 7.5\n",
      "7.8231196 7.5 7.5\n",
      "7.39638 7.5 7.5\n",
      "8.520012 7.5 10.0\n",
      "8.0893 7.5 5.0\n",
      "7.013221 7.5 10.0\n",
      "5.8427258 5 2.5\n",
      "8.448505 7.5 7.5\n",
      "7.68631 7.5 10.0\n",
      "8.408602 7.5 7.5\n",
      "7.281528 7.5 10.0\n",
      "7.4973373 7.5 7.5\n",
      "9.097749 10 2.5\n",
      "8.948606 10 5.0\n",
      "6.835436 7.5 7.5\n",
      "7.6762257 7.5 10.0\n",
      "8.882473 10 10.0\n",
      "7.2579484 7.5 7.5\n",
      "7.913873 7.5 7.5\n",
      "8.181637 7.5 10.0\n",
      "7.5347548 7.5 5.0\n",
      "6.7162385 7.5 10.0\n",
      "6.5141006 7.5 10.0\n",
      "5.0072517 5 2.5\n",
      "7.319083 7.5 5.0\n",
      "7.726082 7.5 5.0\n",
      "9.070667 10 10.0\n",
      "6.9449677 7.5 7.5\n",
      "7.4241624 7.5 10.0\n",
      "8.935159 10 10.0\n",
      "9.121632 10 7.5\n",
      "9.037085 10 10.0\n",
      "9.079686 10 10.0\n",
      "5.319502 5 7.5\n",
      "7.750863 7.5 10.0\n",
      "8.297959 7.5 5.0\n",
      "7.107518 7.5 2.5\n",
      "9.366106 10 10.0\n",
      "7.842175 7.5 2.5\n",
      "7.3438187 7.5 7.5\n",
      "7.6902995 7.5 7.5\n",
      "4.9804335 5 2.5\n",
      "8.831953 10 10.0\n",
      "7.756983 7.5 2.5\n",
      "7.169433 7.5 7.5\n",
      "8.091944 7.5 10.0\n",
      "7.7673006 7.5 10.0\n",
      "8.80626 10 10.0\n",
      "8.424608 7.5 7.5\n",
      "7.9119263 7.5 7.5\n",
      "7.6256275 7.5 7.5\n",
      "8.038233 7.5 10.0\n",
      "7.2625117 7.5 5.0\n",
      "6.7822204 7.5 7.5\n",
      "7.144688 7.5 7.5\n",
      "8.487054 7.5 10.0\n",
      "8.587625 7.5 10.0\n",
      "7.0492554 7.5 7.5\n",
      "6.342285 7.5 5.0\n",
      "6.38799 7.5 10.0\n",
      "7.1295676 7.5 7.5\n",
      "7.4619455 7.5 5.0\n",
      "4.3434243 5 7.5\n",
      "9.680006 10 10.0\n",
      "6.9844713 7.5 7.5\n",
      "8.150993 7.5 2.5\n",
      "7.2638707 7.5 7.5\n",
      "7.212571 7.5 7.5\n",
      "8.798696 10 10.0\n",
      "7.992386 7.5 7.5\n",
      "8.897947 10 7.5\n",
      "6.931009 7.5 10.0\n",
      "5.980958 5 7.5\n",
      "7.5002656 7.5 7.5\n",
      "8.1958885 7.5 10.0\n",
      "8.373877 7.5 2.5\n",
      "6.0194907 5 5.0\n",
      "5.157937 5 2.5\n",
      "7.683049 7.5 7.5\n",
      "7.460378 7.5 7.5\n",
      "8.31866 7.5 10.0\n",
      "6.86084 7.5 2.5\n",
      "6.9291873 7.5 7.5\n",
      "7.3484073 7.5 7.5\n",
      "7.491715 7.5 7.5\n",
      "6.5854144 7.5 7.5\n",
      "8.226849 7.5 10.0\n",
      "7.6999984 7.5 10.0\n",
      "6.993706 7.5 7.5\n",
      "7.161355 7.5 7.5\n",
      "8.086059 7.5 7.5\n",
      "4.4511447 5 7.5\n",
      "7.724736 7.5 5.0\n",
      "6.8132577 7.5 7.5\n",
      "8.556672 7.5 7.5\n",
      "8.3048 7.5 10.0\n",
      "8.198301 7.5 10.0\n",
      "7.0581517 7.5 7.5\n",
      "8.775366 10 10.0\n",
      "9.535846 10 10.0\n",
      "6.279993 7.5 10.0\n",
      "8.58876 7.5 10.0\n",
      "8.370449 7.5 10.0\n",
      "5.8076835 5 0.0\n",
      "9.35909 10 10.0\n",
      "8.692758 7.5 10.0\n",
      "6.409334 7.5 7.5\n",
      "7.706914 7.5 7.5\n",
      "7.9264364 7.5 10.0\n",
      "8.374477 7.5 10.0\n",
      "5.5105133 5 2.5\n",
      "6.679524 7.5 7.5\n",
      "5.9542613 5 7.5\n",
      "6.602333 7.5 7.5\n",
      "5.38588 5 2.5\n",
      "7.379202 7.5 7.5\n",
      "8.2308655 7.5 10.0\n",
      "9.017106 10 10.0\n",
      "7.245659 7.5 7.5\n",
      "7.0276556 7.5 7.5\n",
      "7.7206063 7.5 10.0\n",
      "7.5445886 7.5 7.5\n",
      "8.026932 7.5 7.5\n",
      "7.314439 7.5 10.0\n",
      "8.70756 7.5 7.5\n",
      "7.4323936 7.5 7.5\n",
      "5.741646 5 7.5\n",
      "7.568746 7.5 5.0\n",
      "3.4795103 2.5 0.0\n",
      "9.297452 10 10.0\n",
      "6.5596867 7.5 7.5\n",
      "7.263273 7.5 10.0\n",
      "4.1708136 5 2.5\n",
      "8.284242 7.5 5.0\n",
      "7.6258106 7.5 2.5\n",
      "8.794491 10 10.0\n",
      "6.4097238 7.5 10.0\n",
      "6.2405357 5 7.5\n",
      "8.163931 7.5 10.0\n",
      "8.669819 7.5 7.5\n",
      "6.081125 5 2.5\n",
      "9.173985 10 10.0\n",
      "7.297164 7.5 10.0\n",
      "6.5417137 7.5 5.0\n",
      "8.056555 7.5 7.5\n",
      "8.813874 10 5.0\n",
      "7.6736975 7.5 10.0\n",
      "5.195836 5 2.5\n",
      "7.1033144 7.5 7.5\n",
      "8.408995 7.5 10.0\n",
      "7.2171135 7.5 7.5\n",
      "7.4275546 7.5 7.5\n",
      "9.351756 10 10.0\n",
      "7.830738 7.5 10.0\n",
      "6.8312693 7.5 10.0\n",
      "6.898449 7.5 2.5\n",
      "4.3234873 5 2.5\n",
      "9.103485 10 10.0\n",
      "7.1605515 7.5 5.0\n",
      "5.3991456 5 7.5\n",
      "6.0527334 5 10.0\n",
      "6.081086 5 10.0\n",
      "7.685126 7.5 2.5\n",
      "8.429449 7.5 10.0\n",
      "7.0713825 7.5 2.5\n",
      "8.441404 7.5 10.0\n",
      "9.217741 10 10.0\n",
      "6.127519 5 5.0\n",
      "8.317212 7.5 7.5\n",
      "8.196624 7.5 7.5\n",
      "7.9834213 7.5 10.0\n",
      "5.641536 5 5.0\n",
      "6.13573 5 7.5\n",
      "9.109113 10 10.0\n",
      "5.9636765 5 5.0\n",
      "6.5842867 7.5 7.5\n",
      "7.7114897 7.5 10.0\n",
      "6.721934 7.5 5.0\n",
      "7.4219737 7.5 7.5\n",
      "8.45464 7.5 10.0\n",
      "7.1086082 7.5 7.5\n",
      "6.7797236 7.5 7.5\n",
      "9.308021 10 10.0\n",
      "7.287206 7.5 10.0\n",
      "8.959152 10 10.0\n",
      "8.951061 10 10.0\n",
      "7.508816 7.5 7.5\n",
      "5.068099 5 10.0\n",
      "7.4520006 7.5 7.5\n",
      "7.061678 7.5 10.0\n",
      "7.398614 7.5 10.0\n",
      "7.470941 7.5 7.5\n",
      "6.022891 5 2.5\n",
      "6.1525383 5 5.0\n",
      "6.6300006 7.5 7.5\n",
      "7.019757 7.5 7.5\n",
      "7.284956 7.5 7.5\n",
      "8.901727 10 10.0\n",
      "8.746807 7.5 7.5\n",
      "8.050109 7.5 7.5\n",
      "6.6938796 7.5 7.5\n",
      "8.166225 7.5 10.0\n",
      "7.4254622 7.5 7.5\n",
      "7.721778 7.5 10.0\n",
      "7.1940374 7.5 7.5\n",
      "9.039702 10 10.0\n",
      "8.23031 7.5 10.0\n",
      "9.2777815 10 10.0\n",
      "9.097258 10 10.0\n",
      "7.314315 7.5 10.0\n",
      "7.57996 7.5 7.5\n",
      "6.975276 7.5 7.5\n",
      "7.7763925 7.5 2.5\n",
      "7.2128057 7.5 7.5\n",
      "7.4142804 7.5 10.0\n",
      "8.633662 7.5 7.5\n",
      "8.816249 10 7.5\n",
      "7.356138 7.5 7.5\n",
      "8.937003 10 7.5\n",
      "5.4896417 5 7.5\n",
      "8.899139 10 10.0\n",
      "7.5480833 7.5 7.5\n",
      "9.131315 10 7.5\n",
      "6.890008 7.5 7.5\n",
      "7.1961164 7.5 5.0\n",
      "7.293993 7.5 7.5\n",
      "8.294857 7.5 7.5\n",
      "8.777818 10 10.0\n",
      "9.284302 10 7.5\n",
      "8.583701 7.5 10.0\n",
      "8.726537 7.5 5.0\n",
      "6.5027018 7.5 10.0\n",
      "8.27832 7.5 10.0\n",
      "7.3361435 7.5 10.0\n",
      "4.8088937 5 7.5\n",
      "3.8102713 5 10.0\n",
      "6.2598176 7.5 10.0\n",
      "8.959952 10 5.0\n",
      "4.4287815 5 2.5\n",
      "9.2451515 10 10.0\n",
      "7.2926154 7.5 10.0\n",
      "7.317317 7.5 7.5\n",
      "7.9175944 7.5 10.0\n",
      "7.275666 7.5 2.5\n",
      "7.592629 7.5 7.5\n",
      "6.2287884 5 7.5\n",
      "7.5004053 7.5 7.5\n",
      "7.9783263 7.5 10.0\n",
      "8.9561 10 10.0\n",
      "5.882693 5 7.5\n",
      "4.985522 5 7.5\n",
      "6.6387334 7.5 10.0\n",
      "7.6975536 7.5 10.0\n",
      "8.455681 7.5 10.0\n",
      "7.876215 7.5 10.0\n",
      "8.567278 7.5 10.0\n",
      "8.6879225 7.5 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7574396 7.5 7.5\n",
      "7.146657 7.5 10.0\n",
      "8.529603 7.5 5.0\n",
      "7.1334844 7.5 7.5\n",
      "5.8378696 5 2.5\n",
      "7.2832446 7.5 7.5\n",
      "7.612223 7.5 7.5\n",
      "6.818888 7.5 7.5\n",
      "7.420518 7.5 7.5\n",
      "7.2980275 7.5 5.0\n",
      "5.7383604 5 2.5\n",
      "6.2615175 7.5 7.5\n",
      "6.6522627 7.5 7.5\n",
      "6.1226707 5 7.5\n",
      "4.436254 5 7.5\n",
      "7.765819 7.5 7.5\n",
      "7.6464105 7.5 5.0\n",
      "7.4550295 7.5 10.0\n",
      "8.247253 7.5 7.5\n",
      "7.783889 7.5 10.0\n",
      "6.8527164 7.5 7.5\n",
      "7.6722775 7.5 7.5\n",
      "7.215664 7.5 2.5\n",
      "6.639135 7.5 10.0\n",
      "7.11952 7.5 7.5\n",
      "8.538041 7.5 10.0\n",
      "9.917143 10 10.0\n",
      "7.593615 7.5 10.0\n",
      "8.31717 7.5 7.5\n",
      "7.4880567 7.5 2.5\n",
      "6.509329 7.5 7.5\n",
      "6.3432565 7.5 2.5\n",
      "8.837619 10 10.0\n",
      "7.251931 7.5 7.5\n",
      "5.1459727 5 2.5\n",
      "4.7939253 5 0.0\n",
      "7.554099 7.5 10.0\n",
      "5.7530193 5 2.5\n",
      "7.1315784 7.5 10.0\n",
      "6.6707196 7.5 7.5\n",
      "9.495126 10 10.0\n",
      "7.509618 7.5 10.0\n",
      "7.072568 7.5 10.0\n",
      "8.936038 10 10.0\n",
      "7.7594514 7.5 7.5\n",
      "7.373159 7.5 10.0\n",
      "7.533154 7.5 10.0\n",
      "9.063518 10 7.5\n",
      "6.768366 7.5 2.5\n",
      "6.259156 7.5 7.5\n",
      "7.2441187 7.5 7.5\n",
      "7.7757993 7.5 7.5\n",
      "6.8099904 7.5 5.0\n",
      "6.2015033 5 2.5\n",
      "6.786014 7.5 5.0\n",
      "8.877727 10 10.0\n",
      "8.141465 7.5 5.0\n",
      "8.738115 7.5 10.0\n",
      "7.3168907 7.5 5.0\n",
      "7.533999 7.5 7.5\n",
      "7.1918025 7.5 10.0\n",
      "9.0334425 10 7.5\n",
      "6.937531 7.5 10.0\n",
      "7.204334 7.5 10.0\n",
      "7.071659 7.5 2.5\n",
      "7.742923 7.5 7.5\n",
      "6.729344 7.5 10.0\n",
      "8.120781 7.5 10.0\n",
      "6.0358644 5 7.5\n",
      "7.355685 7.5 10.0\n",
      "6.647059 7.5 5.0\n",
      "7.568609 7.5 10.0\n",
      "7.5426946 7.5 7.5\n",
      "8.941104 10 7.5\n",
      "6.500508 7.5 5.0\n",
      "7.668667 7.5 10.0\n",
      "7.583597 7.5 5.0\n",
      "8.444164 7.5 10.0\n",
      "7.6539226 7.5 5.0\n",
      "8.852838 10 7.5\n",
      "6.603188 7.5 7.5\n",
      "6.876526 7.5 7.5\n",
      "8.750996 10 10.0\n",
      "7.1613374 7.5 7.5\n",
      "7.11142 7.5 7.5\n",
      "6.9658685 7.5 10.0\n",
      "7.299549 7.5 10.0\n",
      "8.605099 7.5 7.5\n",
      "7.939755 7.5 7.5\n",
      "8.517868 7.5 7.5\n",
      "7.1593566 7.5 10.0\n",
      "6.0412936 5 7.5\n",
      "6.973075 7.5 7.5\n",
      "6.5312505 7.5 10.0\n",
      "9.309207 10 7.5\n",
      "9.299072 10 10.0\n",
      "5.751255 5 5.0\n",
      "5.9615045 5 5.0\n",
      "8.295078 7.5 10.0\n",
      "8.866927 10 7.5\n",
      "7.134985 7.5 7.5\n",
      "8.729123 7.5 7.5\n",
      "6.3805733 7.5 5.0\n",
      "7.4307704 7.5 2.5\n",
      "7.6332393 7.5 10.0\n",
      "8.731802 7.5 10.0\n",
      "6.043547 5 7.5\n",
      "8.777002 10 10.0\n",
      "7.8185496 7.5 10.0\n",
      "8.107146 7.5 7.5\n",
      "6.249166 5 7.5\n",
      "7.0336714 7.5 7.5\n",
      "8.262865 7.5 10.0\n",
      "7.272145 7.5 7.5\n",
      "7.7072086 7.5 7.5\n",
      "3.7535827 5 0.0\n",
      "8.681874 7.5 10.0\n",
      "6.8649592 7.5 2.5\n",
      "6.7205205 7.5 5.0\n",
      "5.160978 5 2.5\n",
      "9.01724 10 10.0\n",
      "7.6697683 7.5 10.0\n",
      "7.3892393 7.5 2.5\n",
      "8.7398 7.5 10.0\n",
      "8.93222 10 10.0\n",
      "7.3687215 7.5 7.5\n",
      "6.8376613 7.5 2.5\n",
      "7.203699 7.5 10.0\n",
      "6.5606947 7.5 5.0\n",
      "6.350559 7.5 2.5\n",
      "7.1001077 7.5 7.5\n",
      "8.672239 7.5 7.5\n",
      "8.212751 7.5 5.0\n",
      "7.2803283 7.5 7.5\n",
      "7.4151154 7.5 0.0\n",
      "5.0942025 5 5.0\n",
      "6.186628 5 5.0\n",
      "6.751465 7.5 5.0\n",
      "5.196508 5 2.5\n",
      "7.063168 7.5 7.5\n",
      "7.888785 7.5 10.0\n",
      "7.8750644 7.5 10.0\n",
      "7.4212046 7.5 5.0\n",
      "7.041174 7.5 7.5\n",
      "7.1120834 7.5 5.0\n",
      "7.048967 7.5 7.5\n",
      "7.2169 7.5 5.0\n",
      "8.517978 7.5 7.5\n",
      "7.2771215 7.5 2.5\n",
      "6.7754645 7.5 7.5\n",
      "7.521382 7.5 7.5\n",
      "9.355579 10 10.0\n",
      "7.3347387 7.5 7.5\n",
      "7.4087734 7.5 7.5\n",
      "6.7626157 7.5 10.0\n",
      "3.7648726 5 10.0\n",
      "8.51007 7.5 2.5\n",
      "7.98059 7.5 10.0\n",
      "7.1871157 7.5 10.0\n",
      "7.886685 7.5 5.0\n",
      "8.61995 7.5 7.5\n",
      "6.3969207 7.5 2.5\n",
      "9.26906 10 10.0\n",
      "6.4390635 7.5 2.5\n",
      "5.612626 5 2.5\n",
      "9.184707 10 7.5\n",
      "7.366966 7.5 10.0\n",
      "6.931749 7.5 5.0\n",
      "7.1927876 7.5 5.0\n",
      "8.423054 7.5 10.0\n",
      "7.4575047 7.5 7.5\n",
      "8.372066 7.5 10.0\n",
      "7.172108 7.5 7.5\n",
      "7.591867 7.5 2.5\n",
      "7.0086107 7.5 10.0\n",
      "8.654689 7.5 10.0\n",
      "7.601871 7.5 10.0\n",
      "7.7088895 7.5 7.5\n",
      "7.0183425 7.5 7.5\n",
      "8.605385 7.5 10.0\n",
      "8.634449 7.5 10.0\n",
      "3.3498142 2.5 7.5\n",
      "6.9685354 7.5 5.0\n",
      "7.3649716 7.5 7.5\n",
      "5.3046613 5 0.0\n",
      "7.647665 7.5 10.0\n",
      "6.63456 7.5 7.5\n",
      "9.344967 10 10.0\n",
      "6.812086 7.5 5.0\n",
      "7.3582454 7.5 10.0\n",
      "6.210463 5 2.5\n",
      "6.128749 5 10.0\n",
      "8.783801 10 10.0\n",
      "5.6959405 5 0.0\n",
      "9.169274 10 10.0\n",
      "8.075753 7.5 5.0\n",
      "7.017008 7.5 7.5\n",
      "7.362904 7.5 10.0\n",
      "9.165203 10 10.0\n",
      "6.9268236 7.5 5.0\n",
      "7.5351515 7.5 7.5\n",
      "7.181576 7.5 7.5\n",
      "7.651634 7.5 7.5\n",
      "7.6909857 7.5 5.0\n",
      "8.45688 7.5 7.5\n",
      "7.5970693 7.5 2.5\n",
      "7.509553 7.5 7.5\n",
      "8.765275 10 7.5\n",
      "6.52531 7.5 5.0\n",
      "9.021553 10 7.5\n",
      "7.379155 7.5 7.5\n",
      "8.720298 7.5 10.0\n",
      "8.234053 7.5 10.0\n",
      "8.6726675 7.5 10.0\n",
      "7.9455714 7.5 2.5\n",
      "7.494399 7.5 10.0\n",
      "4.8884907 5 0.0\n",
      "8.674735 7.5 10.0\n",
      "7.2710023 7.5 10.0\n",
      "7.250939 7.5 7.5\n",
      "8.4149475 7.5 7.5\n",
      "7.2949195 7.5 5.0\n",
      "7.0001464 7.5 7.5\n",
      "9.594848 10 10.0\n",
      "9.066174 10 10.0\n",
      "7.7019243 7.5 10.0\n",
      "8.730019 7.5 10.0\n",
      "6.0210137 5 2.5\n",
      "9.244882 10 10.0\n",
      "8.176205 7.5 10.0\n",
      "7.230062 7.5 10.0\n",
      "7.140302 7.5 10.0\n",
      "6.3330617 7.5 7.5\n",
      "8.925147 10 10.0\n",
      "7.849755 7.5 7.5\n",
      "6.778028 7.5 10.0\n",
      "9.038649 10 10.0\n",
      "8.382513 7.5 7.5\n",
      "6.8663383 7.5 7.5\n",
      "9.44787 10 7.5\n",
      "6.3165092 7.5 10.0\n",
      "7.796849 7.5 5.0\n",
      "5.3964906 5 0.0\n",
      "3.043529 2.5 0.0\n",
      "8.822692 10 7.5\n",
      "6.5541563 7.5 5.0\n",
      "5.1540256 5 5.0\n",
      "8.641922 7.5 5.0\n",
      "6.859657 7.5 5.0\n",
      "7.480814 7.5 7.5\n",
      "5.4278364 5 5.0\n",
      "8.3631 7.5 10.0\n",
      "7.4739776 7.5 5.0\n",
      "5.390557 5 2.5\n",
      "4.5011883 5 2.5\n",
      "8.504404 7.5 10.0\n",
      "5.083326 5 0.0\n",
      "7.648808 7.5 2.5\n",
      "7.499165 7.5 10.0\n",
      "7.6955414 7.5 7.5\n",
      "7.681861 7.5 10.0\n",
      "6.754502 7.5 7.5\n",
      "7.2869983 7.5 7.5\n",
      "6.365996 7.5 2.5\n",
      "5.204197 5 2.5\n",
      "5.9054847 5 2.5\n",
      "7.972956 7.5 10.0\n",
      "7.422367 7.5 7.5\n",
      "8.446764 7.5 10.0\n",
      "7.7334347 7.5 5.0\n",
      "7.28498 7.5 10.0\n",
      "7.398317 7.5 5.0\n",
      "6.4745936 7.5 7.5\n",
      "9.028527 10 10.0\n",
      "8.540679 7.5 10.0\n",
      "7.104635 7.5 10.0\n",
      "7.0410643 7.5 7.5\n",
      "6.32346 7.5 5.0\n",
      "6.629197 7.5 7.5\n",
      "8.973448 10 10.0\n",
      "8.889798 10 7.5\n",
      "6.9359818 7.5 5.0\n",
      "7.9293647 7.5 7.5\n",
      "6.583788 7.5 7.5\n",
      "7.3018885 7.5 7.5\n",
      "7.6276655 7.5 5.0\n",
      "7.5687647 7.5 10.0\n",
      "6.1155944 5 7.5\n",
      "6.715773 7.5 2.5\n",
      "5.936355 5 7.5\n",
      "7.531159 7.5 10.0\n",
      "8.485824 7.5 10.0\n",
      "4.843729 5 5.0\n",
      "8.509376 7.5 10.0\n",
      "7.9991617 7.5 10.0\n",
      "9.403778 10 7.5\n",
      "10.0034485 10 7.5\n",
      "8.21 7.5 10.0\n",
      "7.479756 7.5 10.0\n",
      "7.0194397 7.5 7.5\n",
      "8.201563 7.5 7.5\n",
      "8.001001 7.5 7.5\n",
      "6.2427216 5 5.0\n",
      "6.8377757 7.5 2.5\n",
      "8.987858 10 10.0\n",
      "9.340121 10 10.0\n",
      "7.528078 7.5 5.0\n",
      "8.86362 10 10.0\n",
      "8.0806875 7.5 0.0\n",
      "7.5769277 7.5 7.5\n",
      "7.6044216 7.5 7.5\n",
      "7.4456353 7.5 10.0\n",
      "7.4248395 7.5 10.0\n",
      "8.448914 7.5 7.5\n",
      "6.783118 7.5 10.0\n",
      "7.9123955 7.5 7.5\n",
      "7.006884 7.5 7.5\n",
      "7.7470303 7.5 10.0\n",
      "7.163418 7.5 7.5\n",
      "7.277816 7.5 7.5\n",
      "8.656313 7.5 10.0\n",
      "8.476597 7.5 7.5\n",
      "7.624916 7.5 7.5\n",
      "7.606934 7.5 5.0\n",
      "8.754588 10 10.0\n",
      "8.915235 10 10.0\n",
      "7.46821 7.5 7.5\n",
      "8.009338 7.5 10.0\n",
      "7.4551687 7.5 10.0\n",
      "8.752472 10 10.0\n",
      "7.84375 7.5 7.5\n",
      "9.731726 10 7.5\n",
      "5.265014 5 2.5\n",
      "6.9478273 7.5 7.5\n",
      "7.893033 7.5 2.5\n",
      "7.1356273 7.5 10.0\n",
      "7.3350983 7.5 7.5\n",
      "7.393844 7.5 7.5\n",
      "7.138094 7.5 7.5\n",
      "7.0465016 7.5 5.0\n",
      "8.300276 7.5 7.5\n",
      "6.698205 7.5 10.0\n",
      "6.934066 7.5 7.5\n",
      "8.498011 7.5 10.0\n",
      "8.801865 10 10.0\n",
      "8.038824 7.5 10.0\n",
      "9.275744 10 10.0\n",
      "7.6378508 7.5 7.5\n",
      "9.272494 10 10.0\n",
      "6.8717723 7.5 7.5\n",
      "7.825387 7.5 2.5\n",
      "4.575383 5 2.5\n",
      "7.338511 7.5 2.5\n",
      "8.965319 10 10.0\n",
      "6.441193 7.5 7.5\n",
      "8.146828 7.5 10.0\n",
      "6.925268 7.5 2.5\n",
      "4.107786 5 2.5\n",
      "8.620431 7.5 10.0\n",
      "7.274011 7.5 7.5\n",
      "5.253542 5 2.5\n",
      "7.1724224 7.5 5.0\n",
      "8.045315 7.5 7.5\n",
      "7.221854 7.5 7.5\n",
      "6.989506 7.5 5.0\n",
      "5.474185 5 5.0\n",
      "6.8879514 7.5 7.5\n",
      "7.6981916 7.5 7.5\n",
      "6.1464844 5 5.0\n",
      "7.589906 7.5 7.5\n",
      "7.516305 7.5 2.5\n",
      "7.3983226 7.5 7.5\n",
      "8.487232 7.5 5.0\n",
      "7.326425 7.5 7.5\n",
      "5.920574 5 5.0\n",
      "7.580915 7.5 10.0\n",
      "7.974285 7.5 10.0\n",
      "7.279925 7.5 7.5\n",
      "6.843707 7.5 10.0\n",
      "8.773031 10 10.0\n",
      "6.9563394 7.5 10.0\n",
      "8.314357 7.5 10.0\n",
      "7.712937 7.5 5.0\n",
      "7.904101 7.5 10.0\n",
      "5.777071 5 2.5\n",
      "8.881493 10 7.5\n",
      "5.931883 5 2.5\n",
      "7.4885664 7.5 5.0\n",
      "7.2951126 7.5 5.0\n",
      "6.5661273 7.5 10.0\n",
      "6.993216 7.5 2.5\n",
      "7.374301 7.5 7.5\n",
      "7.5812654 7.5 5.0\n",
      "5.222502 5 0.0\n",
      "7.185099 7.5 10.0\n",
      "7.9184823 7.5 7.5\n",
      "6.4165473 7.5 5.0\n",
      "8.590414 7.5 7.5\n",
      "9.219994 10 7.5\n",
      "9.152784 10 7.5\n",
      "7.6017833 7.5 7.5\n",
      "8.836202 10 7.5\n",
      "8.775937 10 2.5\n",
      "7.610288 7.5 10.0\n",
      "7.7863674 7.5 10.0\n",
      "6.8701906 7.5 7.5\n",
      "8.082169 7.5 10.0\n",
      "7.43944 7.5 10.0\n",
      "7.8321486 7.5 0.0\n",
      "7.291096 7.5 7.5\n",
      "8.14492 7.5 10.0\n",
      "6.605267 7.5 7.5\n",
      "6.269217 7.5 7.5\n",
      "7.838585 7.5 7.5\n",
      "8.8443775 10 10.0\n",
      "6.777845 7.5 10.0\n",
      "6.5328045 7.5 7.5\n",
      "6.5589867 7.5 7.5\n",
      "8.7802925 10 7.5\n",
      "7.536606 7.5 10.0\n",
      "7.2934513 7.5 10.0\n",
      "7.374728 7.5 7.5\n",
      "6.3944173 7.5 7.5\n",
      "5.7635794 5 2.5\n",
      "3.656596 2.5 2.5\n",
      "7.4562345 7.5 10.0\n",
      "8.499607 7.5 7.5\n",
      "7.003429 7.5 2.5\n",
      "7.5013814 7.5 5.0\n",
      "6.5105658 7.5 2.5\n",
      "6.034872 5 7.5\n",
      "9.135196 10 7.5\n",
      "6.1855226 5 5.0\n",
      "6.432571 7.5 7.5\n",
      "7.159272 7.5 5.0\n",
      "7.2345076 7.5 7.5\n",
      "8.31964 7.5 10.0\n",
      "7.425407 7.5 5.0\n",
      "8.516319 7.5 10.0\n",
      "7.8409014 7.5 10.0\n",
      "7.0929847 7.5 7.5\n",
      "7.2338347 7.5 2.5\n",
      "7.4362245 7.5 10.0\n",
      "8.501143 7.5 10.0\n",
      "5.954244 5 5.0\n",
      "8.66079 7.5 10.0\n",
      "8.956649 10 10.0\n",
      "6.1084347 5 2.5\n",
      "8.614374 7.5 7.5\n",
      "8.822612 10 7.5\n",
      "7.343077 7.5 10.0\n",
      "8.150848 7.5 10.0\n",
      "6.8793154 7.5 7.5\n",
      "9.04114 10 10.0\n",
      "4.342376 5 5.0\n",
      "9.2200985 10 10.0\n",
      "8.320372 7.5 10.0\n",
      "8.98884 10 2.5\n",
      "7.4062414 7.5 7.5\n",
      "5.727801 5 2.5\n",
      "7.2629056 7.5 7.5\n",
      "7.1584306 7.5 10.0\n",
      "7.9017653 7.5 7.5\n",
      "6.979982 7.5 2.5\n",
      "4.926012 5 10.0\n",
      "9.037029 10 10.0\n",
      "5.8635283 5 10.0\n",
      "6.578788 7.5 5.0\n",
      "7.562007 7.5 7.5\n",
      "7.268746 7.5 7.5\n",
      "7.8298683 7.5 10.0\n",
      "6.9110427 7.5 10.0\n",
      "7.2487926 7.5 7.5\n",
      "7.873275 7.5 7.5\n",
      "9.161444 10 10.0\n",
      "7.1817064 7.5 10.0\n",
      "6.5394335 7.5 10.0\n",
      "7.8899946 7.5 10.0\n",
      "7.1179533 7.5 10.0\n",
      "8.062588 7.5 7.5\n",
      "7.4147215 7.5 7.5\n",
      "6.47768 7.5 7.5\n",
      "8.538068 7.5 5.0\n",
      "9.200843 10 5.0\n",
      "7.2260056 7.5 7.5\n",
      "8.386311 7.5 7.5\n",
      "7.5643725 7.5 7.5\n",
      "7.143354 7.5 7.5\n",
      "7.4040995 7.5 7.5\n",
      "7.7747183 7.5 10.0\n",
      "6.9252405 7.5 7.5\n",
      "7.499321 7.5 7.5\n",
      "7.625387 7.5 7.5\n",
      "8.492781 7.5 7.5\n",
      "7.7727137 7.5 10.0\n",
      "9.410736 10 10.0\n",
      "8.4212265 7.5 7.5\n",
      "5.0432887 5 2.5\n",
      "7.5579004 7.5 10.0\n",
      "7.3813653 7.5 10.0\n",
      "7.366298 7.5 2.5\n",
      "8.751657 10 10.0\n",
      "6.9692817 7.5 7.5\n",
      "7.3837996 7.5 10.0\n",
      "4.7128754 5 7.5\n",
      "8.59533 7.5 10.0\n",
      "8.823772 10 10.0\n",
      "8.283888 7.5 7.5\n",
      "5.4611855 5 7.5\n",
      "9.037518 10 10.0\n",
      "7.6592607 7.5 10.0\n",
      "6.630636 7.5 2.5\n",
      "5.9215016 5 7.5\n",
      "8.906701 10 7.5\n",
      "8.294857 7.5 7.5\n",
      "7.245071 7.5 7.5\n",
      "9.327529 10 10.0\n",
      "5.752332 5 7.5\n",
      "7.198105 7.5 2.5\n",
      "7.2243733 7.5 5.0\n",
      "8.646602 7.5 10.0\n",
      "9.225362 10 7.5\n",
      "5.675704 5 7.5\n",
      "7.522191 7.5 10.0\n",
      "8.761958 10 10.0\n",
      "5.250728 5 0.0\n",
      "7.241708 7.5 7.5\n",
      "7.1478324 7.5 2.5\n",
      "7.6252623 7.5 7.5\n",
      "6.9204516 7.5 7.5\n",
      "7.2942324 7.5 7.5\n",
      "7.613877 7.5 10.0\n",
      "6.9543653 7.5 7.5\n",
      "5.7603903 5 10.0\n",
      "9.71579 10 10.0\n",
      "7.1610374 7.5 7.5\n",
      "7.948576 7.5 10.0\n",
      "6.101103 5 7.5\n",
      "7.369439 7.5 10.0\n",
      "8.806883 10 10.0\n",
      "5.090892 5 2.5\n",
      "7.281867 7.5 10.0\n",
      "7.620492 7.5 7.5\n",
      "9.132525 10 10.0\n",
      "9.047476 10 10.0\n",
      "9.00143 10 10.0\n",
      "8.344004 7.5 7.5\n",
      "7.942431 7.5 10.0\n",
      "7.137034 7.5 7.5\n",
      "6.4771767 7.5 5.0\n",
      "5.3286996 5 7.5\n",
      "8.014618 7.5 7.5\n",
      "6.5817986 7.5 5.0\n",
      "8.97556 10 7.5\n",
      "8.652091 7.5 7.5\n",
      "7.585423 7.5 2.5\n",
      "6.96262 7.5 10.0\n",
      "5.509442 5 7.5\n",
      "7.354374 7.5 2.5\n",
      "7.0831857 7.5 7.5\n",
      "7.798883 7.5 5.0\n",
      "7.3192677 7.5 5.0\n",
      "6.5994096 7.5 7.5\n",
      "7.430019 7.5 7.5\n",
      "8.623701 7.5 7.5\n",
      "7.7108502 7.5 5.0\n",
      "8.494919 7.5 2.5\n",
      "3.7998834 5 0.0\n",
      "6.1068435 5 0.0\n",
      "6.4543977 7.5 5.0\n",
      "7.688884 7.5 10.0\n",
      "9.428779 10 10.0\n",
      "6.88592 7.5 7.5\n",
      "7.1319466 7.5 7.5\n",
      "8.133987 7.5 10.0\n",
      "7.638917 7.5 7.5\n",
      "8.382343 7.5 10.0\n",
      "6.763493 7.5 2.5\n",
      "6.5229025 7.5 5.0\n",
      "8.629407 7.5 7.5\n",
      "6.7921944 7.5 10.0\n",
      "6.1916733 5 10.0\n",
      "8.179028 7.5 10.0\n",
      "7.3136697 7.5 5.0\n",
      "7.456883 7.5 2.5\n",
      "7.1727877 7.5 2.5\n",
      "8.083348 7.5 10.0\n",
      "7.8969812 7.5 10.0\n",
      "6.4721923 7.5 7.5\n",
      "7.4286 7.5 7.5\n",
      "8.005686 7.5 7.5\n",
      "9.131033 10 10.0\n",
      "9.200788 10 7.5\n",
      "9.776914 10 10.0\n",
      "7.308954 7.5 7.5\n",
      "7.3787804 7.5 7.5\n",
      "7.10879 7.5 5.0\n",
      "7.5007076 7.5 7.5\n",
      "4.7373276 5 2.5\n",
      "7.698946 7.5 7.5\n",
      "7.825532 7.5 2.5\n",
      "5.112576 5 10.0\n",
      "8.71077 7.5 7.5\n",
      "8.783698 10 7.5\n",
      "8.000311 7.5 10.0\n",
      "5.8526053 5 5.0\n",
      "7.151727 7.5 10.0\n",
      "8.853235 10 10.0\n",
      "6.983809 7.5 7.5\n",
      "7.014088 7.5 10.0\n",
      "7.175038 7.5 2.5\n",
      "9.147533 10 10.0\n",
      "7.1667047 7.5 10.0\n",
      "6.9234366 7.5 7.5\n",
      "8.093098 7.5 10.0\n",
      "8.676489 7.5 7.5\n",
      "7.061639 7.5 10.0\n",
      "7.740413 7.5 5.0\n",
      "8.39974 7.5 10.0\n",
      "9.170129 10 10.0\n",
      "7.397921 7.5 7.5\n",
      "4.475643 5 5.0\n",
      "6.3607326 7.5 7.5\n",
      "8.690546 7.5 7.5\n",
      "6.9081674 7.5 7.5\n",
      "7.314212 7.5 7.5\n",
      "8.531172 7.5 10.0\n",
      "6.959191 7.5 7.5\n",
      "7.404154 7.5 10.0\n",
      "7.47721 7.5 2.5\n",
      "8.420097 7.5 7.5\n",
      "4.8955836 5 2.5\n",
      "6.703501 7.5 10.0\n",
      "6.7747555 7.5 7.5\n",
      "9.1996355 10 7.5\n",
      "7.032372 7.5 5.0\n",
      "7.9516516 7.5 10.0\n",
      "5.8556833 5 7.5\n",
      "7.3941374 7.5 5.0\n",
      "7.621516 7.5 10.0\n",
      "7.4530396 7.5 7.5\n",
      "5.3358355 5 0.0\n",
      "8.779274 10 7.5\n",
      "7.5688725 7.5 10.0\n",
      "7.018472 7.5 2.5\n",
      "6.9987335 7.5 2.5\n",
      "8.985204 10 10.0\n",
      "8.956691 10 7.5\n",
      "8.448505 7.5 10.0\n",
      "6.7558117 7.5 7.5\n",
      "8.861679 10 7.5\n",
      "8.519202 7.5 7.5\n",
      "6.765058 7.5 7.5\n",
      "7.3710456 7.5 5.0\n",
      "7.425432 7.5 7.5\n",
      "6.4374146 7.5 7.5\n",
      "5.760561 5 5.0\n",
      "6.873416 7.5 7.5\n",
      "8.750112 10 7.5\n",
      "8.54989 7.5 5.0\n",
      "7.544607 7.5 7.5\n",
      "6.992478 7.5 7.5\n",
      "7.0540113 7.5 7.5\n",
      "5.8190494 5 7.5\n",
      "7.925432 7.5 7.5\n",
      "6.305715 7.5 7.5\n",
      "8.526509 7.5 7.5\n",
      "8.55321 7.5 10.0\n",
      "6.286523 7.5 5.0\n",
      "7.367794 7.5 10.0\n",
      "6.9315166 7.5 7.5\n",
      "7.518938 7.5 7.5\n",
      "7.978758 7.5 10.0\n",
      "8.811152 10 10.0\n",
      "6.778396 7.5 7.5\n",
      "7.2507076 7.5 10.0\n",
      "8.848014 10 7.5\n",
      "7.60558 7.5 10.0\n",
      "7.777097 7.5 10.0\n",
      "9.21131 10 10.0\n",
      "7.2263703 7.5 10.0\n",
      "8.717333 7.5 7.5\n",
      "7.3780704 7.5 10.0\n",
      "8.837742 10 10.0\n",
      "6.80549 7.5 7.5\n",
      "7.434809 7.5 10.0\n",
      "5.8019896 5 10.0\n",
      "6.4198833 7.5 10.0\n",
      "6.955144 7.5 7.5\n",
      "8.399872 7.5 10.0\n",
      "7.218571 7.5 7.5\n",
      "8.315033 7.5 10.0\n",
      "7.4616976 7.5 10.0\n",
      "4.5755734 5 10.0\n",
      "8.884412 10 10.0\n",
      "7.234712 7.5 7.5\n",
      "7.2955546 7.5 7.5\n",
      "8.162269 7.5 5.0\n",
      "9.323351 10 7.5\n",
      "7.0851483 7.5 10.0\n",
      "6.8806133 7.5 7.5\n",
      "8.919209 10 10.0\n",
      "5.625055 5 0.0\n",
      "7.1418505 7.5 5.0\n",
      "6.501433 7.5 5.0\n",
      "7.3581285 7.5 7.5\n",
      "3.4804149 2.5 7.5\n",
      "6.616448 7.5 7.5\n",
      "6.812366 7.5 2.5\n",
      "5.7436852 5 7.5\n",
      "6.0842075 5 10.0\n",
      "6.2508607 7.5 2.5\n",
      "6.577914 7.5 10.0\n",
      "6.0183907 5 7.5\n",
      "8.457194 7.5 10.0\n",
      "6.610118 7.5 7.5\n",
      "8.618353 7.5 7.5\n",
      "7.341528 7.5 7.5\n",
      "6.82995 7.5 2.5\n",
      "9.439663 10 7.5\n",
      "7.582166 7.5 7.5\n",
      "6.4994745 7.5 10.0\n",
      "8.816916 10 10.0\n",
      "6.426784 7.5 7.5\n",
      "8.822032 10 7.5\n",
      "9.04423 10 7.5\n",
      "7.193652 7.5 7.5\n",
      "7.0033092 7.5 7.5\n",
      "9.108665 10 7.5\n",
      "8.007248 7.5 7.5\n",
      "8.341686 7.5 5.0\n",
      "7.6064563 7.5 7.5\n",
      "8.777297 10 7.5\n",
      "5.358725 5 10.0\n",
      "7.081816 7.5 2.5\n",
      "8.840815 10 10.0\n",
      "6.553141 7.5 7.5\n",
      "9.199583 10 10.0\n",
      "6.9609137 7.5 5.0\n",
      "7.5133815 7.5 7.5\n",
      "7.9938064 7.5 7.5\n",
      "7.693212 7.5 7.5\n",
      "7.58549 7.5 10.0\n",
      "9.619962 10 10.0\n",
      "8.799793 10 7.5\n",
      "7.9237533 7.5 10.0\n",
      "7.232435 7.5 7.5\n",
      "7.4100175 7.5 7.5\n",
      "8.078245 7.5 10.0\n",
      "5.281729 5 2.5\n",
      "8.677006 7.5 10.0\n",
      "7.1018357 7.5 5.0\n",
      "7.7431417 7.5 10.0\n",
      "7.064949 7.5 7.5\n",
      "6.4300313 7.5 7.5\n",
      "6.71622 7.5 7.5\n",
      "8.365703 7.5 10.0\n",
      "6.878198 7.5 7.5\n",
      "8.667368 7.5 10.0\n",
      "6.7442026 7.5 10.0\n",
      "6.9970465 7.5 7.5\n",
      "8.372765 7.5 10.0\n",
      "4.530624 5 2.5\n",
      "8.345398 7.5 7.5\n",
      "7.529927 7.5 10.0\n",
      "8.711141 7.5 0.0\n",
      "7.4070063 7.5 7.5\n",
      "6.7539377 7.5 7.5\n",
      "5.2200203 5 10.0\n",
      "6.1169014 5 7.5\n",
      "5.8806005 5 7.5\n",
      "9.10668 10 10.0\n",
      "9.83744 10 10.0\n",
      "5.6551857 5 2.5\n",
      "7.6088357 7.5 7.5\n",
      "8.358023 7.5 10.0\n",
      "9.011386 10 7.5\n",
      "8.831547 10 10.0\n",
      "7.501549 7.5 2.5\n",
      "6.558412 7.5 7.5\n",
      "9.609767 10 10.0\n",
      "7.427763 7.5 5.0\n",
      "7.8593307 7.5 10.0\n",
      "7.0350695 7.5 7.5\n",
      "6.939128 7.5 5.0\n",
      "7.238811 7.5 5.0\n",
      "7.340443 7.5 7.5\n",
      "7.207247 7.5 5.0\n",
      "9.123986 10 10.0\n",
      "7.595094 7.5 10.0\n",
      "8.903678 10 10.0\n",
      "7.015466 7.5 10.0\n",
      "8.799338 10 7.5\n",
      "9.80547 10 10.0\n",
      "7.1931653 7.5 10.0\n",
      "7.725206 7.5 10.0\n",
      "5.7076716 5 2.5\n",
      "7.8089876 7.5 10.0\n",
      "6.572604 7.5 7.5\n",
      "9.096749 10 10.0\n",
      "8.461212 7.5 10.0\n",
      "6.7182612 7.5 5.0\n",
      "8.312922 7.5 10.0\n",
      "8.733397 7.5 10.0\n",
      "8.481956 7.5 7.5\n",
      "7.9126725 7.5 10.0\n",
      "7.2704425 7.5 7.5\n",
      "8.283058 7.5 10.0\n",
      "8.724705 7.5 10.0\n",
      "5.45062 5 10.0\n",
      "7.4588437 7.5 7.5\n",
      "7.45834 7.5 10.0\n",
      "7.625082 7.5 5.0\n",
      "6.970528 7.5 7.5\n",
      "9.328814 10 10.0\n",
      "6.7867274 7.5 10.0\n",
      "7.290138 7.5 7.5\n",
      "8.969852 10 10.0\n",
      "7.8374104 7.5 7.5\n",
      "9.061124 10 10.0\n",
      "9.368023 10 10.0\n",
      "6.8151965 7.5 10.0\n",
      "7.1556435 7.5 7.5\n",
      "8.437529 7.5 7.5\n",
      "9.119984 10 10.0\n",
      "7.483712 7.5 10.0\n",
      "8.429295 7.5 10.0\n",
      "7.816572 7.5 7.5\n",
      "7.2241826 7.5 10.0\n",
      "7.221929 7.5 7.5\n",
      "7.3898544 7.5 5.0\n",
      "6.9354825 7.5 10.0\n",
      "7.704663 7.5 7.5\n",
      "8.569557 7.5 7.5\n",
      "7.8051343 7.5 10.0\n",
      "7.0423717 7.5 10.0\n",
      "8.97731 10 10.0\n",
      "9.129261 10 10.0\n",
      "8.682636 7.5 10.0\n",
      "9.5561695 10 10.0\n",
      "4.263068 5 0.0\n",
      "8.865366 10 5.0\n",
      "8.779697 10 7.5\n",
      "8.364222 7.5 7.5\n",
      "9.300999 10 10.0\n",
      "7.1051903 7.5 7.5\n",
      "6.7797184 7.5 2.5\n",
      "7.2157984 7.5 7.5\n",
      "8.886085 10 10.0\n",
      "7.835509 7.5 10.0\n",
      "9.084024 10 7.5\n",
      "8.840619 10 10.0\n",
      "8.607864 7.5 10.0\n",
      "8.027666 7.5 10.0\n",
      "7.9053755 7.5 10.0\n",
      "7.7568417 7.5 7.5\n",
      "8.794814 10 2.5\n",
      "5.0802674 5 2.5\n",
      "8.773797 10 7.5\n",
      "7.408327 7.5 10.0\n",
      "7.4752946 7.5 10.0\n",
      "4.1165023 5 0.0\n",
      "7.5339355 7.5 5.0\n",
      "6.3888245 7.5 7.5\n",
      "7.261553 7.5 10.0\n",
      "5.570896 5 2.5\n",
      "9.537508 10 10.0\n",
      "6.592579 7.5 10.0\n",
      "9.057636 10 7.5\n",
      "7.2703137 7.5 2.5\n",
      "5.2237864 5 7.5\n",
      "9.103315 10 10.0\n",
      "9.073639 10 7.5\n",
      "6.7119155 7.5 7.5\n",
      "7.375075 7.5 7.5\n",
      "6.2597117 7.5 2.5\n",
      "8.877202 10 10.0\n",
      "8.159154 7.5 5.0\n",
      "8.534937 7.5 10.0\n",
      "8.479141 7.5 10.0\n",
      "7.466757 7.5 10.0\n",
      "5.8907995 5 10.0\n",
      "6.0842605 5 2.5\n",
      "5.4495397 5 10.0\n",
      "5.672735 5 2.5\n",
      "7.7406306 7.5 10.0\n",
      "8.523182 7.5 10.0\n",
      "7.125222 7.5 10.0\n",
      "9.088972 10 10.0\n",
      "7.580391 7.5 10.0\n",
      "7.2912707 7.5 10.0\n",
      "7.327047 7.5 7.5\n",
      "9.027111 10 10.0\n",
      "6.8746433 7.5 2.5\n",
      "9.664983 10 10.0\n",
      "6.456794 7.5 2.5\n",
      "8.589406 7.5 10.0\n",
      "9.311261 10 10.0\n",
      "8.261053 7.5 10.0\n",
      "7.203201 7.5 7.5\n",
      "7.8879795 7.5 7.5\n",
      "9.073093 10 10.0\n",
      "7.485351 7.5 7.5\n",
      "7.0763807 7.5 2.5\n",
      "6.746741 7.5 10.0\n",
      "5.4014726 5 5.0\n",
      "9.16915 10 10.0\n",
      "7.5489464 7.5 10.0\n",
      "7.518304 7.5 7.5\n",
      "8.876097 10 5.0\n",
      "7.2474256 7.5 7.5\n",
      "8.831597 10 10.0\n",
      "7.466924 7.5 7.5\n",
      "8.799064 10 10.0\n",
      "6.8644986 7.5 10.0\n",
      "6.4735856 7.5 7.5\n",
      "5.430522 5 2.5\n",
      "5.619048 5 7.5\n",
      "6.902569 7.5 7.5\n",
      "7.1490607 7.5 7.5\n",
      "7.8805895 7.5 10.0\n",
      "9.305983 10 10.0\n",
      "8.447409 7.5 7.5\n",
      "8.568017 7.5 7.5\n",
      "6.962968 7.5 7.5\n",
      "9.044534 10 10.0\n",
      "8.634638 7.5 5.0\n",
      "6.2213807 5 7.5\n",
      "8.515125 7.5 7.5\n",
      "7.9398694 7.5 7.5\n",
      "8.781555 10 10.0\n",
      "7.0721946 7.5 5.0\n",
      "6.844661 7.5 7.5\n",
      "6.876979 7.5 7.5\n",
      "6.9269657 7.5 10.0\n",
      "7.2601304 7.5 5.0\n",
      "7.885566 7.5 7.5\n",
      "7.9265537 7.5 5.0\n",
      "7.437221 7.5 7.5\n",
      "8.811155 10 7.5\n",
      "8.558069 7.5 7.5\n",
      "7.911621 7.5 5.0\n",
      "6.879501 7.5 7.5\n",
      "9.173004 10 10.0\n",
      "7.1493964 7.5 7.5\n",
      "6.5831676 7.5 5.0\n",
      "6.375969 7.5 10.0\n",
      "4.497078 5 10.0\n",
      "7.8846903 7.5 5.0\n",
      "7.263644 7.5 7.5\n",
      "8.81542 10 10.0\n",
      "7.306118 7.5 10.0\n",
      "6.6863756 7.5 10.0\n",
      "5.8281255 5 0.0\n",
      "6.87001 7.5 7.5\n",
      "8.560222 7.5 5.0\n",
      "7.347532 7.5 2.5\n",
      "5.394078 5 2.5\n",
      "7.275878 7.5 7.5\n",
      "8.898712 10 10.0\n",
      "7.2550836 7.5 10.0\n",
      "8.904577 10 7.5\n",
      "4.0245585 5 0.0\n",
      "7.2528696 7.5 10.0\n",
      "7.7091513 7.5 2.5\n",
      "7.3640265 7.5 5.0\n",
      "7.106886 7.5 7.5\n",
      "7.56186 7.5 7.5\n",
      "7.6090803 7.5 5.0\n",
      "7.1107397 7.5 7.5\n",
      "6.525983 7.5 10.0\n",
      "6.9776464 7.5 7.5\n",
      "8.471979 7.5 10.0\n",
      "8.762306 10 10.0\n",
      "7.5732536 7.5 10.0\n",
      "6.853691 7.5 10.0\n",
      "8.944574 10 10.0\n",
      "3.8103564 5 0.0\n",
      "7.7247667 7.5 10.0\n",
      "8.806738 10 7.5\n",
      "7.6130667 7.5 10.0\n",
      "7.1254444 7.5 5.0\n",
      "7.663777 7.5 10.0\n",
      "7.0437512 7.5 7.5\n",
      "8.158699 7.5 10.0\n",
      "7.593561 7.5 7.5\n",
      "6.5909743 7.5 7.5\n",
      "6.465161 7.5 10.0\n",
      "5.2460513 5 2.5\n",
      "7.254616 7.5 7.5\n",
      "8.829225 10 10.0\n",
      "7.3770657 7.5 5.0\n",
      "8.297775 7.5 10.0\n",
      "8.31026 7.5 10.0\n",
      "7.1343074 7.5 10.0\n",
      "8.350252 7.5 7.5\n",
      "7.8289466 7.5 10.0\n",
      "8.011559 7.5 10.0\n",
      "8.526553 7.5 10.0\n",
      "5.3406863 5 7.5\n",
      "6.9610796 7.5 10.0\n",
      "8.2193365 7.5 5.0\n",
      "7.4333043 7.5 7.5\n",
      "6.4549375 7.5 7.5\n",
      "6.9679084 7.5 10.0\n",
      "7.695641 7.5 7.5\n",
      "8.809087 10 10.0\n",
      "7.0992556 7.5 7.5\n",
      "7.294381 7.5 7.5\n",
      "4.769452 5 2.5\n",
      "6.862419 7.5 10.0\n",
      "7.262173 7.5 7.5\n",
      "6.6244183 7.5 7.5\n",
      "7.735661 7.5 10.0\n",
      "7.605994 7.5 7.5\n",
      "7.215745 7.5 10.0\n",
      "4.4958534 5 7.5\n",
      "8.518737 7.5 10.0\n",
      "8.913185 10 7.5\n",
      "7.4162307 7.5 5.0\n",
      "6.533009 7.5 10.0\n",
      "9.361176 10 10.0\n",
      "7.679318 7.5 7.5\n",
      "4.874597 5 2.5\n",
      "6.890183 7.5 7.5\n",
      "7.466236 7.5 10.0\n",
      "8.607478 7.5 7.5\n",
      "7.288839 7.5 5.0\n",
      "8.019413 7.5 10.0\n",
      "6.972181 7.5 10.0\n",
      "7.856065 7.5 7.5\n",
      "4.925813 5 2.5\n",
      "8.89687 10 5.0\n",
      "7.697325 7.5 2.5\n",
      "6.339926 7.5 2.5\n",
      "7.458403 7.5 10.0\n",
      "8.886133 10 7.5\n",
      "8.156813 7.5 5.0\n",
      "4.2491355 5 10.0\n",
      "7.208546 7.5 7.5\n",
      "7.7774754 7.5 10.0\n",
      "8.901677 10 10.0\n",
      "7.411892 7.5 7.5\n",
      "7.6627693 7.5 10.0\n",
      "8.291287 7.5 7.5\n",
      "6.8754053 7.5 5.0\n",
      "7.116129 7.5 7.5\n",
      "8.923519 10 10.0\n",
      "8.903907 10 7.5\n",
      "8.551395 7.5 7.5\n",
      "6.917765 7.5 5.0\n",
      "7.658475 7.5 7.5\n",
      "6.823564 7.5 2.5\n",
      "7.212105 7.5 7.5\n",
      "8.078587 7.5 7.5\n",
      "7.2818537 7.5 2.5\n",
      "7.639511 7.5 10.0\n",
      "8.001198 7.5 10.0\n",
      "7.5388484 7.5 7.5\n",
      "8.592069 7.5 10.0\n",
      "7.282885 7.5 7.5\n",
      "6.8850355 7.5 0.0\n",
      "7.5585303 7.5 10.0\n",
      "7.4688296 7.5 7.5\n",
      "7.4883375 7.5 5.0\n",
      "6.7446547 7.5 7.5\n",
      "9.0044985 10 10.0\n",
      "8.517876 7.5 5.0\n",
      "6.8810687 7.5 2.5\n",
      "5.8312182 5 7.5\n",
      "7.5735903 7.5 10.0\n",
      "7.2877374 7.5 10.0\n",
      "8.843364 10 7.5\n",
      "6.737352 7.5 2.5\n",
      "8.75648 10 7.5\n",
      "9.401746 10 10.0\n",
      "6.4341464 7.5 2.5\n",
      "7.333438 7.5 10.0\n",
      "6.200543 5 7.5\n",
      "7.45658 7.5 7.5\n",
      "7.1498437 7.5 7.5\n",
      "8.480831 7.5 10.0\n",
      "3.9833703 5 2.5\n",
      "9.242586 10 10.0\n",
      "7.17867 7.5 10.0\n",
      "6.9658265 7.5 2.5\n",
      "8.323627 7.5 7.5\n",
      "5.8919883 5 7.5\n",
      "7.4632034 7.5 7.5\n",
      "9.369827 10 10.0\n",
      "6.642099 7.5 7.5\n",
      "7.463152 7.5 7.5\n",
      "8.962686 10 10.0\n",
      "7.239458 7.5 7.5\n",
      "8.264124 7.5 0.0\n",
      "8.264651 7.5 10.0\n",
      "9.138285 10 7.5\n",
      "7.316722 7.5 7.5\n",
      "8.802455 10 7.5\n",
      "8.807313 10 10.0\n",
      "8.62666 7.5 10.0\n",
      "7.138647 7.5 5.0\n",
      "6.3900623 7.5 5.0\n",
      "6.9531364 7.5 7.5\n",
      "7.8080053 7.5 2.5\n",
      "8.557921 7.5 7.5\n",
      "9.209425 10 10.0\n",
      "6.783761 7.5 7.5\n",
      "9.444244 10 10.0\n",
      "9.079541 10 7.5\n",
      "7.1074314 7.5 7.5\n",
      "6.1951776 5 7.5\n",
      "8.623536 7.5 7.5\n",
      "7.2252765 7.5 7.5\n",
      "7.331638 7.5 5.0\n",
      "8.6508465 7.5 10.0\n",
      "7.3306384 7.5 7.5\n",
      "7.466047 7.5 7.5\n",
      "7.7273064 7.5 10.0\n",
      "7.6848145 7.5 7.5\n",
      "7.0623646 7.5 7.5\n",
      "6.8659177 7.5 2.5\n",
      "7.2153535 7.5 2.5\n",
      "7.247919 7.5 10.0\n",
      "7.2381372 7.5 2.5\n",
      "7.190825 7.5 7.5\n",
      "10.200215 10 10.0\n",
      "6.5469565 7.5 10.0\n",
      "7.7336664 7.5 7.5\n",
      "7.7640033 7.5 0.0\n",
      "8.036396 7.5 7.5\n",
      "8.526958 7.5 10.0\n",
      "8.39823 7.5 10.0\n",
      "7.905642 7.5 10.0\n",
      "7.771483 7.5 10.0\n",
      "7.483006 7.5 7.5\n",
      "7.0927114 7.5 5.0\n",
      "7.905081 7.5 7.5\n",
      "6.9597306 7.5 10.0\n",
      "4.8576875 5 2.5\n",
      "8.352243 7.5 7.5\n",
      "6.9372787 7.5 5.0\n",
      "8.763585 10 10.0\n",
      "6.5971627 7.5 7.5\n",
      "7.6886377 7.5 7.5\n",
      "7.7117505 7.5 10.0\n",
      "3.6574373 2.5 2.5\n",
      "7.7333417 7.5 10.0\n",
      "6.842124 7.5 7.5\n",
      "9.386593 10 7.5\n",
      "9.340504 10 10.0\n",
      "6.433352 7.5 10.0\n",
      "8.676256 7.5 10.0\n",
      "5.1865845 5 2.5\n",
      "6.8302584 7.5 7.5\n",
      "9.088181 10 10.0\n",
      "7.1308208 7.5 7.5\n",
      "8.301636 7.5 2.5\n",
      "6.832227 7.5 7.5\n",
      "7.071866 7.5 10.0\n",
      "7.1162558 7.5 7.5\n",
      "7.3441596 7.5 7.5\n",
      "7.6289315 7.5 10.0\n",
      "8.030636 7.5 7.5\n",
      "8.812709 10 10.0\n",
      "7.601276 7.5 7.5\n",
      "7.531294 7.5 7.5\n",
      "8.5161 7.5 10.0\n",
      "7.8374043 7.5 5.0\n",
      "8.760788 10 7.5\n",
      "8.213942 7.5 10.0\n",
      "8.396549 7.5 10.0\n",
      "7.1626964 7.5 10.0\n",
      "9.1387615 10 10.0\n",
      "6.1683393 5 7.5\n",
      "8.980715 10 7.5\n",
      "7.755455 7.5 7.5\n",
      "8.587836 7.5 7.5\n",
      "7.688729 7.5 7.5\n",
      "8.571337 7.5 10.0\n",
      "7.275127 7.5 5.0\n",
      "6.9928136 7.5 7.5\n",
      "7.8500066 7.5 10.0\n",
      "8.157331 7.5 7.5\n",
      "8.90799 10 10.0\n",
      "7.009151 7.5 5.0\n",
      "6.3796782 7.5 2.5\n",
      "7.971824 7.5 7.5\n",
      "7.4151106 7.5 10.0\n",
      "6.0447593 5 7.5\n",
      "7.499411 7.5 7.5\n",
      "9.268566 10 7.5\n",
      "9.811992 10 10.0\n",
      "6.811767 7.5 7.5\n",
      "8.686019 7.5 7.5\n",
      "7.7176733 7.5 7.5\n",
      "8.8081455 10 10.0\n",
      "7.136611 7.5 5.0\n",
      "3.5212393 2.5 2.5\n",
      "7.2362223 7.5 7.5\n",
      "7.2695537 7.5 7.5\n",
      "7.3856254 7.5 7.5\n",
      "7.735018 7.5 10.0\n",
      "5.92856 5 0.0\n",
      "6.5153613 7.5 10.0\n",
      "7.7499266 7.5 10.0\n",
      "9.031276 10 10.0\n",
      "5.66629 5 10.0\n",
      "9.140575 10 5.0\n",
      "9.284374 10 10.0\n",
      "9.2049885 10 10.0\n",
      "8.137038 7.5 7.5\n",
      "5.0320044 5 2.5\n",
      "8.861934 10 2.5\n",
      "8.73337 7.5 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.795179 5 2.5\n",
      "8.171051 7.5 5.0\n",
      "5.4485793 5 2.5\n",
      "6.559353 7.5 10.0\n",
      "8.21508 7.5 5.0\n",
      "8.887403 10 10.0\n",
      "6.473309 7.5 5.0\n",
      "9.495146 10 10.0\n",
      "6.067431 5 7.5\n",
      "6.878742 7.5 7.5\n",
      "7.1737523 7.5 5.0\n",
      "7.470629 7.5 7.5\n",
      "7.115641 7.5 0.0\n",
      "5.6777554 5 5.0\n",
      "5.8339877 5 2.5\n",
      "7.111055 7.5 7.5\n",
      "6.7236257 7.5 10.0\n",
      "7.230857 7.5 2.5\n",
      "6.8952537 7.5 5.0\n",
      "7.876106 7.5 10.0\n",
      "9.333084 10 7.5\n",
      "6.7052875 7.5 10.0\n",
      "8.9069605 10 7.5\n",
      "9.08294 10 10.0\n",
      "8.777982 10 10.0\n",
      "8.99087 10 10.0\n",
      "7.303084 7.5 10.0\n",
      "7.020656 7.5 7.5\n",
      "5.3853273 5 5.0\n",
      "8.794083 10 10.0\n",
      "8.935527 10 10.0\n",
      "7.2178936 7.5 7.5\n",
      "8.520957 7.5 5.0\n",
      "7.0320234 7.5 2.5\n",
      "8.815841 10 7.5\n",
      "9.146775 10 10.0\n",
      "9.14814 10 10.0\n",
      "6.1299076 5 0.0\n",
      "8.279397 7.5 7.5\n",
      "8.929781 10 10.0\n",
      "7.00511 7.5 10.0\n",
      "7.3344545 7.5 10.0\n",
      "7.4628363 7.5 10.0\n",
      "6.5345902 7.5 5.0\n",
      "7.4571605 7.5 7.5\n",
      "5.4562893 5 7.5\n",
      "8.557975 7.5 7.5\n",
      "7.588536 7.5 7.5\n",
      "8.936083 10 10.0\n",
      "7.102791 7.5 5.0\n",
      "8.20962 7.5 10.0\n",
      "7.629561 7.5 10.0\n",
      "6.944566 7.5 5.0\n",
      "7.9404235 7.5 7.5\n",
      "6.6885858 7.5 7.5\n",
      "7.023529 7.5 7.5\n",
      "5.356553 5 2.5\n",
      "9.079288 10 10.0\n",
      "7.165941 7.5 7.5\n",
      "9.04088 10 10.0\n",
      "9.113746 10 10.0\n",
      "9.0373535 10 10.0\n",
      "9.040439 10 10.0\n",
      "7.365515 7.5 10.0\n",
      "7.936763 7.5 7.5\n",
      "5.763829 5 10.0\n",
      "5.2984686 5 2.5\n",
      "6.552891 7.5 2.5\n",
      "7.4260426 7.5 10.0\n",
      "9.222185 10 10.0\n",
      "9.180019 10 10.0\n",
      "6.540282 7.5 5.0\n",
      "7.7624674 7.5 7.5\n",
      "8.782645 10 10.0\n",
      "6.4901967 7.5 5.0\n",
      "6.573381 7.5 7.5\n",
      "6.1251035 5 7.5\n",
      "6.5539117 7.5 5.0\n",
      "7.323544 7.5 7.5\n",
      "7.247866 7.5 10.0\n",
      "9.540761 10 10.0\n",
      "7.534303 7.5 10.0\n",
      "8.647705 7.5 7.5\n",
      "8.689438 7.5 7.5\n",
      "8.94824 10 10.0\n",
      "8.095862 7.5 7.5\n",
      "8.199267 7.5 10.0\n",
      "7.4479475 7.5 7.5\n",
      "7.380012 7.5 7.5\n",
      "8.578756 7.5 7.5\n",
      "5.8299794 5 7.5\n",
      "7.6269054 7.5 7.5\n",
      "4.930387 5 7.5\n",
      "7.394697 7.5 7.5\n",
      "8.052896 7.5 10.0\n",
      "8.554947 7.5 7.5\n",
      "6.8885937 7.5 2.5\n",
      "6.013335 5 0.0\n",
      "8.628763 7.5 10.0\n",
      "7.947933 7.5 2.5\n",
      "7.540949 7.5 10.0\n",
      "8.549387 7.5 10.0\n",
      "7.0716825 7.5 7.5\n",
      "6.194329 5 7.5\n",
      "8.15847 7.5 10.0\n",
      "8.958982 10 10.0\n",
      "6.314321 7.5 10.0\n",
      "8.024106 7.5 7.5\n",
      "5.053256 5 7.5\n",
      "7.574957 7.5 10.0\n",
      "6.4917235 7.5 7.5\n",
      "5.65777 5 2.5\n",
      "8.955595 10 10.0\n",
      "8.564895 7.5 7.5\n",
      "7.3967366 7.5 10.0\n",
      "8.607742 7.5 10.0\n",
      "7.449849 7.5 10.0\n",
      "5.07259 5 7.5\n",
      "8.876394 10 10.0\n",
      "7.397967 7.5 5.0\n",
      "8.744714 7.5 10.0\n",
      "7.060741 7.5 7.5\n",
      "7.575723 7.5 7.5\n",
      "7.545907 7.5 7.5\n",
      "7.2055926 7.5 7.5\n",
      "6.738225 7.5 2.5\n",
      "8.813459 10 7.5\n",
      "8.636903 7.5 10.0\n",
      "8.286764 7.5 10.0\n",
      "8.45381 7.5 7.5\n",
      "6.513028 7.5 7.5\n",
      "6.888366 7.5 5.0\n",
      "6.7437277 7.5 2.5\n",
      "6.4264693 7.5 10.0\n",
      "7.00082 7.5 7.5\n",
      "9.14108 10 10.0\n",
      "6.7400637 7.5 7.5\n",
      "7.07835 7.5 10.0\n",
      "7.025781 7.5 5.0\n",
      "6.122841 5 10.0\n",
      "9.032209 10 10.0\n",
      "8.63817 7.5 10.0\n",
      "7.751196 7.5 7.5\n",
      "8.132216 7.5 10.0\n",
      "8.345111 7.5 10.0\n",
      "7.2409096 7.5 10.0\n",
      "7.7641215 7.5 5.0\n",
      "8.930135 10 10.0\n",
      "6.8128047 7.5 7.5\n",
      "7.1406965 7.5 5.0\n",
      "9.445401 10 10.0\n",
      "6.9769707 7.5 10.0\n",
      "9.237422 10 10.0\n",
      "9.022806 10 10.0\n",
      "7.376457 7.5 10.0\n",
      "8.7632065 10 7.5\n",
      "7.676879 7.5 10.0\n",
      "7.5422735 7.5 10.0\n",
      "6.6136656 7.5 7.5\n",
      "6.820296 7.5 7.5\n",
      "8.773305 10 10.0\n",
      "7.4537106 7.5 2.5\n",
      "9.2694235 10 10.0\n",
      "7.744934 7.5 7.5\n",
      "7.586595 7.5 7.5\n",
      "6.404155 7.5 7.5\n",
      "7.824445 7.5 5.0\n",
      "7.232497 7.5 7.5\n",
      "7.2573013 7.5 0.0\n",
      "7.260645 7.5 2.5\n",
      "7.3987403 7.5 7.5\n",
      "7.8917127 7.5 2.5\n",
      "8.92565 10 10.0\n",
      "9.225636 10 5.0\n",
      "8.712306 7.5 10.0\n",
      "8.084717 7.5 7.5\n",
      "5.4848557 5 2.5\n",
      "6.5518064 7.5 2.5\n",
      "8.447678 7.5 7.5\n",
      "6.9655123 7.5 10.0\n",
      "7.4844613 7.5 5.0\n",
      "8.421961 7.5 10.0\n",
      "8.54448 7.5 7.5\n",
      "7.166653 7.5 7.5\n",
      "6.6840625 7.5 10.0\n",
      "7.5627832 7.5 10.0\n",
      "4.9222913 5 2.5\n",
      "8.803404 10 10.0\n",
      "3.5585673 2.5 5.0\n",
      "8.090763 7.5 10.0\n",
      "7.197181 7.5 7.5\n",
      "7.9986105 7.5 10.0\n",
      "7.605664 7.5 10.0\n",
      "5.9690204 5 10.0\n",
      "8.735226 7.5 7.5\n",
      "6.712805 7.5 7.5\n",
      "7.831993 7.5 10.0\n",
      "9.282228 10 10.0\n",
      "8.583235 7.5 7.5\n",
      "7.603235 7.5 7.5\n",
      "8.822308 10 7.5\n",
      "7.950333 7.5 5.0\n",
      "7.733588 7.5 7.5\n",
      "7.612208 7.5 7.5\n",
      "8.970288 10 7.5\n",
      "7.5020623 7.5 10.0\n",
      "7.3014565 7.5 2.5\n",
      "7.3953776 7.5 10.0\n",
      "6.0299373 5 2.5\n",
      "8.762857 10 7.5\n",
      "6.8085504 7.5 10.0\n",
      "8.402221 7.5 7.5\n",
      "6.962987 7.5 7.5\n",
      "7.5777607 7.5 7.5\n",
      "7.6539173 7.5 7.5\n",
      "6.9473543 7.5 7.5\n",
      "8.871499 10 10.0\n",
      "8.632639 7.5 10.0\n",
      "6.6380157 7.5 7.5\n",
      "5.424932 5 0.0\n",
      "7.31108 7.5 7.5\n",
      "6.5554976 7.5 7.5\n",
      "8.790182 10 7.5\n",
      "9.272254 10 10.0\n",
      "7.0529423 7.5 7.5\n",
      "7.143752 7.5 2.5\n",
      "7.236778 7.5 7.5\n",
      "8.189236 7.5 10.0\n",
      "5.593506 5 5.0\n",
      "7.0223684 7.5 7.5\n",
      "5.939659 5 2.5\n",
      "7.982329 7.5 2.5\n",
      "7.470095 7.5 7.5\n",
      "6.68159 7.5 10.0\n",
      "7.380261 7.5 7.5\n",
      "8.832326 10 10.0\n",
      "6.773444 7.5 5.0\n",
      "6.8262787 7.5 2.5\n",
      "6.738958 7.5 7.5\n",
      "6.9315753 7.5 2.5\n",
      "7.938725 7.5 7.5\n",
      "7.5798883 7.5 10.0\n",
      "7.113123 7.5 2.5\n",
      "7.575845 7.5 10.0\n",
      "8.766823 10 7.5\n",
      "9.478572 10 10.0\n",
      "6.410552 7.5 5.0\n",
      "7.6727724 7.5 7.5\n",
      "6.707111 7.5 7.5\n",
      "7.7603555 7.5 10.0\n",
      "7.3331995 7.5 7.5\n",
      "7.392276 7.5 10.0\n",
      "7.734407 7.5 10.0\n",
      "8.350414 7.5 7.5\n",
      "8.780409 10 7.5\n",
      "9.288985 10 10.0\n",
      "7.6241884 7.5 10.0\n",
      "8.848245 10 10.0\n",
      "7.121177 7.5 7.5\n",
      "9.181227 10 10.0\n",
      "7.564501 7.5 10.0\n",
      "8.4676285 7.5 10.0\n",
      "6.508122 7.5 7.5\n",
      "7.3495307 7.5 7.5\n",
      "7.8854747 7.5 10.0\n",
      "9.050826 10 10.0\n",
      "7.4045124 7.5 7.5\n",
      "6.5935645 7.5 2.5\n",
      "8.3751745 7.5 7.5\n",
      "9.151305 10 7.5\n",
      "8.780131 10 10.0\n",
      "7.6999984 7.5 5.0\n",
      "5.535413 5 10.0\n",
      "8.099703 7.5 10.0\n",
      "7.2799983 7.5 10.0\n",
      "7.5637827 7.5 5.0\n",
      "6.69554 7.5 10.0\n",
      "8.014756 7.5 7.5\n",
      "5.6018634 5 5.0\n",
      "5.8502812 5 10.0\n",
      "7.660278 7.5 10.0\n",
      "6.363688 7.5 7.5\n",
      "7.16239 7.5 2.5\n",
      "8.888669 10 10.0\n",
      "8.793113 10 7.5\n",
      "5.2504034 5 2.5\n",
      "7.7403865 7.5 10.0\n",
      "7.2918777 7.5 5.0\n",
      "8.890551 10 7.5\n",
      "6.0898294 5 7.5\n",
      "7.0753913 7.5 7.5\n",
      "6.7912726 7.5 10.0\n",
      "6.2981052 7.5 5.0\n",
      "7.498666 7.5 10.0\n",
      "7.287884 7.5 7.5\n",
      "7.5241075 7.5 0.0\n",
      "6.6154714 7.5 2.5\n",
      "7.8933024 7.5 10.0\n",
      "7.555913 7.5 10.0\n",
      "6.595496 7.5 2.5\n",
      "8.42863 7.5 7.5\n",
      "7.307203 7.5 5.0\n",
      "7.184511 7.5 0.0\n",
      "7.0012555 7.5 10.0\n",
      "7.479455 7.5 10.0\n",
      "6.9161158 7.5 7.5\n",
      "8.029268 7.5 5.0\n",
      "8.731306 7.5 10.0\n",
      "6.884422 7.5 10.0\n",
      "6.532835 7.5 7.5\n",
      "6.432507 7.5 7.5\n",
      "9.07966 10 10.0\n",
      "7.604865 7.5 10.0\n",
      "8.08231 7.5 10.0\n",
      "6.9609394 7.5 10.0\n",
      "9.161975 10 10.0\n",
      "7.1567783 7.5 10.0\n",
      "7.4081416 7.5 7.5\n",
      "9.139743 10 10.0\n",
      "8.521601 7.5 7.5\n",
      "7.290606 7.5 7.5\n",
      "5.186452 5 2.5\n",
      "8.407731 7.5 7.5\n",
      "6.79906 7.5 7.5\n",
      "6.202064 5 10.0\n",
      "8.942495 10 10.0\n",
      "7.8363967 7.5 7.5\n",
      "9.117894 10 7.5\n",
      "7.0929956 7.5 2.5\n",
      "7.58046 7.5 5.0\n",
      "6.639838 7.5 2.5\n",
      "7.6985745 7.5 7.5\n",
      "8.985766 10 10.0\n",
      "8.577229 7.5 5.0\n",
      "7.324442 7.5 7.5\n",
      "8.544062 7.5 5.0\n",
      "8.827666 10 10.0\n",
      "6.444445 7.5 10.0\n",
      "9.051476 10 10.0\n",
      "7.9380655 7.5 10.0\n",
      "7.4969687 7.5 5.0\n",
      "6.833603 7.5 7.5\n",
      "7.971432 7.5 7.5\n",
      "7.536485 7.5 7.5\n",
      "8.43069 7.5 5.0\n",
      "7.3821015 7.5 2.5\n",
      "5.799295 5 7.5\n",
      "8.073907 7.5 7.5\n",
      "5.60116 5 7.5\n",
      "6.549524 7.5 7.5\n",
      "7.0820284 7.5 10.0\n",
      "8.597996 7.5 7.5\n",
      "6.8750105 7.5 7.5\n",
      "8.843159 10 7.5\n",
      "7.9714055 7.5 7.5\n",
      "6.813808 7.5 2.5\n",
      "7.354239 7.5 10.0\n",
      "8.172924 7.5 2.5\n",
      "5.9640074 5 7.5\n",
      "9.345592 10 10.0\n",
      "9.310735 10 10.0\n",
      "7.7087145 7.5 10.0\n",
      "7.2377157 7.5 7.5\n",
      "5.315522 5 7.5\n",
      "5.406442 5 2.5\n",
      "8.275028 7.5 10.0\n",
      "6.9613595 7.5 10.0\n",
      "8.819082 10 10.0\n",
      "7.230734 7.5 10.0\n",
      "5.4223123 5 7.5\n",
      "6.5875525 7.5 10.0\n",
      "9.070607 10 7.5\n",
      "6.310473 7.5 5.0\n",
      "7.780624 7.5 2.5\n",
      "7.170576 7.5 10.0\n",
      "6.585246 7.5 5.0\n",
      "7.83606 7.5 7.5\n",
      "6.5752416 7.5 5.0\n",
      "6.531415 7.5 7.5\n",
      "6.7328267 7.5 7.5\n",
      "8.808004 10 10.0\n",
      "6.9216685 7.5 2.5\n",
      "4.927455 5 10.0\n",
      "7.271681 7.5 2.5\n",
      "8.627091 7.5 10.0\n",
      "6.8262577 7.5 7.5\n",
      "7.181028 7.5 10.0\n",
      "6.819683 7.5 7.5\n",
      "7.0804667 7.5 7.5\n",
      "7.1746454 7.5 7.5\n",
      "6.605191 7.5 7.5\n",
      "8.671727 7.5 10.0\n",
      "8.540407 7.5 7.5\n",
      "6.381366 7.5 7.5\n",
      "9.040679 10 10.0\n",
      "7.6297555 7.5 10.0\n",
      "7.765636 7.5 7.5\n",
      "9.418956 10 10.0\n",
      "7.2643185 7.5 10.0\n",
      "7.543571 7.5 7.5\n",
      "4.5083385 5 2.5\n",
      "8.987176 10 10.0\n",
      "6.282797 7.5 10.0\n",
      "8.752212 10 7.5\n",
      "8.134048 7.5 5.0\n",
      "6.272325 7.5 7.5\n",
      "6.4707394 7.5 2.5\n",
      "8.47811 7.5 7.5\n",
      "9.198601 10 10.0\n",
      "8.891259 10 7.5\n",
      "7.4879937 7.5 2.5\n",
      "8.307059 7.5 7.5\n",
      "8.559082 7.5 7.5\n",
      "5.9692698 5 0.0\n",
      "7.7506266 7.5 5.0\n",
      "7.448652 7.5 7.5\n",
      "7.338175 7.5 7.5\n",
      "7.816957 7.5 10.0\n",
      "6.2678604 7.5 10.0\n",
      "7.2281046 7.5 7.5\n",
      "6.98469 7.5 7.5\n",
      "8.576602 7.5 7.5\n",
      "7.2163014 7.5 7.5\n",
      "7.3090806 7.5 7.5\n",
      "8.222189 7.5 10.0\n",
      "7.5153875 7.5 7.5\n",
      "8.2531595 7.5 10.0\n",
      "6.450212 7.5 7.5\n",
      "6.9856334 7.5 5.0\n",
      "8.6321125 7.5 10.0\n",
      "7.7887406 7.5 7.5\n",
      "9.742432 10 10.0\n",
      "6.501456 7.5 7.5\n",
      "7.182554 7.5 7.5\n",
      "9.5116205 10 10.0\n",
      "7.3807206 7.5 7.5\n",
      "8.575488 7.5 10.0\n",
      "9.038429 10 7.5\n",
      "9.080168 10 10.0\n",
      "7.048025 7.5 7.5\n",
      "6.602903 7.5 5.0\n",
      "7.9332724 7.5 10.0\n",
      "7.8160176 7.5 7.5\n",
      "7.9278636 7.5 10.0\n",
      "7.3710523 7.5 5.0\n",
      "8.86883 10 7.5\n",
      "8.946785 10 10.0\n",
      "5.2464566 5 2.5\n",
      "9.305518 10 7.5\n",
      "7.804692 7.5 10.0\n",
      "6.3784103 7.5 7.5\n",
      "9.54782 10 7.5\n",
      "7.4317656 7.5 7.5\n",
      "6.901681 7.5 7.5\n",
      "7.3965397 7.5 7.5\n",
      "4.2099056 5 2.5\n",
      "5.702581 5 10.0\n",
      "6.514368 7.5 7.5\n",
      "7.0762715 7.5 2.5\n",
      "8.334358 7.5 7.5\n",
      "7.3036222 7.5 10.0\n",
      "6.4931464 7.5 7.5\n",
      "6.416714 7.5 5.0\n",
      "8.737952 7.5 7.5\n",
      "5.6974754 5 2.5\n",
      "7.534326 7.5 7.5\n",
      "7.9984493 7.5 2.5\n",
      "7.301328 7.5 7.5\n",
      "7.6245074 7.5 10.0\n",
      "6.631763 7.5 2.5\n",
      "5.8321214 5 10.0\n",
      "9.06773 10 10.0\n",
      "8.647634 7.5 7.5\n",
      "6.249001 5 2.5\n",
      "7.668551 7.5 2.5\n",
      "5.7010255 5 2.5\n",
      "8.953619 10 10.0\n",
      "6.2180176 5 10.0\n",
      "7.3723426 7.5 10.0\n",
      "6.8781543 7.5 7.5\n",
      "7.8162885 7.5 10.0\n",
      "6.6770473 7.5 7.5\n",
      "6.7807345 7.5 7.5\n",
      "8.368383 7.5 10.0\n",
      "8.977012 10 7.5\n",
      "7.5830326 7.5 7.5\n",
      "7.2363696 7.5 2.5\n",
      "7.1309705 7.5 5.0\n",
      "9.395374 10 10.0\n",
      "8.418922 7.5 7.5\n",
      "7.5338683 7.5 10.0\n",
      "6.6314735 7.5 7.5\n",
      "7.156119 7.5 10.0\n",
      "4.632284 5 7.5\n",
      "7.8378553 7.5 7.5\n",
      "7.7962084 7.5 7.5\n",
      "6.6233783 7.5 2.5\n",
      "6.3846226 7.5 10.0\n",
      "9.125645 10 10.0\n",
      "9.478191 10 10.0\n",
      "7.3396754 7.5 10.0\n",
      "8.340441 7.5 7.5\n",
      "7.2170515 7.5 10.0\n",
      "8.068691 7.5 7.5\n",
      "7.6339335 7.5 10.0\n",
      "7.729588 7.5 5.0\n",
      "7.6988664 7.5 5.0\n",
      "6.897742 7.5 7.5\n",
      "7.693759 7.5 10.0\n",
      "7.8304935 7.5 7.5\n",
      "8.542388 7.5 10.0\n",
      "8.798858 10 10.0\n",
      "8.561046 7.5 7.5\n",
      "6.3286815 7.5 5.0\n",
      "8.455389 7.5 10.0\n",
      "7.117511 7.5 7.5\n",
      "8.982763 10 10.0\n",
      "7.577491 7.5 10.0\n",
      "9.262005 10 7.5\n",
      "6.569786 7.5 7.5\n",
      "7.406586 7.5 10.0\n",
      "8.255782 7.5 5.0\n",
      "7.5876536 7.5 10.0\n",
      "9.059542 10 10.0\n",
      "9.005013 10 7.5\n",
      "7.9841666 7.5 5.0\n",
      "6.2209425 5 10.0\n",
      "8.255762 7.5 10.0\n",
      "6.9165416 7.5 7.5\n",
      "6.933199 7.5 10.0\n",
      "6.7013674 7.5 10.0\n",
      "7.101739 7.5 5.0\n",
      "8.727008 7.5 10.0\n",
      "6.9873323 7.5 7.5\n",
      "7.4176683 7.5 5.0\n",
      "8.71631 7.5 7.5\n",
      "9.447727 10 10.0\n",
      "9.106267 10 10.0\n",
      "7.467645 7.5 7.5\n",
      "8.583505 7.5 7.5\n",
      "7.940151 7.5 10.0\n",
      "8.2465105 7.5 7.5\n",
      "9.016502 10 7.5\n",
      "7.649454 7.5 10.0\n",
      "7.549582 7.5 10.0\n",
      "9.270515 10 7.5\n",
      "4.552969 5 0.0\n",
      "7.605285 7.5 5.0\n",
      "6.70693 7.5 2.5\n",
      "8.519252 7.5 10.0\n",
      "7.751408 7.5 10.0\n",
      "6.514062 7.5 5.0\n",
      "8.626833 7.5 7.5\n",
      "8.701287 7.5 10.0\n",
      "6.390295 7.5 5.0\n",
      "6.985173 7.5 7.5\n",
      "6.9405117 7.5 7.5\n",
      "7.7030587 7.5 2.5\n",
      "7.601935 7.5 7.5\n",
      "7.380377 7.5 10.0\n",
      "7.207549 7.5 5.0\n",
      "5.2560205 5 2.5\n",
      "8.865373 10 7.5\n",
      "7.959296 7.5 7.5\n",
      "8.459663 7.5 10.0\n",
      "7.6938925 7.5 5.0\n",
      "7.7472315 7.5 10.0\n",
      "8.166938 7.5 5.0\n",
      "6.3575034 7.5 7.5\n",
      "7.2995877 7.5 7.5\n",
      "8.310004 7.5 5.0\n",
      "9.675833 10 10.0\n",
      "8.481352 7.5 7.5\n",
      "7.701749 7.5 7.5\n",
      "7.2444715 7.5 7.5\n",
      "7.163082 7.5 2.5\n",
      "8.7460985 7.5 7.5\n",
      "6.332188 7.5 10.0\n",
      "7.695487 7.5 7.5\n",
      "8.956744 10 7.5\n",
      "6.0311384 5 7.5\n",
      "6.792069 7.5 5.0\n",
      "5.2646055 5 2.5\n",
      "4.8947 5 2.5\n",
      "8.391121 7.5 7.5\n",
      "7.781183 7.5 10.0\n",
      "8.387264 7.5 5.0\n",
      "7.512713 7.5 5.0\n",
      "6.6981516 7.5 5.0\n",
      "7.2297783 7.5 7.5\n",
      "7.3083534 7.5 7.5\n",
      "3.7569492 5 2.5\n",
      "6.580185 7.5 7.5\n",
      "7.0869474 7.5 7.5\n",
      "8.044603 7.5 10.0\n",
      "6.600531 7.5 7.5\n",
      "8.699702 7.5 10.0\n",
      "7.774529 7.5 5.0\n",
      "6.686033 7.5 2.5\n",
      "7.706295 7.5 10.0\n",
      "7.245576 7.5 10.0\n",
      "7.6629405 7.5 7.5\n",
      "5.437481 5 5.0\n",
      "8.486286 7.5 7.5\n",
      "7.341423 7.5 7.5\n",
      "7.244211 7.5 10.0\n",
      "8.795363 10 10.0\n",
      "7.7861633 7.5 10.0\n",
      "8.75372 10 10.0\n",
      "4.447223 5 2.5\n",
      "8.098503 7.5 10.0\n",
      "8.214169 7.5 7.5\n",
      "7.165618 7.5 2.5\n",
      "6.6332064 7.5 5.0\n",
      "6.7120156 7.5 7.5\n",
      "7.2642407 7.5 5.0\n",
      "6.988785 7.5 5.0\n",
      "5.4750347 5 7.5\n",
      "7.777383 7.5 7.5\n",
      "8.971156 10 7.5\n",
      "8.806214 10 7.5\n",
      "8.319092 7.5 10.0\n",
      "7.9334025 7.5 7.5\n",
      "8.744163 7.5 7.5\n",
      "6.205485 5 7.5\n",
      "7.7057076 7.5 7.5\n",
      "9.111185 10 0.0\n",
      "8.613579 7.5 7.5\n",
      "6.9350934 7.5 5.0\n",
      "6.9429216 7.5 5.0\n",
      "6.798795 7.5 7.5\n",
      "8.676356 7.5 10.0\n",
      "8.751474 10 10.0\n",
      "4.9838586 5 0.0\n",
      "7.687613 7.5 10.0\n",
      "8.854778 10 7.5\n",
      "7.957039 7.5 5.0\n",
      "6.9394145 7.5 7.5\n",
      "8.237345 7.5 10.0\n",
      "7.3617816 7.5 10.0\n",
      "8.576541 7.5 10.0\n",
      "7.156694 7.5 7.5\n",
      "9.571813 10 10.0\n",
      "7.175396 7.5 5.0\n",
      "7.095522 7.5 10.0\n",
      "7.673754 7.5 7.5\n",
      "6.612209 7.5 7.5\n",
      "7.0314493 7.5 7.5\n",
      "6.6542187 7.5 2.5\n",
      "6.0832415 5 5.0\n",
      "8.326136 7.5 7.5\n",
      "9.324812 10 10.0\n",
      "7.313712 7.5 7.5\n",
      "6.1933355 5 2.5\n",
      "7.461219 7.5 5.0\n",
      "8.992753 10 10.0\n",
      "6.2270217 5 2.5\n",
      "6.379108 7.5 7.5\n",
      "8.720922 7.5 10.0\n",
      "6.4751725 7.5 5.0\n",
      "6.4918175 7.5 7.5\n",
      "6.598204 7.5 7.5\n",
      "8.401873 7.5 7.5\n",
      "6.512863 7.5 5.0\n",
      "7.435588 7.5 10.0\n",
      "6.938879 7.5 10.0\n",
      "6.4807773 7.5 5.0\n",
      "7.206088 7.5 7.5\n",
      "5.669739 5 7.5\n",
      "6.9036975 7.5 7.5\n",
      "9.766813 10 10.0\n",
      "5.915247 5 2.5\n",
      "6.511838 7.5 0.0\n",
      "6.8798976 7.5 7.5\n",
      "4.0228643 5 7.5\n",
      "8.412083 7.5 10.0\n",
      "6.883768 7.5 10.0\n",
      "7.151635 7.5 7.5\n",
      "8.786153 10 7.5\n",
      "8.576738 7.5 7.5\n",
      "8.997942 10 10.0\n",
      "7.5907836 7.5 7.5\n",
      "4.9446144 5 5.0\n",
      "8.61695 7.5 7.5\n",
      "8.100332 7.5 10.0\n",
      "7.7605987 7.5 10.0\n",
      "7.419445 7.5 7.5\n",
      "8.319029 7.5 7.5\n",
      "9.376163 10 10.0\n",
      "8.933031 10 7.5\n",
      "7.2321033 7.5 7.5\n",
      "6.378215 7.5 7.5\n",
      "6.398544 7.5 10.0\n",
      "7.2348213 7.5 7.5\n",
      "6.0665336 5 7.5\n",
      "7.6436553 7.5 5.0\n",
      "6.4242477 7.5 7.5\n",
      "6.5864177 7.5 7.5\n",
      "6.9929976 7.5 2.5\n",
      "7.4308586 7.5 7.5\n",
      "7.5122366 7.5 0.0\n",
      "8.338272 7.5 10.0\n",
      "7.1991534 7.5 7.5\n",
      "9.292533 10 7.5\n",
      "9.265516 10 7.5\n",
      "9.265324 10 10.0\n",
      "9.279284 10 10.0\n",
      "8.923593 10 10.0\n",
      "6.752211 7.5 5.0\n",
      "9.663937 10 10.0\n",
      "8.513506 7.5 7.5\n",
      "7.260325 7.5 7.5\n",
      "8.810713 10 7.5\n",
      "4.8796697 5 2.5\n",
      "7.3917603 7.5 10.0\n",
      "8.993802 10 10.0\n",
      "8.011976 7.5 10.0\n",
      "7.286121 7.5 5.0\n",
      "7.5255103 7.5 10.0\n",
      "9.275547 10 5.0\n",
      "7.3426614 7.5 7.5\n",
      "8.989453 10 7.5\n",
      "7.8295655 7.5 7.5\n",
      "7.0525703 7.5 2.5\n",
      "6.0915527 5 7.5\n",
      "4.912957 5 2.5\n",
      "9.574413 10 10.0\n",
      "6.402634 7.5 7.5\n",
      "9.079139 10 7.5\n",
      "7.740183 7.5 5.0\n",
      "7.620727 7.5 10.0\n",
      "8.095327 7.5 7.5\n",
      "9.134417 10 10.0\n",
      "7.545144 7.5 10.0\n",
      "7.1886134 7.5 10.0\n",
      "8.670951 7.5 10.0\n",
      "7.4531302 7.5 5.0\n",
      "7.1803293 7.5 7.5\n",
      "6.865906 7.5 5.0\n",
      "5.2394466 5 7.5\n",
      "6.990627 7.5 7.5\n",
      "6.317846 7.5 5.0\n",
      "7.521504 7.5 5.0\n",
      "8.356823 7.5 10.0\n",
      "7.337122 7.5 5.0\n",
      "6.9681034 7.5 7.5\n",
      "8.132064 7.5 10.0\n",
      "7.20198 7.5 10.0\n",
      "7.2596145 7.5 5.0\n",
      "6.8938975 7.5 7.5\n",
      "8.849633 10 7.5\n",
      "5.2152276 5 2.5\n",
      "7.1922903 7.5 7.5\n",
      "5.925305 5 5.0\n",
      "8.83126 10 10.0\n",
      "8.037479 7.5 7.5\n",
      "7.42992 7.5 7.5\n",
      "8.1327305 7.5 10.0\n",
      "7.892463 7.5 10.0\n",
      "6.946012 7.5 10.0\n",
      "7.1389556 7.5 10.0\n",
      "9.1234455 10 10.0\n",
      "7.071132 7.5 2.5\n",
      "7.69124 7.5 7.5\n",
      "7.291709 7.5 7.5\n",
      "7.9747124 7.5 10.0\n",
      "6.6424527 7.5 7.5\n",
      "8.618468 7.5 5.0\n",
      "7.699234 7.5 7.5\n",
      "6.5376515 7.5 7.5\n",
      "7.7759223 7.5 7.5\n",
      "7.5235915 7.5 7.5\n",
      "7.37816 7.5 7.5\n",
      "8.659096 7.5 7.5\n",
      "7.8772883 7.5 10.0\n",
      "7.325911 7.5 7.5\n",
      "2.848714 2.5 0.0\n",
      "6.7180777 7.5 5.0\n",
      "8.414538 7.5 7.5\n",
      "6.953184 7.5 5.0\n",
      "5.395814 5 2.5\n",
      "7.5803337 7.5 10.0\n",
      "9.489346 10 7.5\n",
      "8.6335335 7.5 10.0\n",
      "7.9350557 7.5 7.5\n",
      "9.432738 10 10.0\n",
      "6.423227 7.5 2.5\n",
      "8.856326 10 10.0\n",
      "7.8391647 7.5 10.0\n",
      "8.914419 10 10.0\n",
      "7.756202 7.5 10.0\n",
      "8.731067 7.5 5.0\n",
      "8.860134 10 7.5\n",
      "7.8849535 7.5 7.5\n",
      "9.06101 10 10.0\n",
      "8.809544 10 10.0\n",
      "7.3787103 7.5 10.0\n",
      "6.9704385 7.5 7.5\n",
      "7.158867 7.5 10.0\n",
      "5.0284066 5 2.5\n",
      "8.663938 7.5 10.0\n",
      "8.108798 7.5 7.5\n",
      "8.541402 7.5 2.5\n",
      "8.541363 7.5 10.0\n",
      "7.1693697 7.5 7.5\n",
      "7.4652405 7.5 10.0\n",
      "7.9994063 7.5 10.0\n",
      "7.520384 7.5 7.5\n",
      "6.370214 7.5 2.5\n",
      "7.507338 7.5 0.0\n",
      "8.412423 7.5 10.0\n",
      "3.2681868 2.5 2.5\n",
      "7.138706 7.5 7.5\n",
      "8.925926 10 10.0\n",
      "8.697322 7.5 10.0\n",
      "7.9604325 7.5 10.0\n",
      "8.204713 7.5 2.5\n",
      "8.400347 7.5 7.5\n",
      "6.3788147 7.5 7.5\n",
      "7.306433 7.5 7.5\n",
      "7.764073 7.5 5.0\n",
      "5.8734336 5 7.5\n",
      "6.4721055 7.5 2.5\n",
      "7.0267596 7.5 7.5\n",
      "7.4443154 7.5 10.0\n",
      "7.105748 7.5 5.0\n",
      "6.749915 7.5 7.5\n",
      "6.4740024 7.5 7.5\n",
      "8.486832 7.5 10.0\n",
      "6.4215064 7.5 10.0\n",
      "7.074429 7.5 5.0\n",
      "9.22484 10 10.0\n",
      "4.1694484 5 2.5\n",
      "7.288771 7.5 7.5\n",
      "7.4001155 7.5 5.0\n",
      "7.3550854 7.5 7.5\n",
      "8.675209 7.5 10.0\n",
      "7.4599094 7.5 5.0\n",
      "7.4428554 7.5 7.5\n",
      "7.153505 7.5 7.5\n",
      "7.4663324 7.5 10.0\n",
      "7.890716 7.5 2.5\n",
      "9.152111 10 10.0\n",
      "9.179613 10 10.0\n",
      "8.499989 7.5 10.0\n",
      "6.978427 7.5 2.5\n",
      "8.882984 10 7.5\n",
      "9.803037 10 5.0\n",
      "7.5173397 7.5 10.0\n",
      "7.946553 7.5 10.0\n",
      "5.157532 5 2.5\n",
      "8.385147 7.5 7.5\n",
      "6.8091373 7.5 7.5\n",
      "9.738599 10 10.0\n",
      "8.577357 7.5 10.0\n",
      "7.6354556 7.5 7.5\n",
      "7.944271 7.5 7.5\n",
      "7.8088984 7.5 7.5\n",
      "6.711192 7.5 5.0\n",
      "9.181415 10 10.0\n",
      "8.345118 7.5 10.0\n",
      "7.464939 7.5 2.5\n",
      "9.017062 10 10.0\n",
      "3.4188087 2.5 0.0\n",
      "8.990631 10 10.0\n",
      "6.8886046 7.5 10.0\n",
      "5.5455594 5 7.5\n",
      "5.849814 5 7.5\n",
      "6.8834105 7.5 0.0\n",
      "9.077557 10 10.0\n",
      "7.7458606 7.5 7.5\n",
      "8.170761 7.5 7.5\n",
      "4.5359063 5 2.5\n",
      "7.4548306 7.5 7.5\n",
      "7.4947147 7.5 10.0\n",
      "8.942481 10 7.5\n",
      "7.2921114 7.5 7.5\n",
      "9.10942 10 10.0\n",
      "6.4626794 7.5 7.5\n",
      "7.2657614 7.5 7.5\n",
      "7.692549 7.5 7.5\n",
      "7.803355 7.5 10.0\n",
      "6.7984285 7.5 5.0\n",
      "3.8623085 5 7.5\n",
      "8.608974 7.5 10.0\n",
      "8.99698 10 10.0\n",
      "6.342052 7.5 10.0\n",
      "7.0033474 7.5 7.5\n",
      "7.2271075 7.5 5.0\n",
      "8.703488 7.5 7.5\n",
      "7.881562 7.5 7.5\n",
      "8.665552 7.5 10.0\n",
      "7.053925 7.5 10.0\n",
      "7.779216 7.5 7.5\n",
      "5.0165305 5 10.0\n",
      "7.631777 7.5 10.0\n",
      "7.155921 7.5 10.0\n",
      "7.2695866 7.5 7.5\n",
      "7.0282784 7.5 7.5\n",
      "8.904624 10 7.5\n",
      "8.660762 7.5 5.0\n",
      "7.398917 7.5 7.5\n",
      "8.270994 7.5 7.5\n",
      "7.796476 7.5 7.5\n",
      "8.634703 7.5 10.0\n",
      "8.86881 10 10.0\n",
      "7.062053 7.5 10.0\n",
      "8.940746 10 10.0\n",
      "8.315051 7.5 10.0\n",
      "7.662619 7.5 10.0\n",
      "8.663633 7.5 10.0\n",
      "7.4767423 7.5 7.5\n",
      "7.2762866 7.5 7.5\n",
      "5.3332033 5 2.5\n",
      "6.442603 7.5 7.5\n",
      "8.949857 10 7.5\n",
      "7.00041 7.5 10.0\n",
      "4.3921757 5 0.0\n",
      "9.298478 10 10.0\n",
      "7.939052 7.5 5.0\n",
      "7.8926616 7.5 10.0\n",
      "7.360098 7.5 5.0\n",
      "8.901692 10 7.5\n",
      "6.5881624 7.5 10.0\n",
      "7.6436553 7.5 5.0\n",
      "9.26612 10 10.0\n",
      "7.279023 7.5 2.5\n",
      "7.454567 7.5 5.0\n",
      "8.84128 10 10.0\n",
      "7.154193 7.5 7.5\n",
      "7.348761 7.5 10.0\n",
      "7.0509744 7.5 10.0\n",
      "7.4109974 7.5 10.0\n",
      "7.50665 7.5 10.0\n",
      "7.6811013 7.5 10.0\n",
      "7.7428393 7.5 7.5\n",
      "9.00808 10 10.0\n",
      "7.262486 7.5 10.0\n",
      "8.888634 10 7.5\n",
      "7.2414865 7.5 7.5\n",
      "9.01813 10 10.0\n",
      "5.4588103 5 5.0\n",
      "9.536162 10 10.0\n",
      "8.924709 10 10.0\n",
      "9.236886 10 7.5\n",
      "8.050895 7.5 7.5\n",
      "5.5868134 5 2.5\n",
      "8.454868 7.5 7.5\n",
      "6.8156075 7.5 7.5\n",
      "7.3488946 7.5 5.0\n",
      "9.12472 10 10.0\n",
      "7.9694934 7.5 10.0\n",
      "8.356356 7.5 10.0\n",
      "6.3539596 7.5 5.0\n",
      "4.8942156 5 7.5\n",
      "5.792913 5 2.5\n",
      "8.34318 7.5 7.5\n",
      "6.2689314 7.5 7.5\n",
      "6.4542704 7.5 7.5\n",
      "6.0504494 5 5.0\n",
      "5.3503 5 5.0\n",
      "8.388317 7.5 7.5\n",
      "6.404294 7.5 7.5\n",
      "8.114807 7.5 7.5\n",
      "7.017598 7.5 0.0\n",
      "7.436452 7.5 7.5\n",
      "8.936677 10 10.0\n",
      "7.492207 7.5 7.5\n",
      "7.747825 7.5 5.0\n",
      "5.4058166 5 2.5\n",
      "8.482055 7.5 5.0\n",
      "7.5904565 7.5 7.5\n",
      "8.903685 10 10.0\n",
      "7.2752185 7.5 7.5\n",
      "6.237676 5 5.0\n",
      "7.296435 7.5 10.0\n",
      "6.833897 7.5 10.0\n",
      "7.549978 7.5 10.0\n",
      "7.071357 7.5 10.0\n",
      "5.4863944 5 2.5\n",
      "6.307876 7.5 7.5\n",
      "8.20893 7.5 10.0\n",
      "5.990776 5 7.5\n",
      "8.362532 7.5 10.0\n",
      "7.1043367 7.5 7.5\n",
      "7.3421392 7.5 10.0\n",
      "7.644373 7.5 10.0\n",
      "7.4476748 7.5 2.5\n",
      "8.021668 7.5 10.0\n",
      "7.874553 7.5 7.5\n",
      "9.096622 10 10.0\n",
      "7.7939878 7.5 7.5\n",
      "7.065462 7.5 7.5\n",
      "7.933445 7.5 10.0\n",
      "6.372114 7.5 0.0\n",
      "7.3497086 7.5 7.5\n",
      "9.058817 10 10.0\n",
      "7.126306 7.5 7.5\n",
      "9.141496 10 7.5\n",
      "7.120605 7.5 7.5\n",
      "7.9963956 7.5 7.5\n",
      "7.2307744 7.5 7.5\n",
      "7.8520155 7.5 7.5\n",
      "6.823829 7.5 5.0\n",
      "7.277965 7.5 10.0\n",
      "6.9042625 7.5 5.0\n",
      "7.4205875 7.5 10.0\n",
      "9.475593 10 7.5\n",
      "7.6673994 7.5 7.5\n",
      "7.582217 7.5 10.0\n",
      "7.6652284 7.5 5.0\n",
      "7.099575 7.5 10.0\n",
      "7.53591 7.5 7.5\n",
      "6.852302 7.5 7.5\n",
      "7.071714 7.5 5.0\n",
      "8.843876 10 5.0\n",
      "6.181886 5 2.5\n",
      "9.502911 10 10.0\n",
      "8.127546 7.5 7.5\n",
      "9.289203 10 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.760685 7.5 10.0\n",
      "8.821927 10 7.5\n",
      "7.4442616 7.5 7.5\n",
      "7.7990084 7.5 7.5\n",
      "6.3827243 7.5 2.5\n",
      "7.2358866 7.5 10.0\n",
      "8.875368 10 10.0\n",
      "6.5619397 7.5 5.0\n",
      "9.182947 10 10.0\n",
      "4.367136 5 7.5\n",
      "7.6697392 7.5 7.5\n",
      "7.6056943 7.5 7.5\n",
      "7.1915956 7.5 10.0\n",
      "8.1389675 7.5 10.0\n",
      "8.704581 7.5 7.5\n",
      "7.4515715 7.5 7.5\n",
      "7.3995833 7.5 2.5\n",
      "5.835661 5 2.5\n",
      "8.826144 10 10.0\n",
      "9.235827 10 7.5\n",
      "5.5191054 5 5.0\n",
      "6.203065 5 7.5\n",
      "6.5741863 7.5 7.5\n",
      "6.2972455 7.5 10.0\n",
      "7.064277 7.5 5.0\n",
      "5.743789 5 5.0\n",
      "8.2548685 7.5 10.0\n",
      "8.869461 10 10.0\n",
      "7.3615146 7.5 7.5\n",
      "6.889896 7.5 7.5\n",
      "6.8485804 7.5 7.5\n",
      "6.5264893 7.5 7.5\n",
      "6.994022 7.5 7.5\n",
      "7.7897563 7.5 10.0\n",
      "8.830721 10 7.5\n",
      "6.8106136 7.5 10.0\n",
      "7.553045 7.5 10.0\n",
      "6.657207 7.5 5.0\n",
      "7.0640388 7.5 7.5\n",
      "6.8612704 7.5 5.0\n",
      "8.883724 10 7.5\n",
      "7.7433324 7.5 7.5\n",
      "7.1755404 7.5 10.0\n",
      "7.748843 7.5 7.5\n",
      "6.334149 7.5 5.0\n",
      "9.155457 10 10.0\n",
      "8.379332 7.5 10.0\n",
      "8.09853 7.5 10.0\n",
      "8.055823 7.5 7.5\n",
      "6.5188313 7.5 10.0\n",
      "8.244404 7.5 7.5\n",
      "7.3874316 7.5 5.0\n",
      "7.6197114 7.5 7.5\n",
      "5.0924687 5 2.5\n",
      "7.3565054 7.5 7.5\n",
      "6.8516836 7.5 5.0\n",
      "7.22283 7.5 7.5\n",
      "8.544028 7.5 10.0\n",
      "8.874953 10 10.0\n",
      "7.785538 7.5 2.5\n",
      "7.615743 7.5 5.0\n",
      "6.2110815 5 7.5\n",
      "8.905908 10 7.5\n",
      "9.155115 10 7.5\n",
      "8.831339 10 10.0\n",
      "8.791692 10 10.0\n",
      "7.1740227 7.5 7.5\n",
      "7.984481 7.5 10.0\n",
      "6.8095455 7.5 7.5\n",
      "6.7658477 7.5 7.5\n",
      "4.0211477 5 0.0\n",
      "9.298213 10 10.0\n",
      "7.7640285 7.5 10.0\n",
      "7.1943264 7.5 7.5\n",
      "6.6188107 7.5 5.0\n",
      "7.418891 7.5 7.5\n",
      "9.093144 10 10.0\n",
      "6.556414 7.5 2.5\n",
      "8.967906 10 7.5\n",
      "6.96446 7.5 7.5\n",
      "9.513585 10 10.0\n",
      "6.2502117 7.5 2.5\n",
      "6.600219 7.5 7.5\n",
      "6.180531 5 7.5\n",
      "8.556815 7.5 10.0\n",
      "6.4508605 7.5 2.5\n",
      "7.747286 7.5 7.5\n",
      "8.94993 10 10.0\n",
      "7.9718065 7.5 0.0\n",
      "7.671445 7.5 7.5\n",
      "8.54826 7.5 10.0\n",
      "6.4970074 7.5 10.0\n",
      "6.2253866 5 5.0\n",
      "9.364621 10 10.0\n",
      "7.103515 7.5 7.5\n",
      "4.0923433 5 5.0\n",
      "7.1871715 7.5 10.0\n",
      "8.133171 7.5 10.0\n",
      "7.228049 7.5 7.5\n",
      "5.460142 5 0.0\n",
      "9.281177 10 10.0\n",
      "6.7303257 7.5 7.5\n",
      "9.328558 10 7.5\n",
      "7.0105066 7.5 5.0\n",
      "7.8402147 7.5 10.0\n",
      "9.561613 10 10.0\n",
      "5.0860367 5 5.0\n",
      "6.75933 7.5 5.0\n",
      "7.101638 7.5 5.0\n",
      "8.863973 10 10.0\n",
      "9.284204 10 10.0\n",
      "8.5385065 7.5 7.5\n",
      "7.055512 7.5 10.0\n",
      "8.534483 7.5 7.5\n",
      "7.2394156 7.5 7.5\n",
      "6.813231 7.5 10.0\n",
      "5.1219826 5 5.0\n",
      "8.446651 7.5 2.5\n",
      "8.489075 7.5 7.5\n",
      "6.176046 5 10.0\n",
      "7.112429 7.5 7.5\n",
      "8.769637 10 10.0\n",
      "6.7999105 7.5 7.5\n",
      "7.1541214 7.5 2.5\n",
      "7.662334 7.5 7.5\n",
      "7.457184 7.5 7.5\n",
      "8.565492 7.5 10.0\n",
      "7.406676 7.5 10.0\n",
      "8.319792 7.5 10.0\n",
      "4.7781196 5 5.0\n",
      "7.4248605 7.5 7.5\n",
      "7.2647586 7.5 7.5\n",
      "8.287544 7.5 10.0\n",
      "9.121345 10 10.0\n",
      "6.904462 7.5 7.5\n",
      "7.063353 7.5 5.0\n",
      "7.685941 7.5 10.0\n",
      "7.0683255 7.5 7.5\n",
      "9.269771 10 10.0\n",
      "6.7854 7.5 5.0\n",
      "8.355713 7.5 7.5\n",
      "8.555223 7.5 7.5\n",
      "6.920619 7.5 5.0\n",
      "7.2219195 7.5 10.0\n",
      "7.631307 7.5 7.5\n",
      "8.436543 7.5 10.0\n",
      "7.7471223 7.5 10.0\n",
      "6.6988764 7.5 7.5\n",
      "7.487588 7.5 7.5\n",
      "8.995469 10 10.0\n",
      "7.4221916 7.5 5.0\n",
      "7.378341 7.5 10.0\n",
      "6.356868 7.5 0.0\n",
      "8.7482395 7.5 7.5\n",
      "8.006449 7.5 7.5\n",
      "8.9731455 10 10.0\n",
      "8.04119 7.5 7.5\n",
      "7.2025995 7.5 7.5\n",
      "7.1456933 7.5 7.5\n",
      "8.393837 7.5 10.0\n",
      "7.091093 7.5 7.5\n",
      "7.6636677 7.5 7.5\n",
      "7.4544606 7.5 10.0\n",
      "6.9319725 7.5 7.5\n",
      "6.9912496 7.5 7.5\n",
      "5.8340125 5 7.5\n",
      "8.336481 7.5 2.5\n",
      "7.256458 7.5 10.0\n",
      "7.868079 7.5 5.0\n",
      "6.8389444 7.5 5.0\n",
      "7.5735617 7.5 2.5\n",
      "5.6374464 5 2.5\n",
      "8.234454 7.5 10.0\n",
      "7.6379957 7.5 7.5\n",
      "7.2473564 7.5 10.0\n",
      "6.423319 7.5 5.0\n",
      "6.8627553 7.5 7.5\n",
      "8.638815 7.5 10.0\n",
      "7.8739066 7.5 7.5\n",
      "7.2595453 7.5 7.5\n",
      "6.9961743 7.5 10.0\n",
      "6.727895 7.5 5.0\n",
      "7.7048035 7.5 5.0\n",
      "9.503086 10 10.0\n",
      "8.992665 10 7.5\n",
      "7.1220965 7.5 10.0\n",
      "8.152927 7.5 10.0\n",
      "6.0989876 5 7.5\n",
      "7.2947507 7.5 10.0\n",
      "7.812168 7.5 10.0\n",
      "8.249279 7.5 7.5\n",
      "9.083114 10 7.5\n",
      "6.684174 7.5 7.5\n",
      "8.27601 7.5 7.5\n",
      "7.4649386 7.5 7.5\n",
      "6.228361 5 7.5\n",
      "7.2239947 7.5 10.0\n",
      "8.472889 7.5 10.0\n",
      "7.2850413 7.5 10.0\n",
      "5.152608 5 2.5\n",
      "7.450144 7.5 10.0\n",
      "9.023595 10 10.0\n",
      "6.1205363 5 5.0\n",
      "7.088463 7.5 7.5\n",
      "8.339172 7.5 7.5\n",
      "8.894118 10 10.0\n",
      "8.418751 7.5 10.0\n",
      "7.47054 7.5 7.5\n",
      "7.6479 7.5 7.5\n",
      "8.790858 10 10.0\n",
      "5.976678 5 2.5\n",
      "6.3362617 7.5 5.0\n",
      "7.508385 7.5 7.5\n",
      "9.050475 10 10.0\n",
      "7.22314 7.5 10.0\n",
      "9.095815 10 7.5\n",
      "7.5938005 7.5 7.5\n",
      "7.402622 7.5 10.0\n",
      "8.155241 7.5 7.5\n",
      "6.7528048 7.5 5.0\n",
      "6.831529 7.5 5.0\n",
      "8.079639 7.5 7.5\n",
      "7.168214 7.5 7.5\n",
      "7.065857 7.5 7.5\n",
      "8.898822 10 7.5\n",
      "8.517264 7.5 10.0\n",
      "8.42282 7.5 10.0\n",
      "6.33531 7.5 5.0\n",
      "7.5515003 7.5 7.5\n",
      "8.382813 7.5 10.0\n",
      "9.278016 10 10.0\n",
      "6.69611 7.5 2.5\n",
      "7.9641695 7.5 7.5\n",
      "8.9510145 10 7.5\n",
      "7.120676 7.5 10.0\n",
      "8.603761 7.5 10.0\n",
      "7.2068686 7.5 2.5\n",
      "8.484365 7.5 10.0\n",
      "7.5601597 7.5 7.5\n",
      "7.4336624 7.5 10.0\n",
      "7.676981 7.5 7.5\n",
      "7.314356 7.5 7.5\n",
      "7.321901 7.5 7.5\n",
      "7.0178547 7.5 5.0\n",
      "7.8469286 7.5 7.5\n",
      "6.5889993 7.5 7.5\n",
      "6.132666 5 5.0\n",
      "9.227357 10 10.0\n",
      "7.771103 7.5 10.0\n",
      "8.806351 10 2.5\n",
      "4.484934 5 2.5\n",
      "6.7978477 7.5 7.5\n",
      "6.767732 7.5 0.0\n",
      "8.985864 10 10.0\n",
      "7.0490413 7.5 7.5\n",
      "7.362008 7.5 7.5\n",
      "8.767563 10 10.0\n",
      "8.767576 10 10.0\n",
      "7.6037 7.5 7.5\n",
      "7.472853 7.5 10.0\n",
      "7.4841633 7.5 7.5\n",
      "8.15233 7.5 10.0\n",
      "7.745507 7.5 10.0\n",
      "7.3786197 7.5 10.0\n",
      "8.100622 7.5 5.0\n",
      "7.5063143 7.5 7.5\n",
      "8.019329 7.5 7.5\n",
      "7.081466 7.5 7.5\n",
      "6.8630347 7.5 10.0\n",
      "7.892143 7.5 10.0\n",
      "6.891666 7.5 5.0\n",
      "7.5126605 7.5 10.0\n",
      "7.487547 7.5 7.5\n",
      "7.158037 7.5 5.0\n",
      "7.1660485 7.5 7.5\n",
      "7.125655 7.5 7.5\n",
      "6.889044 7.5 10.0\n",
      "9.171648 10 7.5\n",
      "6.2396994 5 7.5\n",
      "9.701401 10 10.0\n",
      "7.149961 7.5 7.5\n",
      "8.671176 7.5 10.0\n",
      "7.6878686 7.5 7.5\n",
      "7.2988453 7.5 5.0\n",
      "6.78473 7.5 0.0\n",
      "6.952039 7.5 7.5\n",
      "9.267616 10 10.0\n",
      "8.707578 7.5 7.5\n",
      "6.4654503 7.5 7.5\n",
      "7.875001 7.5 7.5\n",
      "6.2194095 5 2.5\n",
      "6.391421 7.5 7.5\n",
      "7.931196 7.5 10.0\n",
      "7.3833327 7.5 7.5\n",
      "6.3278265 7.5 7.5\n",
      "8.853412 10 10.0\n",
      "8.527034 7.5 10.0\n",
      "7.1646705 7.5 0.0\n",
      "4.830397 5 0.0\n",
      "7.9131107 7.5 7.5\n",
      "7.0594935 7.5 7.5\n",
      "6.41397 7.5 7.5\n",
      "8.766951 10 7.5\n",
      "8.48736 7.5 10.0\n",
      "7.68842 7.5 7.5\n",
      "7.4392753 7.5 10.0\n",
      "6.8414216 7.5 7.5\n",
      "8.034958 7.5 7.5\n",
      "6.0081954 5 5.0\n",
      "8.634897 7.5 10.0\n",
      "6.126692 5 10.0\n",
      "8.662507 7.5 7.5\n",
      "6.707382 7.5 7.5\n",
      "7.843692 7.5 2.5\n",
      "8.566007 7.5 10.0\n",
      "9.95166 10 7.5\n",
      "7.8053713 7.5 10.0\n",
      "3.3283925 2.5 2.5\n",
      "8.162451 7.5 10.0\n",
      "7.5280657 7.5 10.0\n",
      "7.6494412 7.5 7.5\n",
      "9.088149 10 10.0\n",
      "8.942622 10 10.0\n",
      "9.069761 10 7.5\n",
      "8.784606 10 7.5\n",
      "7.5085697 7.5 7.5\n",
      "8.459416 7.5 7.5\n",
      "9.266925 10 10.0\n",
      "6.5855036 7.5 0.0\n",
      "8.705413 7.5 7.5\n",
      "7.36313 7.5 10.0\n",
      "8.466101 7.5 10.0\n",
      "7.400836 7.5 10.0\n",
      "7.8765554 7.5 7.5\n",
      "7.7707906 7.5 5.0\n",
      "6.338151 7.5 5.0\n",
      "6.449645 7.5 7.5\n",
      "6.7081747 7.5 5.0\n",
      "6.397057 7.5 7.5\n",
      "6.9551578 7.5 10.0\n",
      "9.258585 10 10.0\n",
      "8.364756 7.5 10.0\n",
      "7.536412 7.5 7.5\n",
      "7.2656803 7.5 7.5\n",
      "7.810284 7.5 10.0\n",
      "7.5170255 7.5 7.5\n",
      "7.2494063 7.5 10.0\n",
      "7.197843 7.5 7.5\n",
      "7.7980466 7.5 10.0\n",
      "6.504983 7.5 2.5\n",
      "9.44681 10 10.0\n",
      "4.16425 5 2.5\n",
      "7.66822 7.5 7.5\n",
      "5.1666336 5 7.5\n",
      "6.283653 7.5 7.5\n",
      "8.754262 10 7.5\n",
      "7.1499963 7.5 7.5\n",
      "5.7567387 5 2.5\n",
      "6.232669 5 5.0\n",
      "8.56062 7.5 10.0\n",
      "7.4789815 7.5 10.0\n",
      "7.169029 7.5 2.5\n",
      "7.0149016 7.5 7.5\n",
      "5.8781085 5 7.5\n",
      "9.148239 10 7.5\n",
      "8.4042015 7.5 7.5\n",
      "7.6319895 7.5 10.0\n",
      "7.684509 7.5 10.0\n",
      "6.562287 7.5 7.5\n",
      "7.7269554 7.5 10.0\n",
      "8.871754 10 10.0\n",
      "7.497858 7.5 5.0\n",
      "8.635564 7.5 7.5\n",
      "7.614476 7.5 5.0\n",
      "8.73728 7.5 7.5\n",
      "7.680233 7.5 7.5\n",
      "7.3038306 7.5 5.0\n",
      "6.51153 7.5 2.5\n",
      "7.249142 7.5 5.0\n",
      "5.9831886 5 7.5\n",
      "9.194047 10 5.0\n",
      "6.564926 7.5 7.5\n",
      "7.376843 7.5 7.5\n",
      "6.883712 7.5 5.0\n",
      "7.2710114 7.5 7.5\n",
      "6.5180864 7.5 7.5\n",
      "6.8026314 7.5 7.5\n",
      "7.9298987 7.5 7.5\n",
      "5.750521 5 7.5\n",
      "3.5695658 2.5 0.0\n",
      "7.1151724 7.5 7.5\n",
      "6.5837936 7.5 7.5\n",
      "8.670176 7.5 7.5\n",
      "8.762258 10 10.0\n",
      "7.7187757 7.5 2.5\n",
      "7.1892815 7.5 7.5\n",
      "9.041867 10 10.0\n",
      "7.552977 7.5 7.5\n",
      "7.5985346 7.5 10.0\n",
      "9.450669 10 10.0\n",
      "5.1497116 5 7.5\n",
      "7.0983987 7.5 10.0\n",
      "7.4697337 7.5 7.5\n",
      "8.99073 10 10.0\n",
      "7.088537 7.5 7.5\n",
      "7.4016585 7.5 7.5\n",
      "5.7633333 5 7.5\n",
      "9.429383 10 10.0\n",
      "6.74521 7.5 7.5\n",
      "8.124723 7.5 7.5\n",
      "5.767807 5 0.0\n",
      "8.250881 7.5 7.5\n",
      "9.027729 10 7.5\n",
      "7.931411 7.5 10.0\n",
      "4.4305305 5 0.0\n",
      "7.7821355 7.5 10.0\n",
      "8.188417 7.5 10.0\n",
      "6.294384 7.5 7.5\n",
      "7.5833473 7.5 7.5\n",
      "8.190156 7.5 7.5\n",
      "7.5552173 7.5 2.5\n",
      "5.401988 5 10.0\n",
      "8.687737 7.5 7.5\n",
      "7.3829203 7.5 7.5\n",
      "4.9184823 5 7.5\n",
      "4.795736 5 10.0\n",
      "8.450025 7.5 7.5\n",
      "6.302373 7.5 10.0\n",
      "7.9600043 7.5 10.0\n",
      "7.285608 7.5 2.5\n",
      "7.430115 7.5 7.5\n",
      "8.461951 7.5 10.0\n",
      "8.900803 10 10.0\n",
      "9.764553 10 10.0\n",
      "7.173943 7.5 10.0\n",
      "7.2012124 7.5 5.0\n",
      "9.271759 10 10.0\n",
      "8.847291 10 10.0\n",
      "7.331409 7.5 7.5\n",
      "7.6099057 7.5 7.5\n",
      "6.362331 7.5 7.5\n",
      "6.9939804 7.5 2.5\n",
      "7.1794066 7.5 10.0\n",
      "8.91889 10 10.0\n",
      "7.495342 7.5 10.0\n",
      "5.962276 5 7.5\n",
      "6.79363 7.5 7.5\n",
      "7.3363185 7.5 10.0\n",
      "6.842632 7.5 5.0\n",
      "9.456772 10 2.5\n",
      "7.6076565 7.5 7.5\n",
      "8.131601 7.5 7.5\n",
      "5.491631 5 2.5\n",
      "8.915633 10 7.5\n",
      "7.686285 7.5 7.5\n",
      "9.151863 10 7.5\n",
      "6.7845774 7.5 7.5\n",
      "6.9657335 7.5 7.5\n",
      "6.9048076 7.5 7.5\n",
      "7.1704164 7.5 7.5\n",
      "6.575851 7.5 7.5\n",
      "8.08417 7.5 10.0\n",
      "8.502848 7.5 10.0\n",
      "6.927402 7.5 10.0\n",
      "7.3492827 7.5 5.0\n",
      "8.512946 7.5 7.5\n",
      "8.936766 10 10.0\n",
      "8.954133 10 10.0\n",
      "8.521378 7.5 7.5\n",
      "7.0609393 7.5 7.5\n",
      "7.061174 7.5 7.5\n",
      "8.530084 7.5 7.5\n",
      "7.4564056 7.5 5.0\n",
      "7.1120663 7.5 7.5\n",
      "9.085295 10 10.0\n",
      "9.576993 10 10.0\n",
      "9.058344 10 2.5\n",
      "6.1162314 5 7.5\n",
      "7.615408 7.5 2.5\n",
      "6.636728 7.5 10.0\n",
      "7.300126 7.5 7.5\n",
      "7.492826 7.5 7.5\n",
      "7.9226766 7.5 10.0\n",
      "9.098399 10 10.0\n",
      "7.315274 7.5 7.5\n",
      "7.2308707 7.5 10.0\n",
      "8.218155 7.5 7.5\n",
      "8.825605 10 10.0\n",
      "9.131255 10 10.0\n",
      "6.3436623 7.5 0.0\n",
      "7.1296115 7.5 10.0\n",
      "6.2182455 5 10.0\n",
      "7.571516 7.5 7.5\n",
      "7.8731775 7.5 10.0\n",
      "6.3650527 7.5 10.0\n",
      "7.4471903 7.5 5.0\n",
      "7.588214 7.5 10.0\n",
      "6.9339223 7.5 5.0\n",
      "7.271678 7.5 7.5\n",
      "8.605566 7.5 10.0\n",
      "6.868173 7.5 7.5\n",
      "8.517467 7.5 7.5\n",
      "6.343595 7.5 10.0\n",
      "7.0638437 7.5 7.5\n",
      "9.584772 10 10.0\n",
      "5.2647486 5 5.0\n",
      "7.063435 7.5 2.5\n",
      "7.6944933 7.5 7.5\n",
      "6.9750166 7.5 2.5\n",
      "7.5036335 7.5 10.0\n",
      "8.626322 7.5 7.5\n",
      "7.160359 7.5 7.5\n",
      "6.7259126 7.5 2.5\n",
      "8.633618 7.5 10.0\n",
      "7.1803737 7.5 10.0\n",
      "8.456575 7.5 7.5\n",
      "8.528995 7.5 10.0\n",
      "6.9848337 7.5 10.0\n",
      "8.582359 7.5 10.0\n",
      "7.6636477 7.5 5.0\n",
      "7.5601425 7.5 7.5\n"
     ]
    }
   ],
   "source": [
    "# for pred, clipped, actual in zip(xgb_preds, clipS(xgb_copy), y_test ):\n",
    "#     print (pred, clipped, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35883188889119\n"
     ]
    }
   ],
   "source": [
    "print (mean_squared_error(y_test,clipS(xgb_preds))**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shrikar/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import theano\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)\n",
    "np.random.seed(123)  # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11202/11202 [==============================] - 2s 185us/step - loss: 41.4869\n",
      "Epoch 2/200\n",
      "11202/11202 [==============================] - 2s 178us/step - loss: 22.5995\n",
      "Epoch 3/200\n",
      "11202/11202 [==============================] - 2s 165us/step - loss: 12.4291\n",
      "Epoch 4/200\n",
      "11202/11202 [==============================] - 2s 158us/step - loss: 7.9893\n",
      "Epoch 5/200\n",
      "11202/11202 [==============================] - 1s 113us/step - loss: 6.6835\n",
      "Epoch 6/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4924\n",
      "Epoch 7/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4853\n",
      "Epoch 8/200\n",
      "11202/11202 [==============================] - 1s 120us/step - loss: 6.4852\n",
      "Epoch 9/200\n",
      "11202/11202 [==============================] - 1s 108us/step - loss: 6.4849\n",
      "Epoch 10/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4851\n",
      "Epoch 11/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4850\n",
      "Epoch 12/200\n",
      "11202/11202 [==============================] - 2s 159us/step - loss: 6.4851\n",
      "Epoch 13/200\n",
      "11202/11202 [==============================] - 2s 201us/step - loss: 6.4852\n",
      "Epoch 14/200\n",
      "11202/11202 [==============================] - 2s 184us/step - loss: 6.4849\n",
      "Epoch 15/200\n",
      "11202/11202 [==============================] - 2s 179us/step - loss: 6.4854\n",
      "Epoch 16/200\n",
      "11202/11202 [==============================] - 2s 175us/step - loss: 6.4855\n",
      "Epoch 17/200\n",
      "11202/11202 [==============================] - 2s 177us/step - loss: 6.4850\n",
      "Epoch 18/200\n",
      "11202/11202 [==============================] - 2s 175us/step - loss: 6.4849\n",
      "Epoch 19/200\n",
      "11202/11202 [==============================] - 2s 192us/step - loss: 6.4850\n",
      "Epoch 20/200\n",
      "11202/11202 [==============================] - 2s 186us/step - loss: 6.4851\n",
      "Epoch 21/200\n",
      "11202/11202 [==============================] - 2s 187us/step - loss: 6.4846\n",
      "Epoch 22/200\n",
      "11202/11202 [==============================] - 2s 179us/step - loss: 6.4850\n",
      "Epoch 23/200\n",
      "11202/11202 [==============================] - 2s 178us/step - loss: 6.4842\n",
      "Epoch 24/200\n",
      "11202/11202 [==============================] - 2s 203us/step - loss: 6.4853\n",
      "Epoch 25/200\n",
      "11202/11202 [==============================] - 1s 128us/step - loss: 6.4851\n",
      "Epoch 26/200\n",
      "11202/11202 [==============================] - 1s 111us/step - loss: 6.4850\n",
      "Epoch 27/200\n",
      "11202/11202 [==============================] - 1s 109us/step - loss: 6.4841\n",
      "Epoch 28/200\n",
      "11202/11202 [==============================] - 1s 114us/step - loss: 6.4857\n",
      "Epoch 29/200\n",
      "11202/11202 [==============================] - 2s 151us/step - loss: 6.4851\n",
      "Epoch 30/200\n",
      "11202/11202 [==============================] - 1s 119us/step - loss: 6.4850 0s - loss: \n",
      "Epoch 31/200\n",
      "11202/11202 [==============================] - 1s 133us/step - loss: 6.4846\n",
      "Epoch 32/200\n",
      "11202/11202 [==============================] - 2s 204us/step - loss: 6.4853\n",
      "Epoch 33/200\n",
      "11202/11202 [==============================] - 3s 223us/step - loss: 6.4853\n",
      "Epoch 34/200\n",
      "11202/11202 [==============================] - 2s 188us/step - loss: 6.4857\n",
      "Epoch 35/200\n",
      "11202/11202 [==============================] - 2s 172us/step - loss: 6.4852\n",
      "Epoch 36/200\n",
      "11202/11202 [==============================] - 2s 134us/step - loss: 6.4853\n",
      "Epoch 37/200\n",
      "11202/11202 [==============================] - 2s 153us/step - loss: 6.4850\n",
      "Epoch 38/200\n",
      "11202/11202 [==============================] - 1s 113us/step - loss: 6.4852\n",
      "Epoch 39/200\n",
      "11202/11202 [==============================] - 1s 112us/step - loss: 6.4849\n",
      "Epoch 40/200\n",
      "11202/11202 [==============================] - 1s 115us/step - loss: 6.4851\n",
      "Epoch 41/200\n",
      "11202/11202 [==============================] - 1s 110us/step - loss: 6.4855\n",
      "Epoch 42/200\n",
      "11202/11202 [==============================] - 1s 119us/step - loss: 6.4850\n",
      "Epoch 43/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4854\n",
      "Epoch 44/200\n",
      "11202/11202 [==============================] - 1s 109us/step - loss: 6.4856\n",
      "Epoch 45/200\n",
      "11202/11202 [==============================] - 1s 116us/step - loss: 6.4848\n",
      "Epoch 46/200\n",
      "11202/11202 [==============================] - 1s 123us/step - loss: 6.4850\n",
      "Epoch 47/200\n",
      "11202/11202 [==============================] - 1s 116us/step - loss: 6.4851\n",
      "Epoch 48/200\n",
      "11202/11202 [==============================] - 1s 120us/step - loss: 6.4850\n",
      "Epoch 49/200\n",
      "11202/11202 [==============================] - 1s 123us/step - loss: 6.4848\n",
      "Epoch 50/200\n",
      "11202/11202 [==============================] - 1s 127us/step - loss: 6.4851\n",
      "Epoch 51/200\n",
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4850\n",
      "Epoch 52/200\n",
      "11202/11202 [==============================] - 1s 124us/step - loss: 6.4846\n",
      "Epoch 53/200\n",
      "11202/11202 [==============================] - 2s 154us/step - loss: 6.4852\n",
      "Epoch 54/200\n",
      "11202/11202 [==============================] - 2s 143us/step - loss: 6.4848\n",
      "Epoch 55/200\n",
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4850\n",
      "Epoch 56/200\n",
      "11202/11202 [==============================] - 2s 154us/step - loss: 6.4852\n",
      "Epoch 57/200\n",
      "11202/11202 [==============================] - 2s 143us/step - loss: 6.4852\n",
      "Epoch 58/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4851\n",
      "Epoch 59/200\n",
      "11202/11202 [==============================] - 1s 134us/step - loss: 6.4852\n",
      "Epoch 60/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4854\n",
      "Epoch 61/200\n",
      "11202/11202 [==============================] - 2s 148us/step - loss: 6.4852\n",
      "Epoch 62/200\n",
      "11202/11202 [==============================] - 2s 144us/step - loss: 6.4853\n",
      "Epoch 63/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4853\n",
      "Epoch 64/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4854\n",
      "Epoch 65/200\n",
      "11202/11202 [==============================] - 1s 121us/step - loss: 6.4850\n",
      "Epoch 66/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4850\n",
      "Epoch 67/200\n",
      "11202/11202 [==============================] - 1s 132us/step - loss: 6.4848\n",
      "Epoch 68/200\n",
      "11202/11202 [==============================] - 2s 207us/step - loss: 6.4851\n",
      "Epoch 69/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4846\n",
      "Epoch 70/200\n",
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4847\n",
      "Epoch 71/200\n",
      "11202/11202 [==============================] - 1s 121us/step - loss: 6.4850\n",
      "Epoch 72/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4851\n",
      "Epoch 73/200\n",
      "11202/11202 [==============================] - 1s 129us/step - loss: 6.4850\n",
      "Epoch 74/200\n",
      "11202/11202 [==============================] - 1s 129us/step - loss: 6.4853\n",
      "Epoch 75/200\n",
      "11202/11202 [==============================] - 1s 127us/step - loss: 6.4848\n",
      "Epoch 76/200\n",
      "11202/11202 [==============================] - 1s 121us/step - loss: 6.4847\n",
      "Epoch 77/200\n",
      "11202/11202 [==============================] - 1s 132us/step - loss: 6.4841\n",
      "Epoch 78/200\n",
      "11202/11202 [==============================] - 1s 112us/step - loss: 6.4854\n",
      "Epoch 79/200\n",
      "11202/11202 [==============================] - 1s 118us/step - loss: 6.4846\n",
      "Epoch 80/200\n",
      "11202/11202 [==============================] - 1s 134us/step - loss: 6.4845\n",
      "Epoch 81/200\n",
      "11202/11202 [==============================] - 1s 130us/step - loss: 6.4853\n",
      "Epoch 82/200\n",
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4848\n",
      "Epoch 83/200\n",
      "11202/11202 [==============================] - 1s 127us/step - loss: 6.4850\n",
      "Epoch 84/200\n",
      "11202/11202 [==============================] - 1s 129us/step - loss: 6.4851\n",
      "Epoch 85/200\n",
      "11202/11202 [==============================] - 1s 119us/step - loss: 6.4851\n",
      "Epoch 86/200\n",
      "11202/11202 [==============================] - 1s 126us/step - loss: 6.4852\n",
      "Epoch 87/200\n",
      "11202/11202 [==============================] - 1s 124us/step - loss: 6.4850\n",
      "Epoch 88/200\n",
      "11202/11202 [==============================] - 1s 126us/step - loss: 6.4849\n",
      "Epoch 89/200\n",
      "11202/11202 [==============================] - 1s 133us/step - loss: 6.4849\n",
      "Epoch 90/200\n",
      "11202/11202 [==============================] - 1s 114us/step - loss: 6.4849\n",
      "Epoch 91/200\n",
      "11202/11202 [==============================] - 2s 139us/step - loss: 6.4851\n",
      "Epoch 92/200\n",
      "11202/11202 [==============================] - 1s 119us/step - loss: 6.4854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "11202/11202 [==============================] - 1s 133us/step - loss: 6.4853\n",
      "Epoch 94/200\n",
      "11202/11202 [==============================] - 1s 115us/step - loss: 6.4850\n",
      "Epoch 95/200\n",
      "11202/11202 [==============================] - 1s 108us/step - loss: 6.4843\n",
      "Epoch 96/200\n",
      "11202/11202 [==============================] - 1s 116us/step - loss: 6.4840\n",
      "Epoch 97/200\n",
      "11202/11202 [==============================] - 1s 109us/step - loss: 6.4848\n",
      "Epoch 98/200\n",
      "11202/11202 [==============================] - 1s 130us/step - loss: 6.4852\n",
      "Epoch 99/200\n",
      "11202/11202 [==============================] - 2s 149us/step - loss: 6.4845\n",
      "Epoch 100/200\n",
      "11202/11202 [==============================] - 2s 171us/step - loss: 6.4856\n",
      "Epoch 101/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4848\n",
      "Epoch 102/200\n",
      "11202/11202 [==============================] - 2s 175us/step - loss: 6.4850\n",
      "Epoch 103/200\n",
      "11202/11202 [==============================] - 1s 129us/step - loss: 6.4841\n",
      "Epoch 104/200\n",
      "11202/11202 [==============================] - 2s 135us/step - loss: 6.4848\n",
      "Epoch 105/200\n",
      "11202/11202 [==============================] - 1s 133us/step - loss: 6.4849\n",
      "Epoch 106/200\n",
      "11202/11202 [==============================] - 1s 111us/step - loss: 6.4853\n",
      "Epoch 107/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4850\n",
      "Epoch 108/200\n",
      "11202/11202 [==============================] - 1s 108us/step - loss: 6.4850\n",
      "Epoch 109/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4852\n",
      "Epoch 110/200\n",
      "11202/11202 [==============================] - 1s 114us/step - loss: 6.4852\n",
      "Epoch 111/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4851\n",
      "Epoch 112/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4850\n",
      "Epoch 113/200\n",
      "11202/11202 [==============================] - 1s 111us/step - loss: 6.4852\n",
      "Epoch 114/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4850\n",
      "Epoch 115/200\n",
      "11202/11202 [==============================] - 1s 105us/step - loss: 6.4853\n",
      "Epoch 116/200\n",
      "11202/11202 [==============================] - 1s 108us/step - loss: 6.4846\n",
      "Epoch 117/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4852\n",
      "Epoch 118/200\n",
      "11202/11202 [==============================] - 2s 134us/step - loss: 6.4848\n",
      "Epoch 119/200\n",
      "11202/11202 [==============================] - 1s 114us/step - loss: 6.4852\n",
      "Epoch 120/200\n",
      "11202/11202 [==============================] - 1s 113us/step - loss: 6.4852\n",
      "Epoch 121/200\n",
      "11202/11202 [==============================] - 1s 112us/step - loss: 6.4847\n",
      "Epoch 122/200\n",
      "11202/11202 [==============================] - 1s 110us/step - loss: 6.4853\n",
      "Epoch 123/200\n",
      "11202/11202 [==============================] - 1s 113us/step - loss: 6.4851\n",
      "Epoch 124/200\n",
      "11202/11202 [==============================] - 1s 120us/step - loss: 6.4853\n",
      "Epoch 125/200\n",
      "11202/11202 [==============================] - 1s 130us/step - loss: 6.4851\n",
      "Epoch 126/200\n",
      "11202/11202 [==============================] - 1s 111us/step - loss: 6.4852\n",
      "Epoch 127/200\n",
      "11202/11202 [==============================] - 1s 116us/step - loss: 6.4849\n",
      "Epoch 128/200\n",
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4848\n",
      "Epoch 129/200\n",
      "11202/11202 [==============================] - ETA: 0s - loss: 6.480 - 1s 122us/step - loss: 6.4850\n",
      "Epoch 130/200\n",
      "11202/11202 [==============================] - 2s 169us/step - loss: 6.4841\n",
      "Epoch 131/200\n",
      "11202/11202 [==============================] - 1s 128us/step - loss: 6.4848\n",
      "Epoch 132/200\n",
      "11202/11202 [==============================] - 2s 174us/step - loss: 6.4842\n",
      "Epoch 133/200\n",
      "11202/11202 [==============================] - 1s 112us/step - loss: 6.4851\n",
      "Epoch 134/200\n",
      "11202/11202 [==============================] - 1s 115us/step - loss: 6.4849\n",
      "Epoch 135/200\n",
      "11202/11202 [==============================] - 1s 130us/step - loss: 6.4843\n",
      "Epoch 136/200\n",
      "11202/11202 [==============================] - 2s 147us/step - loss: 6.4851\n",
      "Epoch 137/200\n",
      "11202/11202 [==============================] - 1s 121us/step - loss: 6.4852\n",
      "Epoch 138/200\n",
      "11202/11202 [==============================] - 2s 176us/step - loss: 6.4843\n",
      "Epoch 139/200\n",
      "11202/11202 [==============================] - 2s 158us/step - loss: 6.4853\n",
      "Epoch 140/200\n",
      "11202/11202 [==============================] - 2s 146us/step - loss: 6.4849\n",
      "Epoch 141/200\n",
      "11202/11202 [==============================] - 1s 118us/step - loss: 6.4846\n",
      "Epoch 142/200\n",
      "11202/11202 [==============================] - 1s 112us/step - loss: 6.4846\n",
      "Epoch 143/200\n",
      "11202/11202 [==============================] - 1s 123us/step - loss: 6.4850\n",
      "Epoch 144/200\n",
      "11202/11202 [==============================] - 2s 166us/step - loss: 6.4850\n",
      "Epoch 145/200\n",
      "11202/11202 [==============================] - 1s 113us/step - loss: 6.4850\n",
      "Epoch 146/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4843\n",
      "Epoch 147/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4841\n",
      "Epoch 148/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4850\n",
      "Epoch 149/200\n",
      "11202/11202 [==============================] - 1s 105us/step - loss: 6.4842\n",
      "Epoch 150/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4852\n",
      "Epoch 151/200\n",
      "11202/11202 [==============================] - 1s 109us/step - loss: 6.4847\n",
      "Epoch 152/200\n",
      "11202/11202 [==============================] - 1s 105us/step - loss: 6.4852\n",
      "Epoch 153/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4850\n",
      "Epoch 154/200\n",
      "11202/11202 [==============================] - 1s 105us/step - loss: 6.4847\n",
      "Epoch 155/200\n",
      "11202/11202 [==============================] - 1s 123us/step - loss: 6.4839\n",
      "Epoch 156/200\n",
      "11202/11202 [==============================] - 2s 139us/step - loss: 6.4857\n",
      "Epoch 157/200\n",
      "11202/11202 [==============================] - 1s 105us/step - loss: 6.4849\n",
      "Epoch 158/200\n",
      "11202/11202 [==============================] - 1s 109us/step - loss: 6.4851\n",
      "Epoch 159/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4850\n",
      "Epoch 160/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4852\n",
      "Epoch 161/200\n",
      "11202/11202 [==============================] - 1s 115us/step - loss: 6.4848\n",
      "Epoch 162/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4852\n",
      "Epoch 163/200\n",
      "11202/11202 [==============================] - 1s 128us/step - loss: 6.4853\n",
      "Epoch 164/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4845\n",
      "Epoch 165/200\n",
      "11202/11202 [==============================] - 2s 150us/step - loss: 6.4845\n",
      "Epoch 166/200\n",
      "11202/11202 [==============================] - 2s 172us/step - loss: 6.4847\n",
      "Epoch 167/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4854\n",
      "Epoch 168/200\n",
      "11202/11202 [==============================] - 2s 158us/step - loss: 6.4850\n",
      "Epoch 169/200\n",
      "11202/11202 [==============================] - 2s 134us/step - loss: 6.4852\n",
      "Epoch 170/200\n",
      "11202/11202 [==============================] - 1s 133us/step - loss: 6.4851\n",
      "Epoch 171/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4849\n",
      "Epoch 172/200\n",
      "11202/11202 [==============================] - 2s 146us/step - loss: 6.4852\n",
      "Epoch 173/200\n",
      "11202/11202 [==============================] - 1s 116us/step - loss: 6.4851\n",
      "Epoch 174/200\n",
      "11202/11202 [==============================] - 2s 161us/step - loss: 6.4847\n",
      "Epoch 175/200\n",
      "11202/11202 [==============================] - 2s 138us/step - loss: 6.4851\n",
      "Epoch 176/200\n",
      "11202/11202 [==============================] - 2s 139us/step - loss: 6.4850\n",
      "Epoch 177/200\n",
      "11202/11202 [==============================] - 1s 124us/step - loss: 6.4849\n",
      "Epoch 178/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4841\n",
      "Epoch 179/200\n",
      "11202/11202 [==============================] - 1s 129us/step - loss: 6.4852\n",
      "Epoch 180/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4849\n",
      "Epoch 181/200\n",
      "11202/11202 [==============================] - 1s 124us/step - loss: 6.4849\n",
      "Epoch 182/200\n",
      "11202/11202 [==============================] - 1s 119us/step - loss: 6.4851\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4849\n",
      "Epoch 184/200\n",
      "11202/11202 [==============================] - 1s 128us/step - loss: 6.4849\n",
      "Epoch 185/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4851\n",
      "Epoch 186/200\n",
      "11202/11202 [==============================] - 2s 138us/step - loss: 6.4842\n",
      "Epoch 187/200\n",
      "11202/11202 [==============================] - 2s 136us/step - loss: 6.4849\n",
      "Epoch 188/200\n",
      "11202/11202 [==============================] - 2s 140us/step - loss: 6.4843\n",
      "Epoch 189/200\n",
      "11202/11202 [==============================] - 2s 159us/step - loss: 6.4849\n",
      "Epoch 190/200\n",
      "11202/11202 [==============================] - 2s 163us/step - loss: 6.4851\n",
      "Epoch 191/200\n",
      "11202/11202 [==============================] - 2s 157us/step - loss: 6.4847\n",
      "Epoch 192/200\n",
      "11202/11202 [==============================] - 1s 114us/step - loss: 6.4853\n",
      "Epoch 193/200\n",
      "11202/11202 [==============================] - 1s 117us/step - loss: 6.4852\n",
      "Epoch 194/200\n",
      "11202/11202 [==============================] - 3s 251us/step - loss: 6.4846\n",
      "Epoch 195/200\n",
      "11202/11202 [==============================] - 2s 219us/step - loss: 6.4853\n",
      "Epoch 196/200\n",
      "11202/11202 [==============================] - 3s 282us/step - loss: 6.4853\n",
      "Epoch 197/200\n",
      "11202/11202 [==============================] - 2s 171us/step - loss: 6.4851\n",
      "Epoch 198/200\n",
      "11202/11202 [==============================] - 1s 127us/step - loss: 6.4853\n",
      "Epoch 199/200\n",
      "11202/11202 [==============================] - 1s 121us/step - loss: 6.4849\n",
      "Epoch 200/200\n",
      "11202/11202 [==============================] - 2s 151us/step - loss: 6.4849\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=4, activation='relu'))\n",
    "#model.add(Dense(200, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='hard_sigmoid'))\n",
    "#model.add(Dense(50, activation='hard_sigmoid'))\n",
    "#model.add(Dense(40, activation='sigmoid'))\n",
    "#model.add(Dense(10, activation='sigmoid'))\n",
    "#model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=.001))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=10)\n",
    "\n",
    "nn_preds = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-35-236c77614555>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mprint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmean_squared_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnn_preds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0;36m.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'nn_preds' is not defined"
     ]
    }
   ],
   "source": [
    "print (mean_squared_error(y_test,nn_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.918158279204034\n"
     ]
    }
   ],
   "source": [
    "print (mean_absolute_error(y_test,nn_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n",
      "Hello World!\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['C20D1B75A4164F2493A4698E035E1B98']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['C20D1B75A4164F2493A4698E035E1B98'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.FunctionDef object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, ...], cell_name='<ipython-input-10-f68cdd6908ba>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        result = <ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/home/shrikar/Documents/pythonStuff/dsfinalproject/<ipython-input-10-f68cdd6908ba> in <module>()\n     51 batch_size = [20,50,100] # add 5, 10, 20, 40, 60, 80, 100 etc\n     52 param_grid = dict(epochs=epochs, batch_size=batch_size, activation=activations )\n     53 \n     54 #gridSearch\n     55 grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, verbose = 1)\n---> 56 grid_result = grid.fit(X_test, y_test) \n     57 \n     58 \n     59 # summarize results\n     60 print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=1), X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method KFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X =              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns]\n        y = 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed May  2 00:53:55 2018\nPID: 6680                 Python 2.7.14: /home/shrikar/anaconda2/bin/python\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasRegressor object>, X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([1601, 1602, 1603, ..., 4799, 4800, 4801]), test=array([   0,    1,    2, ..., 1598, 1599, 1600]), verbose=1, parameters={'activation': 'relu', 'batch_size': 20, 'epochs': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method KerasRegressor.set_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        parameters = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in set_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, **params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n    108             **params: Dictionary of parameter names mapped to their values.\n    109 \n    110         # Returns\n    111             self\n    112         \"\"\"\n--> 113         self.check_params(params)\n        self.check_params = <bound method KerasRegressor.check_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        params = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    114         self.sk_params.update(params)\n    115         return self\n    116 \n    117     def fit(self, x, y, **kwargs):\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in check_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n     84                 if has_arg(fn, params_name):\n     85                     break\n     86             else:\n     87                 if params_name != 'nb_epoch':\n     88                     raise ValueError(\n---> 89                         '{} is not a legal parameter'.format(params_name))\n        params_name = 'activation'\n     90 \n     91     def get_params(self, **params):\n     92         \"\"\"Gets parameters for this estimator.\n     93 \n\nValueError: activation is not a legal parameter\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJoblibValueError\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-f68cdd6908ba>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;31m#gridSearch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[0mgrid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_grid\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 56\u001B[0;31m \u001B[0mgrid_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    637\u001B[0m                                   error_score=self.error_score)\n\u001B[1;32m    638\u001B[0m           for parameters, (train, test) in product(candidate_params,\n\u001B[0;32m--> 639\u001B[0;31m                                                    cv.split(X, y, groups)))\n\u001B[0m\u001B[1;32m    640\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    641\u001B[0m         \u001B[0;31m# if one choose to see train score, \"out\" will contain train score info\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m    787\u001B[0m                 \u001B[0;31m# consumption.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    788\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 789\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    790\u001B[0m             \u001B[0;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    791\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001B[0m in \u001B[0;36mretrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    738\u001B[0m                     \u001B[0mexception\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexception_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreport\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    739\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 740\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mexception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    741\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    742\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mJoblibValueError\u001B[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['C20D1B75A4164F2493A4698E035E1B98']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['C20D1B75A4164F2493A4698E035E1B98'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.FunctionDef object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, ...], cell_name='<ipython-input-10-f68cdd6908ba>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        result = <ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/home/shrikar/Documents/pythonStuff/dsfinalproject/<ipython-input-10-f68cdd6908ba> in <module>()\n     51 batch_size = [20,50,100] # add 5, 10, 20, 40, 60, 80, 100 etc\n     52 param_grid = dict(epochs=epochs, batch_size=batch_size, activation=activations )\n     53 \n     54 #gridSearch\n     55 grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, verbose = 1)\n---> 56 grid_result = grid.fit(X_test, y_test) \n     57 \n     58 \n     59 # summarize results\n     60 print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=1), X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method KFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X =              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns]\n        y = 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed May  2 00:53:55 2018\nPID: 6680                 Python 2.7.14: /home/shrikar/anaconda2/bin/python\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasRegressor object>, X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([1601, 1602, 1603, ..., 4799, 4800, 4801]), test=array([   0,    1,    2, ..., 1598, 1599, 1600]), verbose=1, parameters={'activation': 'relu', 'batch_size': 20, 'epochs': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method KerasRegressor.set_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        parameters = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in set_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, **params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n    108             **params: Dictionary of parameter names mapped to their values.\n    109 \n    110         # Returns\n    111             self\n    112         \"\"\"\n--> 113         self.check_params(params)\n        self.check_params = <bound method KerasRegressor.check_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        params = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    114         self.sk_params.update(params)\n    115         return self\n    116 \n    117     def fit(self, x, y, **kwargs):\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in check_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n     84                 if has_arg(fn, params_name):\n     85                     break\n     86             else:\n     87                 if params_name != 'nb_epoch':\n     88                     raise ValueError(\n---> 89                         '{} is not a legal parameter'.format(params_name))\n        params_name = 'activation'\n     90 \n     91     def get_params(self, **params):\n     92         \"\"\"Gets parameters for this estimator.\n     93 \n\nValueError: activation is not a legal parameter\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# Refer https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "# Refer https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# Aim of this is to show case use of keras and grid search libraries\n",
    "print(\"Hello World!\")\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "##############################################################\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(346, input_dim=346, activation='relu'))\n",
    "    model.add(Dense(200, activation=activation))\n",
    "    model.add(Dense(100, activation=activation))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "print(\"Hello World!\")\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=1)\n",
    "\n",
    "# Use scikit-learn to grid search \n",
    "activation =  ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'softsign'] # softmax, softplus, softsign\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "learn_rate = [.00001,.0001,0.001, 0.01, 0.1, 0.3]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "weight_constraint=[1, 2, 3, 4, 5]\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "init = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "optimizer = [ 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "\n",
    "# grid search epochs, batch size\n",
    "#learn_rate = [.00001,.0001, 0.001]\n",
    "activations =  ['relu', 'hard_sigmoid', 'softsign'] # softmax, softplus, softsign \n",
    "#dropout_rate = [0.0, 0.3, 0.7,]\n",
    "epochs = [1, 10,50,150] # add 50, 100, 150 etc\n",
    "batch_size = [20,50,100] # add 5, 10, 20, 40, 60, 80, 100 etc\n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size, activation=activations )\n",
    "\n",
    "#gridSearch\n",
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, verbose = 1)\n",
    "grid_result = grid.fit(X_test, y_test) \n",
    "\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-52-4157204f298c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mprint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mgrid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_params_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mngrid_preds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mprint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmean_squared_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mngrid_preds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0;36m.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'grid' is not defined"
     ]
    }
   ],
   "source": [
    "print (grid.best_params_)\n",
    "ngrid_preds = grid.predict(X_test)\n",
    "print (mean_squared_error(y_test,ngrid_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1.1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=1.1, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=1.1, total=   1.2s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=1.1, total=   1.2s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=1e-05, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=1e-05, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=1e-05, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=100, epsilon=2, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=100, epsilon=2, total=   1.1s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=100, epsilon=2, total=   1.5s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=1000, epsilon=2, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=1000, epsilon=2, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=1000, epsilon=2, total=   2.2s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10000, epsilon=2, total=   1.6s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10000, epsilon=2, total=   2.2s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=100, epsilon=10, total=   1.4s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=100, epsilon=10, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=1000, epsilon=10, total=   1.6s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=1000, epsilon=10, total=   3.2s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=1000, epsilon=10, total=   1.6s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10000, epsilon=10, total=   1.9s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10000, epsilon=10, total=   4.2s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10000, epsilon=10, total=   1.2s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=100, total=   1.4s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=100, total=   1.5s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=100, total=   4.0s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=100, total=   1.6s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=100, total=   2.0s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=100, total=   4.1s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=100, total=   1.6s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=100, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=100, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=100, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=1000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=1000, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=1000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=1e-05, max_iter=10000, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=1e-05, max_iter=10000, epsilon=1000, total=   1.9s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1000 .......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=1e-05, max_iter=10000, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=100, epsilon=10000, total=   1.7s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=100, epsilon=10000, total=   2.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=100, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1e-05, max_iter=1000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1e-05, max_iter=1000, epsilon=10000, total=   3.0s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1e-05, max_iter=1000, epsilon=10000, total=   2.0s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=1e-05, max_iter=10000, epsilon=10000, total=   1.7s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=1e-05, max_iter=10000, epsilon=10000, total=   1.8s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=1e-05, max_iter=10000, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=1.1, total=   0.2s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=1.1, total=   1.6s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=1.1, total=   1.4s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1.1 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1.1 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1.1 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=1.1, total=   1.5s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.0001, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.0001, max_iter=10, epsilon=2, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.0001, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=100, epsilon=2, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=100, epsilon=2, total=   1.9s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=100, epsilon=2, total=   1.4s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=1000, epsilon=2, total=   2.3s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=1000, epsilon=2, total=   1.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=2 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=2 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10000, epsilon=2, total=   3.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=2 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10000, epsilon=2, total=   1.2s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=100, epsilon=10, total=   1.7s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=100, epsilon=10, total=   1.4s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=100, epsilon=10, total=   1.1s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=1000, epsilon=10, total=   1.9s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=1000, epsilon=10, total=   2.7s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=1000, epsilon=10, total=   2.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10000, epsilon=10, total=   2.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10000, epsilon=10, total=   3.6s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=100, total=   0.6s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=100, total=   2.6s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=100, total=   1.9s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=100, total=   1.7s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=100, total=   3.8s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=100 .......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=100, total=   1.7s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=100 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=100 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=100, total=   2.8s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10, epsilon=1000, total=   0.6s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10, epsilon=1000, total=   0.7s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=100, epsilon=1000, total=   2.8s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=100, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=100, epsilon=1000, total=   2.4s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=1000, epsilon=1000, total=   2.2s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=1000, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=1000, epsilon=1000, total=   1.9s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=10000, epsilon=1000, total=   2.4s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=10000, epsilon=1000, total=   1.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=10000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10, epsilon=10000, total=   0.5s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=100, epsilon=10000, total=   1.7s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=100, epsilon=10000, total=   1.8s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=100, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=1000, epsilon=10000, total=   3.5s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=1000, epsilon=10000, total=   3.5s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=1000, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10000 .....................\n",
      "[CV] ...... alpha=0.0001, max_iter=10000, epsilon=10000, total=   2.2s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10000 .....................\n",
      "[CV] ...... alpha=0.0001, max_iter=10000, epsilon=10000, total=   2.0s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10000 .....................\n",
      "[CV] ...... alpha=0.0001, max_iter=10000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=1.1, total=   2.1s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=1.1, total=   1.6s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=1.1, total=   1.7s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.001, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.001, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.001, max_iter=10, epsilon=2, total=   0.2s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=100, epsilon=2, total=   0.7s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=100, epsilon=2, total=   1.7s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=100, epsilon=2, total=   1.9s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=1000, epsilon=2, total=   1.8s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=1000, epsilon=2, total=   2.7s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10000, epsilon=2, total=   1.7s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10000, epsilon=2, total=   2.6s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=100, epsilon=10, total=   1.2s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=1000, epsilon=10, total=   3.2s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10 ..........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... alpha=0.001, max_iter=1000, epsilon=10, total=   2.1s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=1000, epsilon=10, total=   1.3s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10000, epsilon=10, total=   3.5s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10000, epsilon=10, total=   2.5s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10000, epsilon=10, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=100, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=100, total=   1.7s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=100, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=100, total=   1.6s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=100, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=100, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=100, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=1000, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=1000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=1000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=10000, epsilon=1000, total=   1.5s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=10000, epsilon=1000, total=   1.9s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=10000, epsilon=1000, total=   1.9s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=100, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=100, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=100, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=1000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=1000, epsilon=10000, total=   2.2s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=1000, epsilon=10000, total=   0.7s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.001, max_iter=10000, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.001, max_iter=10000, epsilon=10000, total=   2.0s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.001, max_iter=10000, epsilon=10000, total=   1.1s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=1.1, total=   1.8s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=1.1, total=   0.9s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=1.1, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=1.1, total=   2.9s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.01, max_iter=10, epsilon=2, total=   0.2s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.01, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.01, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.01, max_iter=100, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.01, max_iter=100, epsilon=2, total=   2.2s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=2 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=0.01, max_iter=100, epsilon=2, total=   1.9s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=1000, epsilon=2, total=   1.7s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=1000, epsilon=2, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10000, epsilon=2, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10000, epsilon=2, total=   1.2s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10000, epsilon=2, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.01, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.01, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.01, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=100, epsilon=10, total=   1.3s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=100, epsilon=10, total=   1.7s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=100, epsilon=10, total=   1.0s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=1000, epsilon=10, total=   2.0s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=1000, epsilon=10, total=   1.6s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=1000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10000, epsilon=10, total=   2.0s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10000, epsilon=10, total=   1.6s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10000, epsilon=10, total=   1.0s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=100, total=   1.7s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=100, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=100, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=100, total=   1.8s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=100, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=100, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10, epsilon=1000, total=   0.5s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=100, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=100, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=100, epsilon=1000, total=   1.6s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=1000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=1000, epsilon=1000, total=   1.1s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=1000, epsilon=1000, total=   2.1s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=10000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=10000, epsilon=1000, total=   1.1s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=10000, epsilon=1000, total=   2.1s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=100, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=100, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=100, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=1000, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=1000, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=1000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.01, max_iter=10000, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.01, max_iter=10000, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.01, max_iter=10000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1.1 ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=1.1, total=   0.9s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=1.1, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=1.1, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=1.1, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=0.1, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=0.1, max_iter=10, epsilon=2, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=0.1, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=100, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=100, epsilon=2, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=100, epsilon=2, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=1000, epsilon=2, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=1000, epsilon=2, total=   1.7s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10000, epsilon=2, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10000, epsilon=2, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=100, epsilon=10, total=   1.0s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=100, epsilon=10, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=1000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=1000, epsilon=10, total=   2.2s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=1000, epsilon=10, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=10000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=10000, epsilon=10, total=   2.4s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=10000, epsilon=10, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=100, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=100, total=   0.8s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=100, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=100, total=   0.8s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=100, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=100, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=100, epsilon=1000, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=100, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=1000, epsilon=1000, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=1000, epsilon=1000, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=1000, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=10000, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=10000, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=10000, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10000 ...........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ alpha=0.1, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=10, epsilon=10000, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=100, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=100, epsilon=10000, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=100, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=1000, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=1000, epsilon=10000, total=   3.4s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=1000, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.1, max_iter=10000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.1, max_iter=10000, epsilon=10000, total=   3.0s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.1, max_iter=10000, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1.1 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1.1 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1.1 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=1.1, total=   1.7s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=1.1, total=   2.2s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1, max_iter=10000, epsilon=1.1, total=   0.9s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1, max_iter=10000, epsilon=1.1, total=   2.2s\n",
      "[CV] alpha=1, max_iter=10, epsilon=2 .................................\n",
      "[CV] .................. alpha=1, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1, max_iter=10, epsilon=2 .................................\n",
      "[CV] .................. alpha=1, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1, max_iter=10, epsilon=2 .................................\n",
      "[CV] .................. alpha=1, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1, max_iter=100, epsilon=2 ................................\n",
      "[CV] ................. alpha=1, max_iter=100, epsilon=2, total=   0.5s\n",
      "[CV] alpha=1, max_iter=100, epsilon=2 ................................\n",
      "[CV] ................. alpha=1, max_iter=100, epsilon=2, total=   1.5s\n",
      "[CV] alpha=1, max_iter=100, epsilon=2 ................................\n",
      "[CV] ................. alpha=1, max_iter=100, epsilon=2, total=   1.8s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=2 ...............................\n",
      "[CV] ................ alpha=1, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=2 ...............................\n",
      "[CV] ................ alpha=1, max_iter=1000, epsilon=2, total=   1.2s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=2 ...............................\n",
      "[CV] ................ alpha=1, max_iter=1000, epsilon=2, total=   2.3s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10000, epsilon=2, total=   1.3s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10000, epsilon=2, total=   2.1s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10 ................................\n",
      "[CV] ................. alpha=1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10 ................................\n",
      "[CV] ................. alpha=1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10 ................................\n",
      "[CV] ................. alpha=1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10 ...............................\n",
      "[CV] ................ alpha=1, max_iter=100, epsilon=10, total=   1.2s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10 ...............................\n",
      "[CV] ................ alpha=1, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10 ...............................\n",
      "[CV] ................ alpha=1, max_iter=100, epsilon=10, total=   1.2s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10 ..............................\n",
      "[CV] ............... alpha=1, max_iter=1000, epsilon=10, total=   1.2s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10 ..............................\n",
      "[CV] ............... alpha=1, max_iter=1000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10 ..............................\n",
      "[CV] ............... alpha=1, max_iter=1000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10 .............................\n",
      "[CV] .............. alpha=1, max_iter=10000, epsilon=10, total=   1.2s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10 .............................\n",
      "[CV] .............. alpha=1, max_iter=10000, epsilon=10, total=   1.7s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10 .............................\n",
      "[CV] .............. alpha=1, max_iter=10000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=1, max_iter=10, epsilon=100 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=100 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=100 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=1, max_iter=100, epsilon=100 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=100, total=   2.1s\n",
      "[CV] alpha=1, max_iter=100, epsilon=100 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=100, total=   3.2s\n",
      "[CV] alpha=1, max_iter=100, epsilon=100 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=100, total=   2.2s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=100 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=100, total=   2.2s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=100 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=100, total=   1.8s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=100 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=100, total=   1.7s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=100 ............................\n",
      "[CV] ............. alpha=1, max_iter=10000, epsilon=100, total=   1.8s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=100 ............................\n",
      "[CV] ............. alpha=1, max_iter=10000, epsilon=100, total=   1.8s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=100 ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=1, max_iter=10000, epsilon=100, total=   1.6s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1000 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1000 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1000 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1000 .............................\n",
      "[CV] .............. alpha=1, max_iter=100, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1000 .............................\n",
      "[CV] .............. alpha=1, max_iter=100, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1000 .............................\n",
      "[CV] .............. alpha=1, max_iter=100, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1000 ............................\n",
      "[CV] ............. alpha=1, max_iter=1000, epsilon=1000, total=   1.9s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1000 ............................\n",
      "[CV] ............. alpha=1, max_iter=1000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1000 ............................\n",
      "[CV] ............. alpha=1, max_iter=1000, epsilon=1000, total=   2.1s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=10000, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=10000, epsilon=1000, total=   2.4s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=10000, epsilon=1000, total=   2.2s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10000 .............................\n",
      "[CV] .............. alpha=1, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10000 .............................\n",
      "[CV] .............. alpha=1, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10000 .............................\n",
      "[CV] .............. alpha=1, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10000 ............................\n",
      "[CV] ............. alpha=1, max_iter=100, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10000 ............................\n",
      "[CV] ............. alpha=1, max_iter=100, epsilon=10000, total=   1.8s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10000 ............................\n",
      "[CV] ............. alpha=1, max_iter=100, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=1000, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=1000, epsilon=10000, total=   2.1s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=1000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1, max_iter=10000, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1, max_iter=10000, epsilon=10000, total=   2.1s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1, max_iter=10000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=1.1, total=   0.9s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10, epsilon=2 ................................\n",
      "[CV] ................. alpha=10, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=10, max_iter=10, epsilon=2 ................................\n",
      "[CV] ................. alpha=10, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=10, max_iter=10, epsilon=2 ................................\n",
      "[CV] ................. alpha=10, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=10, max_iter=100, epsilon=2 ...............................\n",
      "[CV] ................ alpha=10, max_iter=100, epsilon=2, total=   0.6s\n",
      "[CV] alpha=10, max_iter=100, epsilon=2 ...............................\n",
      "[CV] ................ alpha=10, max_iter=100, epsilon=2, total=   1.7s\n",
      "[CV] alpha=10, max_iter=100, epsilon=2 ...............................\n",
      "[CV] ................ alpha=10, max_iter=100, epsilon=2, total=   1.7s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=10, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=10, max_iter=1000, epsilon=2, total=   1.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=10, max_iter=1000, epsilon=2, total=   1.8s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=2 .............................\n",
      "[CV] .............. alpha=10, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=2 .............................\n",
      "[CV] .............. alpha=10, max_iter=10000, epsilon=2, total=   1.7s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=2 .............................\n",
      "[CV] .............. alpha=10, max_iter=10000, epsilon=2, total=   1.8s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10 ...............................\n",
      "[CV] ................ alpha=10, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10 ...............................\n",
      "[CV] ................ alpha=10, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10 ...............................\n",
      "[CV] ................ alpha=10, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10 ..............................\n",
      "[CV] ............... alpha=10, max_iter=100, epsilon=10, total=   1.3s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10 ..............................\n",
      "[CV] ............... alpha=10, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10 ..............................\n",
      "[CV] ............... alpha=10, max_iter=100, epsilon=10, total=   1.1s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10 .............................\n",
      "[CV] .............. alpha=10, max_iter=1000, epsilon=10, total=   1.3s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10 .............................\n",
      "[CV] .............. alpha=10, max_iter=1000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10 .............................\n",
      "[CV] .............. alpha=10, max_iter=1000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10 ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=10, max_iter=10000, epsilon=10, total=   1.4s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10 ............................\n",
      "[CV] ............. alpha=10, max_iter=10000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10 ............................\n",
      "[CV] ............. alpha=10, max_iter=10000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=10, max_iter=10, epsilon=100 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=100 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=100 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=10, max_iter=100, epsilon=100 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=100, total=   1.0s\n",
      "[CV] alpha=10, max_iter=100, epsilon=100 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=100, total=   1.7s\n",
      "[CV] alpha=10, max_iter=100, epsilon=100 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=100, total=   0.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=100 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=100 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=100, total=   2.0s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=100 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=100, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=100, total=   2.1s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=100, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1000 .............................\n",
      "[CV] .............. alpha=10, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1000 .............................\n",
      "[CV] .............. alpha=10, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1000 .............................\n",
      "[CV] .............. alpha=10, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1000 ............................\n",
      "[CV] ............. alpha=10, max_iter=100, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1000 ............................\n",
      "[CV] ............. alpha=10, max_iter=100, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1000 ............................\n",
      "[CV] ............. alpha=10, max_iter=100, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=1000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=1000, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=1000, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=10000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=10000, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=10000, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10000 ............................\n",
      "[CV] ............. alpha=10, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10000 ............................\n",
      "[CV] ............. alpha=10, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10000 ............................\n",
      "[CV] ............. alpha=10, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=100, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=100, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=100, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=1000, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=1000, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=1000, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=10, max_iter=10000, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=10, max_iter=10000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=10, max_iter=10000, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=100, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=100, max_iter=10, epsilon=2, total=   0.4s\n",
      "[CV] alpha=100, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=100, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=100, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=100, max_iter=100, epsilon=2, total=   0.5s\n",
      "[CV] alpha=100, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=100, max_iter=100, epsilon=2, total=   1.6s\n",
      "[CV] alpha=100, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=100, max_iter=100, epsilon=2, total=   0.9s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=2 .............................\n",
      "[CV] .............. alpha=100, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=2 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=100, max_iter=1000, epsilon=2, total=   1.5s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=2 .............................\n",
      "[CV] .............. alpha=100, max_iter=1000, epsilon=2, total=   0.9s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=100, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=100, max_iter=10000, epsilon=2, total=   1.5s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=100, max_iter=10000, epsilon=2, total=   0.9s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=100, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=100, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=100, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=100, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=100, max_iter=100, epsilon=10, total=   1.4s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=100, max_iter=100, epsilon=10, total=   1.4s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=100, max_iter=1000, epsilon=10, total=   2.1s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=100, max_iter=1000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=100, max_iter=1000, epsilon=10, total=   1.4s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10000, epsilon=10, total=   2.1s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10000, epsilon=10, total=   1.4s\n",
      "[CV] alpha=100, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=100, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=100, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=100, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=100, total=   1.1s\n",
      "[CV] alpha=100, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=100, total=   1.8s\n",
      "[CV] alpha=100, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=100, total=   0.9s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=100, total=   1.6s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=100, total=   1.4s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=100, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=100, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=100, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=100, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=100, epsilon=1000, total=   1.5s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=100, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=100, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=1000, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=1000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=1000, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=100, max_iter=10000, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=100, max_iter=10000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=100, max_iter=10000, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=100, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=100, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=100, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=100, max_iter=1000, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=100, max_iter=1000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=100, max_iter=1000, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=100, max_iter=10000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=100, max_iter=10000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=100, max_iter=10000, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=1.1, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=1.1, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=1.1, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=100, epsilon=1.1, total=   1.2s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1.1 ...........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ alpha=1000, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=1.1, total=   1.2s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=1.1, total=   1.4s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1000, max_iter=10, epsilon=2, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1000, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1000, max_iter=10, epsilon=2, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=2 .............................\n",
      "[CV] .............. alpha=1000, max_iter=100, epsilon=2, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=2 .............................\n",
      "[CV] .............. alpha=1000, max_iter=100, epsilon=2, total=   1.6s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=2 .............................\n",
      "[CV] .............. alpha=1000, max_iter=100, epsilon=2, total=   1.3s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=1000, max_iter=1000, epsilon=2, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=1000, max_iter=1000, epsilon=2, total=   1.6s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=1000, max_iter=1000, epsilon=2, total=   1.3s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10000, epsilon=2, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10000, epsilon=2, total=   1.6s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10000, epsilon=2, total=   1.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=1000, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=1000, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=1000, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=1000, max_iter=100, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=1000, max_iter=100, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=1000, max_iter=100, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=1000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=1000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=1000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=100, epsilon=100, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=100, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=100, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=100, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=100, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=100, epsilon=1000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=100, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=100, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1000, max_iter=1000, epsilon=1000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1000, max_iter=1000, epsilon=1000, total=   1.1s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1000, max_iter=1000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=10000, epsilon=1000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=10000, epsilon=1000, total=   1.1s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=10000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10000 .........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... alpha=1000, max_iter=100, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10000 .........................\n",
      "[CV] .......... alpha=1000, max_iter=100, epsilon=10000, total=   1.1s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10000 .........................\n",
      "[CV] .......... alpha=1000, max_iter=100, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=1000, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=1000, epsilon=10000, total=   1.1s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=1000, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1000, max_iter=10000, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1000, max_iter=10000, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1000, max_iter=10000, epsilon=10000, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 648 out of 648 | elapsed: 12.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.710401073583229\n"
     ]
    }
   ],
   "source": [
    "parameters = { #when use hyperthread, xgboost may become slower\n",
    "              'epsilon':[1.1,2,10,100,1000,10000],# dart is nice but far too slow\n",
    "              'max_iter':[10,100,1000,10000],\n",
    "              'alpha':[.00001,.0001,.001,.01,.1,1,10,100,1000],\n",
    "}\n",
    "hr_model = HuberRegressor()\n",
    "\n",
    "gridHR = GridSearchCV(hr_model, param_grid=parameters,scoring = scoring, cv=3, verbose=2, refit = 'mean')\n",
    "gridHR.fit(X_train,y_train)\n",
    "hr_preds = gridHR.predict(X_test)\n",
    "print (mean_squared_error(y_test,hr_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Final Project - EE 379k - sp18 - \n",
    "\n",
    "# Shahshank Kambhampati - skk834, Shrikara Murthy - svm456, Pranav Harathi - , Neil Charles - \n",
    "\n",
    "# Job Satisfaction Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "### All hail lord and savior XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, LogisticRegression, Ridge, Lasso, HuberRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomTreesEmbedding, AdaBoostClassifier, AdaBoostRegressor, RandomForestRegressor, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectKBest,  chi2\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from __future__ import print_function\n",
    "%config inlinebackend.figure_format = 'retina' \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Observations about the Data and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number = re.compile('[\\d,]+')\n",
    "def get_first_number(val):\n",
    "    matched = number.match(str(val))\n",
    "    if matched:\n",
    "        return int(matched.group())\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "satisfaction_strs = {\n",
    "    'I love my job': 10,\n",
    "    'I\\'m somewhat satisfied with my job': 7.5,\n",
    "    'I\\'m neither satisfied nor dissatisfied with my job': 5,\n",
    "    'I\\'m somewhat dissatisfied with my job': 2.5,\n",
    "    'I hate my job': 0,\n",
    "}\n",
    "\n",
    "binary_labels = [\n",
    "    'Lang & Tech',\n",
    "    'Training & Education',\n",
    "    'How can companies improve interview process',\n",
    "    'Why try Stack Overflow Careers',\n",
    "    'Most important aspect of new job opportunity',\n",
    "    'Most annoying about job search',\n",
    "    'Appealing message traits',\n",
    "    'Most urgent info about job opportunity',\n",
    "    'Who do you want to communicate with about a new job opportunity',\n",
    "    'Why use Stack Overflow',\n",
    "    'Why answer',\n",
    "    'Source control used',\n",
    "]\n",
    "\n",
    "numeric_labels = [\n",
    "    'Age',\n",
    "    'Years IT / Programming Experience',\n",
    "    'Compensation: midpoint'\n",
    "]\n",
    "\n",
    "yes_no_labels = [\n",
    "    'Changed Jobs in last 12 Months'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaNs:\n",
      "Age\n",
      "Years IT / Programming Experience\n",
      "Compensation: midpoint\n",
      "Filling with mean of column\n"
     ]
    }
   ],
   "source": [
    "# 2015 preproc\n",
    "data = pd.read_csv('data/2015.csv')\n",
    "to_drop = [label for label in data if 'write-in' in label.lower()]\n",
    "\n",
    "data['Job Satisfaction'] = data['Job Satisfaction']\\\n",
    "                                    .map(satisfaction_strs).astype('float')\n",
    "data = data[data['Job Satisfaction'].notnull()]\n",
    "to_drop.append('Country')\n",
    "to_drop.append('Compensation')\n",
    "\n",
    "data['Age'] = data['Age'].map(get_first_number).astype('float')\n",
    "data['gender_M'] = (data['Gender'] == 'Male').astype('int8')\n",
    "data['gender_F'] = (data['Gender'] == 'Female').astype('int8')\n",
    "to_drop.append('Gender')\n",
    "to_drop.append('Prefered Source Control')\n",
    "\n",
    "bin_labels = [key for key in data if any(label in key for label in binary_labels)]\n",
    "data[bin_labels] = data[bin_labels].apply(lambda col: col.notnull().astype('int8'))\n",
    "\n",
    "data[numeric_labels] = data[numeric_labels].applymap(get_first_number)\n",
    "data[yes_no_labels] = data[yes_no_labels]\\\n",
    "                                .apply(lambda col: col.map({'Yes': 1, 'No': 0}))\\\n",
    "                                .fillna(0)\n",
    "\n",
    "data.drop(to_drop, axis=1, inplace=True)\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "print(\"Columns with NaNs:\")\n",
    "\n",
    "for key in data:\n",
    "    if data[key].isnull().any():\n",
    "        print (key)\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "print ('Filling with mean of column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data contains a DataFrame with no NaNs, all numbers.\n",
    "# We're trying to predict the \"Job Satisfaction\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = data[['Compensation: midpoint','Purchasing Power_I have no say in purchasing what I need or want at work','Remote Status_Never','Changed Jobs in last 12 Months']]\n",
    "X = data.drop('Job Satisfaction',axis=1)\n",
    "y = data['Job Satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)#stratify=y\n",
    "scoring = {'mean': make_scorer(mean_squared_error)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Years IT / Programming Experience  Current Lang & Tech: Android  \\\n",
      "0  25.0                                2.0                             0   \n",
      "1  20.0                                1.0                             0   \n",
      "2  20.0                                1.0                             0   \n",
      "3  25.0                                6.0                             0   \n",
      "4  30.0                                2.0                             0   \n",
      "\n",
      "   Current Lang & Tech: Arduino  Current Lang & Tech: AngularJS  \\\n",
      "0                             0                               0   \n",
      "1                             0                               0   \n",
      "2                             0                               0   \n",
      "3                             0                               0   \n",
      "4                             0                               0   \n",
      "\n",
      "   Current Lang & Tech: C  Current Lang & Tech: C++  \\\n",
      "0                       0                         0   \n",
      "1                       0                         0   \n",
      "2                       0                         0   \n",
      "3                       0                         0   \n",
      "4                       0                         0   \n",
      "\n",
      "   Current Lang & Tech: C++11  Current Lang & Tech: C#  \\\n",
      "0                           0                        0   \n",
      "1                           0                        1   \n",
      "2                           0                        1   \n",
      "3                           0                        0   \n",
      "4                           0                        1   \n",
      "\n",
      "   Current Lang & Tech: Cassandra  \\\n",
      "0                               0   \n",
      "1                               0   \n",
      "2                               0   \n",
      "3                               0   \n",
      "4                               0   \n",
      "\n",
      "                            ...                            \\\n",
      "0                           ...                             \n",
      "1                           ...                             \n",
      "2                           ...                             \n",
      "3                           ...                             \n",
      "4                           ...                             \n",
      "\n",
      "   Preferred text editor_XEmacs  Preferred text editor_atom.io  \\\n",
      "0                           0.0                            0.0   \n",
      "1                           0.0                            0.0   \n",
      "2                           1.0                            0.0   \n",
      "3                           0.0                            0.0   \n",
      "4                           0.0                            0.0   \n",
      "\n",
      "   Prefered IDE theme_Dark  Prefered IDE theme_I don't use an IDE  \\\n",
      "0                      1.0                                    0.0   \n",
      "1                      0.0                                    0.0   \n",
      "2                      1.0                                    0.0   \n",
      "3                      1.0                                    0.0   \n",
      "4                      1.0                                    0.0   \n",
      "\n",
      "   Prefered IDE theme_Light  \\\n",
      "0                       0.0   \n",
      "1                       1.0   \n",
      "2                       0.0   \n",
      "3                       0.0   \n",
      "4                       0.0   \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Always  \\\n",
      "0                                                0.0       \n",
      "1                                                0.0       \n",
      "2                                                0.0       \n",
      "3                                                0.0       \n",
      "4                                                0.0       \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Never  \\\n",
      "0                                                0.0      \n",
      "1                                                0.0      \n",
      "2                                                0.0      \n",
      "3                                                0.0      \n",
      "4                                                0.0      \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Rarely  \\\n",
      "0                                                0.0       \n",
      "1                                                0.0       \n",
      "2                                                1.0       \n",
      "3                                                0.0       \n",
      "4                                                0.0       \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Sometimes  \\\n",
      "0                                                0.0          \n",
      "1                                                0.0          \n",
      "2                                                0.0          \n",
      "3                                                0.0          \n",
      "4                                                0.0          \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Usually  \n",
      "0                                                1.0       \n",
      "1                                                1.0       \n",
      "2                                                0.0       \n",
      "3                                                1.0       \n",
      "4                                                1.0       \n",
      "\n",
      "[5 rows x 347 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Age  Years IT / Programming Experience  \\\n",
      "count  16004.000000                       16004.000000   \n",
      "mean      28.478348                           5.839325   \n",
      "std        6.955481                           3.850501   \n",
      "min       20.000000                           1.000000   \n",
      "25%       25.000000                           2.000000   \n",
      "50%       25.000000                           6.000000   \n",
      "75%       30.000000                          11.000000   \n",
      "max       51.000000                          11.000000   \n",
      "\n",
      "       Current Lang & Tech: Android  Current Lang & Tech: Arduino  \\\n",
      "count                  16004.000000                  16004.000000   \n",
      "mean                       0.173269                      0.061110   \n",
      "std                        0.378492                      0.239539   \n",
      "min                        0.000000                      0.000000   \n",
      "25%                        0.000000                      0.000000   \n",
      "50%                        0.000000                      0.000000   \n",
      "75%                        0.000000                      0.000000   \n",
      "max                        1.000000                      1.000000   \n",
      "\n",
      "       Current Lang & Tech: AngularJS  Current Lang & Tech: C  \\\n",
      "count                    16004.000000            16004.000000   \n",
      "mean                         0.147713                0.131280   \n",
      "std                          0.354826                0.337717   \n",
      "min                          0.000000                0.000000   \n",
      "25%                          0.000000                0.000000   \n",
      "50%                          0.000000                0.000000   \n",
      "75%                          0.000000                0.000000   \n",
      "max                          1.000000                1.000000   \n",
      "\n",
      "       Current Lang & Tech: C++  Current Lang & Tech: C++11  \\\n",
      "count              16004.000000                16004.000000   \n",
      "mean                   0.171270                    0.069733   \n",
      "std                    0.376756                    0.254704   \n",
      "min                    0.000000                    0.000000   \n",
      "25%                    0.000000                    0.000000   \n",
      "50%                    0.000000                    0.000000   \n",
      "75%                    0.000000                    0.000000   \n",
      "max                    1.000000                    1.000000   \n",
      "\n",
      "       Current Lang & Tech: C#  Current Lang & Tech: Cassandra  \\\n",
      "count             16004.000000                    16004.000000   \n",
      "mean                  0.334416                        0.010122   \n",
      "std                   0.471801                        0.100103   \n",
      "min                   0.000000                        0.000000   \n",
      "25%                   0.000000                        0.000000   \n",
      "50%                   0.000000                        0.000000   \n",
      "75%                   1.000000                        0.000000   \n",
      "max                   1.000000                        1.000000   \n",
      "\n",
      "                                ...                            \\\n",
      "count                           ...                             \n",
      "mean                            ...                             \n",
      "std                             ...                             \n",
      "min                             ...                             \n",
      "25%                             ...                             \n",
      "50%                             ...                             \n",
      "75%                             ...                             \n",
      "max                             ...                             \n",
      "\n",
      "       Preferred text editor_XEmacs  Preferred text editor_atom.io  \\\n",
      "count                  16004.000000                   16004.000000   \n",
      "mean                       0.002374                       0.021995   \n",
      "std                        0.048672                       0.146670   \n",
      "min                        0.000000                       0.000000   \n",
      "25%                        0.000000                       0.000000   \n",
      "50%                        0.000000                       0.000000   \n",
      "75%                        0.000000                       0.000000   \n",
      "max                        1.000000                       1.000000   \n",
      "\n",
      "       Prefered IDE theme_Dark  Prefered IDE theme_I don't use an IDE  \\\n",
      "count             16004.000000                           16004.000000   \n",
      "mean                  0.428268                               0.059548   \n",
      "std                   0.494843                               0.236654   \n",
      "min                   0.000000                               0.000000   \n",
      "25%                   0.000000                               0.000000   \n",
      "50%                   0.000000                               0.000000   \n",
      "75%                   1.000000                               0.000000   \n",
      "max                   1.000000                               1.000000   \n",
      "\n",
      "       Prefered IDE theme_Light  \\\n",
      "count              16004.000000   \n",
      "mean                   0.343227   \n",
      "std                    0.474801   \n",
      "min                    0.000000   \n",
      "25%                    0.000000   \n",
      "50%                    0.000000   \n",
      "75%                    1.000000   \n",
      "max                    1.000000   \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Always  \\\n",
      "count                                       16004.000000       \n",
      "mean                                            0.079668       \n",
      "std                                             0.270786       \n",
      "min                                             0.000000       \n",
      "25%                                             0.000000       \n",
      "50%                                             0.000000       \n",
      "75%                                             0.000000       \n",
      "max                                             1.000000       \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Never  \\\n",
      "count                                       16004.000000      \n",
      "mean                                            0.000812      \n",
      "std                                             0.028490      \n",
      "min                                             0.000000      \n",
      "25%                                             0.000000      \n",
      "50%                                             0.000000      \n",
      "75%                                             0.000000      \n",
      "max                                             1.000000      \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Rarely  \\\n",
      "count                                       16004.000000       \n",
      "mean                                            0.003687       \n",
      "std                                             0.060607       \n",
      "min                                             0.000000       \n",
      "25%                                             0.000000       \n",
      "50%                                             0.000000       \n",
      "75%                                             0.000000       \n",
      "max                                             1.000000       \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Sometimes  \\\n",
      "count                                       16004.000000          \n",
      "mean                                            0.108660          \n",
      "std                                             0.311222          \n",
      "min                                             0.000000          \n",
      "25%                                             0.000000          \n",
      "50%                                             0.000000          \n",
      "75%                                             0.000000          \n",
      "max                                             1.000000          \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Usually  \n",
      "count                                       16004.000000       \n",
      "mean                                            0.634404       \n",
      "std                                             0.481612       \n",
      "min                                             0.000000       \n",
      "25%                                             0.000000       \n",
      "50%                                             1.000000       \n",
      "75%                                             1.000000       \n",
      "max                                             1.000000       \n",
      "\n",
      "[8 rows x 347 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open to new job opportunities_I am actively looking for a new job                          -0.261420\n",
      "Open to new job opportunities_I am open to new job opportunities                           -0.176831\n",
      "Purchasing Power_I have no say in purchasing what I need or want at work                   -0.164541\n",
      "Remote Status_Never                                                                        -0.137992\n",
      "Perception of recruiter contact_I wish more recruiters contacted me!                       -0.135077\n",
      "Most annoying about job search: Finding job I'm qualified for                              -0.096418\n",
      "Perception of contact form: Email_Great                                                    -0.091982\n",
      "Perception of contact form: Stack Overflow Careers_Great                                   -0.087447\n",
      "Why try Stack Overflow Careers: Jobs site for programmers                                  -0.078943\n",
      "Appealing message traits: Salary information                                               -0.069400\n",
      "Most annoying about job search: Taking time off work to interview                          -0.068056\n",
      "Who do you want to communicate with about a new job opportunity: In-house recruiter        -0.066069\n",
      "Who do you want to communicate with about a new job opportunity: Developer                 -0.066019\n",
      "Who do you want to communicate with about a new job opportunity: Manager                   -0.064743\n",
      "Who do you want to communicate with about a new job opportunity: In-house tech recruiter   -0.063494\n",
      "How can companies improve interview process: Flexible interview schedule                   -0.061611\n",
      "Who do you want to communicate with about a new job opportunity: Headhunter                -0.061126\n",
      "Appealing message traits: Benefits & Perks                                                 -0.061064\n",
      "Perception of contact form: Xing_I don't have an account                                   -0.059816\n",
      "Perception of contact form: LinkedIn_Great                                                 -0.056304\n",
      "Most urgent info about job opportunity: Tech stack                                         -0.055674\n",
      "Desktop Operating System_Windows 7                                                         -0.054349\n",
      "Why try Stack Overflow Careers: Jobs are on Stack Overflow                                 -0.052858\n",
      "Employment Status_Employed full-time                                                       -0.051188\n",
      "Perception of contact form: Phone_Tolerate                                                 -0.050408\n",
      "Preferred text editor_NotePad++                                                            -0.049123\n",
      "Most annoying about job search: Finding interesting job                                    -0.048531\n",
      "Appealing message traits: Team described                                                   -0.048329\n",
      "Most annoying about job search: Interesting companies rarely respond                       -0.048258\n",
      "Why try Stack Overflow Careers: Selection of revelant jobs                                 -0.048190\n",
      "                                                                                              ...   \n",
      "Current Lang & Tech: Cloud                                                                  0.030571\n",
      "Future Lang & Tech: JavaScript                                                              0.030888\n",
      "Current Lang & Tech: Redis                                                                  0.031731\n",
      "Current Lang & Tech: Objective-C                                                            0.032213\n",
      "Perception of contact form: Stack Overflow Careers_Hate                                     0.032683\n",
      "Current Lang & Tech: PHP                                                                    0.032788\n",
      "Current Lang & Tech: JavaScript                                                             0.034507\n",
      "Current Lang & Tech: AngularJS                                                              0.034955\n",
      "Current Lang & Tech: iOS                                                                    0.035125\n",
      "Future Lang & Tech: PHP                                                                     0.035510\n",
      "Industry_Web Services                                                                       0.037380\n",
      "Years IT / Programming Experience                                                           0.038563\n",
      "Current Lang & Tech: Node.js                                                                0.041067\n",
      "Industry_Software Products                                                                  0.042618\n",
      "Desktop Operating System_Mac OS X                                                           0.046400\n",
      "How important is remote when evaluating new job opportunity?_It's non-negotiable            0.047050\n",
      "Employment Status_Freelance / Contractor                                                    0.049061\n",
      "Appealing message traits: Code or projects mentioned                                        0.049100\n",
      "Employment Status_Other                                                                     0.050034\n",
      "Occupation_Executive (VP of Eng., CTO, CIO, etc.)                                           0.053755\n",
      "Purchasing Power_I have a discretionary budget at my disposal                               0.054428\n",
      "Perception of contact form: Email_Hate                                                      0.056162\n",
      "Remote Status_Part-time Remote                                                              0.060221\n",
      "Perception of recruiter contact_Please, make the recruiter spamŒæstop                       0.065541\n",
      "Changed Jobs in last 12 Months                                                              0.066034\n",
      "Remote Status_Full-time Remote                                                              0.074636\n",
      "Compensation: midpoint                                                                      0.085901\n",
      "Purchasing Power_I can buy anything I want without asking anyone                            0.122394\n",
      "Open to new job opportunities_I am not interested in other job opportunities                0.335079\n",
      "Job Satisfaction                                                                            1.000000\n",
      "Name: Job Satisfaction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "c = data.corr()\n",
    "print(c['Job Satisfaction'].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "rfe = RFE(model, 50,2)\n",
    "rfe = rfe.fit(X_train,y_train)\n",
    "X_train = rfe.transform(X_train)\n",
    "X_test = rfe.transform(X_test)\n",
    "#rfe_preds = rfe.predict(X_test)\n",
    "#print mean_squared_error(y_test,rfe_preds)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "print rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators':[160]\n",
    "}\n",
    "modelETC = ExtraTreesRegressor()\n",
    "gridETC = GridSearchCV(modelETC, param_grid=parameters,scoring = scoring, cv=5, refit = 'mean',verbose=1)\n",
    "gridETC.fit(X_train,y_train)\n",
    "print(gridETC.best_params_)\n",
    "#print(modelETC.feature_importances_)\n",
    "etc_preds = gridETC.predict(X_test)\n",
    "print (mean_squared_error(y_test,etc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (mean_squared_error(y_test,etc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.471834236419676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7feeac38f990>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuYAAAEZCAYAAADbteACAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPN9TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee75f0b990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "#gridXGB = GridSearchCV(xgb_model, param_grid=parameters,scoring = scoring, cv=3, verbose=2, refit = 'mean')\n",
    "#gridXGB.fit(X_train, y_train,eval_metric='rmse')\n",
    "#print(gridXGB.best_params_)\n",
    "#xgb_preds = gridXGB.predict(X_test)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "print (mean_squared_error(y_test,xgb_preds)**.5)\n",
    "#xgb_copy = list(xgb_preds)\n",
    "xgb_model.fit(X, y)\n",
    "xgb_model._Booster.save_model('output2015.model')\n",
    "xgb.plot_importance(xgb_model,max_num_features = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.33352], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model._Booster.predict(xgb.DMatrix([0.0,0.0,0.0,0.0], feature_names=[u'Compensation: midpoint', u'Purchasing Power_I have no say in purchasing what I need or want at work', u'Remote Status_Never', u'Changed Jobs in last 12 Months']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = { #when use hyperthread, xgboost may become slower\n",
    "              'booster':['gbtree'],# dart is nice but far too slow\n",
    "              'learning_rate': [.01], #\n",
    "              'max_depth': [7],#1,3,5,6,7,8,10\n",
    "              'min_child_weight': [8],#1,3,5,7,8,9,10\n",
    "              'reg_alpha':[.01],#.0001,.001,.01,.1,1,10\n",
    "              'silent': [0],\n",
    "              'subsample': [.6],#.6,.7,.8,.9\n",
    "              'gamma':[.001],#.1,.01,.001.,.005,0\n",
    "              'colsample_bytree': [.8],#.6,.7,.8,.9\n",
    "              'n_estimators': [10000], \n",
    "              'seed': [1337]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree \n",
      "[CV]  reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree, total=21.1min\n",
      "[CV] reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 21.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree, total=25.0min\n",
      "[CV] reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree \n",
      "[CV]  reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree, total=21.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 68.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2666836788652214\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "gridXGB = GridSearchCV(xgb_model, param_grid=parameters,scoring = scoring, cv=3, verbose=2, refit = 'mean')\n",
    "gridXGB.fit(X_train, y_train,eval_metric='rmse')\n",
    "#print(gridXGB.best_params_)\n",
    "xgb_preds = gridXGB.predict(X_test)\n",
    "#xgb_model.fit(X_train, y_train)\n",
    "#xgb_preds = xgb_model.predict(X_test)\n",
    "print (mean_squared_error(y_test,xgb_preds)**.5)\n",
    "#xgb_copy = list(xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gridXGB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-fed3b56b9277>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgridXGB\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_params_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'gridXGB' is not defined"
     ]
    }
   ],
   "source": [
    "print(gridXGB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.322300794571225\n"
     ]
    }
   ],
   "source": [
    "print (mean_squared_error(y_test,xgb_preds)**.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "7.492633136249195\n"
     ]
    }
   ],
   "source": [
    "print (sum(y_test)/len(y_test))\n",
    "print (sum(xgb_preds)/len(xgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.580892773519512\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators':[1],\n",
    "    'learning_rate':[.1]\n",
    "   # 'base_estimator':[ExtraTreesClassifier(160,class_weight='balanced')]\n",
    "   # 'base_estimator':[grid]\n",
    "}\n",
    "modelABC = AdaBoostRegressor(base_estimator=xgb.XGBRegressor(reg_alpha=.01, colsample_bytree=.8, \n",
    "                                silent=0, learning_rate=.01, min_child_weight=8, n_estimators=10000, \n",
    "                                            subsample=.6, max_depth=7,gamma=.001,booster='gbtree'),n_estimators =50)\n",
    "#gridABC = GridSearchCV(modelABC, param_grid=parameters,scoring = scoring, cv=2, refit = 'mean',verbose=2)\n",
    "modelABC.fit(X_train,y_train)\n",
    "abc_preds = modelABC.predict(X_test)\n",
    "print (mean_squared_error(y_test,abc_preds)**.5)\n",
    "#print(gridABC.best_params_)\n",
    "#print(model.feature_importances_)\n",
    "#best score 2.2432 - all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clipS(preds):\n",
    "    for pred, element in enumerate(preds):\n",
    "        if preds[pred] < 1.25:\n",
    "            preds[pred] = 0\n",
    "        elif preds[pred] < 3.75:\n",
    "            preds[pred] = 2.5\n",
    "        elif  preds[pred] < 6.25:\n",
    "            preds[pred] = 5\n",
    "        elif  preds[pred] < 8.75:\n",
    "            preds[pred] = 7.5\n",
    "        else: \n",
    "            preds[pred] = 10\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.286079 7.5 10.0\n",
      "7.927208 7.5 7.5\n",
      "6.8665676 7.5 7.5\n",
      "7.365894 7.5 7.5\n",
      "8.49939 7.5 5.0\n",
      "7.1254463 7.5 5.0\n",
      "6.702565 7.5 7.5\n",
      "5.842753 5 7.5\n",
      "8.738859 7.5 10.0\n",
      "7.841649 7.5 10.0\n",
      "6.74351 7.5 7.5\n",
      "7.807215 7.5 7.5\n",
      "9.261417 10 7.5\n",
      "7.109841 7.5 5.0\n",
      "6.8010564 7.5 7.5\n",
      "7.597346 7.5 10.0\n",
      "6.9410725 7.5 2.5\n",
      "6.5449824 7.5 0.0\n",
      "7.402582 7.5 5.0\n",
      "6.431654 7.5 0.0\n",
      "7.1956844 7.5 7.5\n",
      "7.6999984 7.5 10.0\n",
      "6.1977854 5 2.5\n",
      "7.982983 7.5 10.0\n",
      "7.190724 7.5 7.5\n",
      "6.7932687 7.5 10.0\n",
      "8.369915 7.5 7.5\n",
      "8.421787 7.5 7.5\n",
      "7.026611 7.5 7.5\n",
      "6.857605 7.5 7.5\n",
      "8.973689 10 10.0\n",
      "6.7475266 7.5 2.5\n",
      "8.897934 10 7.5\n",
      "7.8295035 7.5 10.0\n",
      "9.146121 10 10.0\n",
      "8.495934 7.5 7.5\n",
      "6.728901 7.5 7.5\n",
      "7.36117 7.5 10.0\n",
      "8.701159 7.5 10.0\n",
      "7.6483 7.5 10.0\n",
      "7.262645 7.5 7.5\n",
      "7.3512554 7.5 7.5\n",
      "7.0285273 7.5 10.0\n",
      "8.729461 7.5 7.5\n",
      "7.8325706 7.5 7.5\n",
      "8.742565 7.5 10.0\n",
      "6.331672 7.5 0.0\n",
      "8.884819 10 7.5\n",
      "7.004472 7.5 7.5\n",
      "7.0543513 7.5 5.0\n",
      "7.403653 7.5 10.0\n",
      "7.0553303 7.5 7.5\n",
      "7.1007104 7.5 7.5\n",
      "4.405138 5 5.0\n",
      "6.3311124 7.5 5.0\n",
      "7.363051 7.5 5.0\n",
      "6.0551515 5 2.5\n",
      "9.117585 10 10.0\n",
      "9.358985 10 10.0\n",
      "5.541956 5 2.5\n",
      "8.615711 7.5 10.0\n",
      "9.012321 10 7.5\n",
      "6.0414762 5 7.5\n",
      "8.579151 7.5 10.0\n",
      "8.030192 7.5 7.5\n",
      "8.855805 10 10.0\n",
      "8.832175 10 7.5\n",
      "7.6058855 7.5 5.0\n",
      "7.199923 7.5 7.5\n",
      "8.900732 10 10.0\n",
      "8.324468 7.5 10.0\n",
      "8.5223 7.5 7.5\n",
      "9.109856 10 10.0\n",
      "6.486567 7.5 2.5\n",
      "8.735019 7.5 10.0\n",
      "7.5179343 7.5 5.0\n",
      "3.6571748 2.5 2.5\n",
      "6.286259 7.5 7.5\n",
      "6.783825 7.5 2.5\n",
      "6.983751 7.5 7.5\n",
      "8.085805 7.5 2.5\n",
      "6.5495825 7.5 10.0\n",
      "7.5467052 7.5 5.0\n",
      "9.301053 10 10.0\n",
      "6.9998946 7.5 7.5\n",
      "6.4746428 7.5 7.5\n",
      "8.327482 7.5 7.5\n",
      "7.71578 7.5 7.5\n",
      "8.524395 7.5 7.5\n",
      "6.8809905 7.5 7.5\n",
      "7.17428 7.5 7.5\n",
      "6.652444 7.5 7.5\n",
      "9.1943655 10 10.0\n",
      "7.41816 7.5 2.5\n",
      "8.574999 7.5 10.0\n",
      "9.110284 10 10.0\n",
      "7.2170534 7.5 5.0\n",
      "6.7920656 7.5 7.5\n",
      "7.6146593 7.5 2.5\n",
      "7.6355267 7.5 10.0\n",
      "7.725098 7.5 7.5\n",
      "9.835834 10 10.0\n",
      "8.92887 10 7.5\n",
      "7.7761097 7.5 5.0\n",
      "7.411673 7.5 10.0\n",
      "6.9068995 7.5 10.0\n",
      "4.706843 5 5.0\n",
      "6.7363033 7.5 10.0\n",
      "7.4693766 7.5 10.0\n",
      "6.62778 7.5 10.0\n",
      "8.363657 7.5 5.0\n",
      "7.438783 7.5 7.5\n",
      "8.178367 7.5 10.0\n",
      "6.381085 7.5 2.5\n",
      "8.266884 7.5 10.0\n",
      "8.277149 7.5 7.5\n",
      "7.65782 7.5 10.0\n",
      "8.929945 10 10.0\n",
      "9.464274 10 10.0\n",
      "7.760153 7.5 7.5\n",
      "7.0397315 7.5 7.5\n",
      "7.167578 7.5 7.5\n",
      "6.8036776 7.5 5.0\n",
      "7.7189155 7.5 7.5\n",
      "7.5646496 7.5 2.5\n",
      "8.044349 7.5 5.0\n",
      "7.171184 7.5 7.5\n",
      "8.161463 7.5 7.5\n",
      "7.9289637 7.5 10.0\n",
      "7.277117 7.5 10.0\n",
      "6.609256 7.5 2.5\n",
      "5.275037 5 5.0\n",
      "7.0832453 7.5 10.0\n",
      "9.117787 10 7.5\n",
      "7.603249 7.5 7.5\n",
      "6.663688 7.5 7.5\n",
      "4.723162 5 2.5\n",
      "7.6154575 7.5 10.0\n",
      "8.043401 7.5 10.0\n",
      "8.383421 7.5 7.5\n",
      "6.9304047 7.5 5.0\n",
      "8.473858 7.5 10.0\n",
      "7.591846 7.5 7.5\n",
      "7.1693206 7.5 0.0\n",
      "7.0171704 7.5 2.5\n",
      "8.716563 7.5 10.0\n",
      "6.279488 7.5 7.5\n",
      "7.7324343 7.5 7.5\n",
      "7.218708 7.5 5.0\n",
      "7.526625 7.5 7.5\n",
      "5.372349 5 5.0\n",
      "8.66315 7.5 10.0\n",
      "7.438694 7.5 7.5\n",
      "7.6925898 7.5 10.0\n",
      "7.1397734 7.5 7.5\n",
      "7.101089 7.5 7.5\n",
      "8.670513 7.5 10.0\n",
      "7.135246 7.5 10.0\n",
      "7.6819215 7.5 2.5\n",
      "8.511471 7.5 5.0\n",
      "6.893649 7.5 7.5\n",
      "7.893755 7.5 10.0\n",
      "8.673151 7.5 7.5\n",
      "7.3726406 7.5 7.5\n",
      "5.202962 5 0.0\n",
      "7.3817315 7.5 7.5\n",
      "7.201135 7.5 10.0\n",
      "7.397476 7.5 7.5\n",
      "4.704034 5 5.0\n",
      "6.9775224 7.5 7.5\n",
      "8.79597 10 10.0\n",
      "7.282974 7.5 10.0\n",
      "8.459864 7.5 10.0\n",
      "7.0988016 7.5 7.5\n",
      "5.45099 5 7.5\n",
      "6.903828 7.5 2.5\n",
      "7.262401 7.5 7.5\n",
      "5.0595374 5 2.5\n",
      "7.8998914 7.5 7.5\n",
      "8.004835 7.5 7.5\n",
      "5.8966293 5 5.0\n",
      "4.485405 5 2.5\n",
      "5.643121 5 2.5\n",
      "8.961643 10 10.0\n",
      "7.5989194 7.5 10.0\n",
      "6.7831264 7.5 5.0\n",
      "8.754775 10 10.0\n",
      "8.347086 7.5 7.5\n",
      "6.6628594 7.5 2.5\n",
      "7.0336676 7.5 7.5\n",
      "7.366872 7.5 7.5\n",
      "6.7191534 7.5 7.5\n",
      "7.8934665 7.5 10.0\n",
      "9.191255 10 10.0\n",
      "7.557719 7.5 7.5\n",
      "6.9939127 7.5 7.5\n",
      "6.472245 7.5 5.0\n",
      "7.3428783 7.5 2.5\n",
      "6.4768124 7.5 2.5\n",
      "5.3114104 5 7.5\n",
      "7.6250925 7.5 7.5\n",
      "7.5127063 7.5 10.0\n",
      "7.503521 7.5 7.5\n",
      "8.132802 7.5 7.5\n",
      "7.9164486 7.5 7.5\n",
      "7.0198107 7.5 7.5\n",
      "7.0506005 7.5 2.5\n",
      "8.404212 7.5 7.5\n",
      "7.6292434 7.5 7.5\n",
      "6.6520014 7.5 10.0\n",
      "8.912238 10 10.0\n",
      "8.9411745 10 10.0\n",
      "7.1848226 7.5 5.0\n",
      "5.805557 5 5.0\n",
      "7.137453 7.5 7.5\n",
      "7.3466763 7.5 7.5\n",
      "7.4282475 7.5 10.0\n",
      "5.8565474 5 10.0\n",
      "6.839623 7.5 7.5\n",
      "7.060577 7.5 7.5\n",
      "9.138858 10 10.0\n",
      "6.35038 7.5 5.0\n",
      "7.7695136 7.5 10.0\n",
      "6.0542393 5 7.5\n",
      "7.2977853 7.5 10.0\n",
      "6.835838 7.5 5.0\n",
      "7.5787945 7.5 7.5\n",
      "8.911916 10 5.0\n",
      "7.544947 7.5 5.0\n",
      "8.094479 7.5 10.0\n",
      "8.853425 10 10.0\n",
      "8.564133 7.5 7.5\n",
      "7.4951167 7.5 2.5\n",
      "7.7497053 7.5 7.5\n",
      "6.557948 7.5 7.5\n",
      "7.6053023 7.5 10.0\n",
      "8.348433 7.5 7.5\n",
      "6.014029 5 5.0\n",
      "7.017941 7.5 7.5\n",
      "5.64851 5 10.0\n",
      "6.886149 7.5 5.0\n",
      "6.4640403 7.5 7.5\n",
      "5.3906755 5 10.0\n",
      "7.2654233 7.5 10.0\n",
      "9.335668 10 10.0\n",
      "6.481755 7.5 2.5\n",
      "6.017241 5 7.5\n",
      "8.043382 7.5 10.0\n",
      "9.051476 10 10.0\n",
      "6.560203 7.5 7.5\n",
      "8.62571 7.5 5.0\n",
      "8.877778 10 10.0\n",
      "7.7104654 7.5 7.5\n",
      "7.369749 7.5 7.5\n",
      "8.967628 10 10.0\n",
      "5.2159295 5 2.5\n",
      "8.635881 7.5 7.5\n",
      "7.1446714 7.5 2.5\n",
      "7.4312387 7.5 2.5\n",
      "6.711874 7.5 10.0\n",
      "8.671534 7.5 7.5\n",
      "7.5660887 7.5 2.5\n",
      "5.8431525 5 5.0\n",
      "6.714745 7.5 7.5\n",
      "7.6558537 7.5 10.0\n",
      "7.377463 7.5 7.5\n",
      "4.7338557 5 5.0\n",
      "9.316233 10 7.5\n",
      "7.186562 7.5 7.5\n",
      "8.721661 7.5 10.0\n",
      "6.9716315 7.5 10.0\n",
      "7.6170654 7.5 10.0\n",
      "4.8393083 5 7.5\n",
      "7.38621 7.5 10.0\n",
      "7.297359 7.5 7.5\n",
      "6.9779367 7.5 7.5\n",
      "8.299047 7.5 7.5\n",
      "8.64231 7.5 10.0\n",
      "9.119448 10 7.5\n",
      "4.38325 5 2.5\n",
      "9.018082 10 10.0\n",
      "7.2247763 7.5 10.0\n",
      "6.4251723 7.5 7.5\n",
      "7.1317353 7.5 10.0\n",
      "8.600432 7.5 10.0\n",
      "7.3213086 7.5 10.0\n",
      "7.583395 7.5 5.0\n",
      "8.4304905 7.5 10.0\n",
      "7.1937423 7.5 10.0\n",
      "7.2638855 7.5 7.5\n",
      "4.718356 5 2.5\n",
      "8.542231 7.5 7.5\n",
      "8.715064 7.5 10.0\n",
      "7.007884 7.5 7.5\n",
      "7.155012 7.5 10.0\n",
      "6.0820823 5 2.5\n",
      "8.476149 7.5 10.0\n",
      "6.3996363 7.5 2.5\n",
      "6.704749 7.5 5.0\n",
      "7.937782 7.5 7.5\n",
      "6.222191 5 0.0\n",
      "6.969253 7.5 7.5\n",
      "8.322651 7.5 5.0\n",
      "6.794183 7.5 7.5\n",
      "8.821465 10 10.0\n",
      "8.9155245 10 10.0\n",
      "9.655393 10 10.0\n",
      "7.691099 7.5 7.5\n",
      "8.331469 7.5 2.5\n",
      "9.57851 10 10.0\n",
      "7.8688903 7.5 10.0\n",
      "7.268002 7.5 5.0\n",
      "4.363471 5 7.5\n",
      "7.0442104 7.5 7.5\n",
      "7.034379 7.5 7.5\n",
      "8.409029 7.5 5.0\n",
      "7.3680425 7.5 10.0\n",
      "4.837284 5 2.5\n",
      "8.177069 7.5 10.0\n",
      "7.5692315 7.5 10.0\n",
      "6.857407 7.5 5.0\n",
      "8.328121 7.5 7.5\n",
      "7.276381 7.5 5.0\n",
      "7.601217 7.5 10.0\n",
      "7.3337727 7.5 7.5\n",
      "6.951588 7.5 7.5\n",
      "8.452675 7.5 5.0\n",
      "7.929223 7.5 5.0\n",
      "7.182568 7.5 7.5\n",
      "6.8402877 7.5 10.0\n",
      "6.775493 7.5 5.0\n",
      "6.1471343 5 10.0\n",
      "7.3068666 7.5 7.5\n",
      "6.7196417 7.5 7.5\n",
      "8.756385 10 5.0\n",
      "7.2793436 7.5 10.0\n",
      "5.000211 5 10.0\n",
      "6.7214365 7.5 10.0\n",
      "7.6406875 7.5 10.0\n",
      "7.3126354 7.5 7.5\n",
      "9.401726 10 10.0\n",
      "9.104323 10 10.0\n",
      "8.366888 7.5 7.5\n",
      "4.901815 5 5.0\n",
      "8.21958 7.5 10.0\n",
      "7.9752884 7.5 2.5\n",
      "7.4142094 7.5 7.5\n",
      "7.7659926 7.5 10.0\n",
      "8.70406 7.5 10.0\n",
      "7.4904323 7.5 7.5\n",
      "6.7746053 7.5 7.5\n",
      "6.530846 7.5 7.5\n",
      "8.04063 7.5 5.0\n",
      "8.221747 7.5 7.5\n",
      "7.400912 7.5 10.0\n",
      "7.7718835 7.5 7.5\n",
      "7.148913 7.5 2.5\n",
      "8.17844 7.5 10.0\n",
      "9.469219 10 10.0\n",
      "7.73892 7.5 10.0\n",
      "7.133104 7.5 7.5\n",
      "6.705155 7.5 5.0\n",
      "6.997345 7.5 7.5\n",
      "8.586482 7.5 10.0\n",
      "8.821429 10 7.5\n",
      "7.6046114 7.5 5.0\n",
      "7.3128233 7.5 10.0\n",
      "8.714591 7.5 7.5\n",
      "7.660843 7.5 7.5\n",
      "8.609051 7.5 7.5\n",
      "6.9730186 7.5 5.0\n",
      "8.670081 7.5 10.0\n",
      "8.079895 7.5 10.0\n",
      "7.9215693 7.5 7.5\n",
      "5.7190385 5 7.5\n",
      "9.331474 10 10.0\n",
      "6.8284993 7.5 7.5\n",
      "8.0086975 7.5 10.0\n",
      "7.02293 7.5 10.0\n",
      "7.0213385 7.5 7.5\n",
      "6.6029406 7.5 10.0\n",
      "7.4014792 7.5 10.0\n",
      "7.298542 7.5 0.0\n",
      "7.619708 7.5 5.0\n",
      "7.1979895 7.5 10.0\n",
      "7.448646 7.5 7.5\n",
      "8.440142 7.5 7.5\n",
      "6.9769835 7.5 7.5\n",
      "6.138256 5 7.5\n",
      "7.2245126 7.5 5.0\n",
      "6.527871 7.5 7.5\n",
      "6.8050394 7.5 7.5\n",
      "6.3317323 7.5 2.5\n",
      "6.772269 7.5 7.5\n",
      "8.76172 10 7.5\n",
      "7.0657053 7.5 7.5\n",
      "5.377063 5 10.0\n",
      "8.594167 7.5 5.0\n",
      "7.422571 7.5 10.0\n",
      "6.9281945 7.5 7.5\n",
      "5.144563 5 5.0\n",
      "7.5175185 7.5 5.0\n",
      "6.9254336 7.5 10.0\n",
      "7.3157744 7.5 7.5\n",
      "7.2429156 7.5 7.5\n",
      "4.8302307 5 2.5\n",
      "5.554353 5 2.5\n",
      "7.481337 7.5 10.0\n",
      "7.421533 7.5 7.5\n",
      "8.007649 7.5 10.0\n",
      "7.350526 7.5 2.5\n",
      "9.06644 10 10.0\n",
      "7.250871 7.5 10.0\n",
      "7.9431186 7.5 10.0\n",
      "6.920812 7.5 10.0\n",
      "6.753942 7.5 10.0\n",
      "8.611946 7.5 7.5\n",
      "7.4769297 7.5 5.0\n",
      "7.192379 7.5 10.0\n",
      "5.9402156 5 2.5\n",
      "8.96776 10 10.0\n",
      "6.6662545 7.5 2.5\n",
      "7.4262714 7.5 2.5\n",
      "8.85153 10 7.5\n",
      "8.936792 10 7.5\n",
      "7.3628335 7.5 7.5\n",
      "5.7974925 5 7.5\n",
      "7.203161 7.5 0.0\n",
      "6.0014415 5 7.5\n",
      "7.666558 7.5 7.5\n",
      "7.287009 7.5 7.5\n",
      "7.173406 7.5 5.0\n",
      "7.7139025 7.5 10.0\n",
      "6.0934787 5 7.5\n",
      "7.2690234 7.5 5.0\n",
      "8.296945 7.5 10.0\n",
      "7.9280605 7.5 7.5\n",
      "7.032693 7.5 2.5\n",
      "8.463832 7.5 10.0\n",
      "7.1000605 7.5 7.5\n",
      "8.899751 10 10.0\n",
      "7.7113748 7.5 7.5\n",
      "8.2399845 7.5 10.0\n",
      "8.778484 10 10.0\n",
      "7.807631 7.5 10.0\n",
      "7.206174 7.5 2.5\n",
      "8.808467 10 7.5\n",
      "4.1308002 5 2.5\n",
      "7.0482454 7.5 7.5\n",
      "8.931331 10 0.0\n",
      "7.2467513 7.5 7.5\n",
      "7.292097 7.5 7.5\n",
      "6.701726 7.5 7.5\n",
      "9.159873 10 7.5\n",
      "8.311512 7.5 10.0\n",
      "7.8484197 7.5 10.0\n",
      "7.418136 7.5 7.5\n",
      "6.9726777 7.5 10.0\n",
      "7.6918173 7.5 10.0\n",
      "6.9782104 7.5 7.5\n",
      "7.405746 7.5 7.5\n",
      "6.3513823 7.5 7.5\n",
      "7.091888 7.5 7.5\n",
      "9.166574 10 10.0\n",
      "7.951657 7.5 10.0\n",
      "6.0477605 5 2.5\n",
      "9.185785 10 10.0\n",
      "5.3644524 5 7.5\n",
      "7.0279727 7.5 7.5\n",
      "8.721304 7.5 10.0\n",
      "5.368986 5 0.0\n",
      "7.10423 7.5 7.5\n",
      "7.692889 7.5 10.0\n",
      "7.1589327 7.5 2.5\n",
      "9.070053 10 10.0\n",
      "6.972535 7.5 7.5\n",
      "5.3782387 5 5.0\n",
      "7.221765 7.5 7.5\n",
      "7.29352 7.5 7.5\n",
      "7.9121714 7.5 10.0\n",
      "6.5349183 7.5 5.0\n",
      "8.577447 7.5 10.0\n",
      "9.000124 10 10.0\n",
      "9.061013 10 10.0\n",
      "6.8140445 7.5 5.0\n",
      "8.715182 7.5 7.5\n",
      "7.6654744 7.5 7.5\n",
      "9.053612 10 10.0\n",
      "6.8768363 7.5 7.5\n",
      "7.7563195 7.5 7.5\n",
      "5.586463 5 5.0\n",
      "7.1503057 7.5 7.5\n",
      "7.8367867 7.5 7.5\n",
      "8.792763 10 10.0\n",
      "7.0504675 7.5 7.5\n",
      "7.165014 7.5 7.5\n",
      "7.01019 7.5 2.5\n",
      "6.183681 5 7.5\n",
      "7.369988 7.5 10.0\n",
      "8.126756 7.5 7.5\n",
      "6.9977584 7.5 2.5\n",
      "8.87244 10 10.0\n",
      "6.3783193 7.5 7.5\n",
      "8.659013 7.5 10.0\n",
      "6.876874 7.5 5.0\n",
      "9.120095 10 10.0\n",
      "7.640631 7.5 7.5\n",
      "7.764863 7.5 5.0\n",
      "7.984157 7.5 5.0\n",
      "6.3734446 7.5 10.0\n",
      "9.266925 10 10.0\n",
      "7.1606984 7.5 7.5\n",
      "7.230636 7.5 7.5\n",
      "7.7491655 7.5 7.5\n",
      "8.973715 10 7.5\n",
      "6.57913 7.5 7.5\n",
      "6.8133802 7.5 7.5\n",
      "7.585878 7.5 5.0\n",
      "6.0682187 5 2.5\n",
      "7.4714656 7.5 10.0\n",
      "8.99028 10 10.0\n",
      "6.096297 5 7.5\n",
      "7.929471 7.5 10.0\n",
      "6.6532526 7.5 7.5\n",
      "7.255486 7.5 7.5\n",
      "7.121804 7.5 7.5\n",
      "8.741817 7.5 10.0\n",
      "6.4791694 7.5 10.0\n",
      "7.16204 7.5 10.0\n",
      "7.40656 7.5 10.0\n",
      "8.835292 10 10.0\n",
      "6.354284 7.5 2.5\n",
      "7.7022524 7.5 10.0\n",
      "7.180073 7.5 7.5\n",
      "7.618295 7.5 5.0\n",
      "9.011094 10 10.0\n",
      "6.4088025 7.5 7.5\n",
      "6.851756 7.5 10.0\n",
      "6.524576 7.5 5.0\n",
      "6.737183 7.5 10.0\n",
      "7.736432 7.5 10.0\n",
      "8.675886 7.5 10.0\n",
      "7.5902305 7.5 7.5\n",
      "6.956921 7.5 7.5\n",
      "7.0642276 7.5 10.0\n",
      "7.7774615 7.5 10.0\n",
      "8.840522 10 10.0\n",
      "9.018677 10 10.0\n",
      "7.1048713 7.5 10.0\n",
      "7.5425825 7.5 10.0\n",
      "5.916163 5 10.0\n",
      "6.2203655 5 7.5\n",
      "9.624352 10 10.0\n",
      "5.7014008 5 7.5\n",
      "6.383533 7.5 5.0\n",
      "6.731 7.5 2.5\n",
      "8.903315 10 10.0\n",
      "7.2506924 7.5 10.0\n",
      "7.6655774 7.5 7.5\n",
      "7.8781333 7.5 7.5\n",
      "7.3385854 7.5 10.0\n",
      "7.295913 7.5 10.0\n",
      "7.059357 7.5 5.0\n",
      "8.175743 7.5 7.5\n",
      "7.035736 7.5 7.5\n",
      "9.075741 10 10.0\n",
      "8.659208 7.5 7.5\n",
      "7.261086 7.5 5.0\n",
      "9.128366 10 10.0\n",
      "9.201667 10 10.0\n",
      "6.909012 7.5 7.5\n",
      "8.563478 7.5 10.0\n",
      "7.7417493 7.5 7.5\n",
      "6.598126 7.5 10.0\n",
      "6.838928 7.5 7.5\n",
      "4.8229856 5 5.0\n",
      "6.9030147 7.5 7.5\n",
      "4.448558 5 7.5\n",
      "7.3287625 7.5 7.5\n",
      "8.58215 7.5 7.5\n",
      "6.9423847 7.5 7.5\n",
      "7.1722794 7.5 5.0\n",
      "7.8454676 7.5 7.5\n",
      "8.680428 7.5 7.5\n",
      "8.819686 10 7.5\n",
      "7.5887103 7.5 10.0\n",
      "9.291523 10 7.5\n",
      "8.94677 10 10.0\n",
      "7.8365974 7.5 10.0\n",
      "7.1992483 7.5 10.0\n",
      "7.6480193 7.5 10.0\n",
      "6.431595 7.5 7.5\n",
      "6.666589 7.5 2.5\n",
      "7.5594454 7.5 7.5\n",
      "7.0675583 7.5 7.5\n",
      "8.671326 7.5 10.0\n",
      "8.293993 7.5 7.5\n",
      "6.065326 5 10.0\n",
      "8.743233 7.5 10.0\n",
      "8.602865 7.5 10.0\n",
      "7.545047 7.5 5.0\n",
      "6.366297 7.5 2.5\n",
      "6.999705 7.5 7.5\n",
      "7.727626 7.5 7.5\n",
      "7.2649617 7.5 5.0\n",
      "6.262243 7.5 2.5\n",
      "6.624135 7.5 5.0\n",
      "8.509215 7.5 7.5\n",
      "7.9518967 7.5 10.0\n",
      "9.159919 10 10.0\n",
      "6.3651114 7.5 2.5\n",
      "7.2806845 7.5 10.0\n",
      "7.0947695 7.5 5.0\n",
      "4.6172037 5 0.0\n",
      "9.0803995 10 10.0\n",
      "6.4334626 7.5 5.0\n",
      "7.1046987 7.5 10.0\n",
      "8.443733 7.5 10.0\n",
      "8.841903 10 10.0\n",
      "8.612307 7.5 7.5\n",
      "8.098684 7.5 10.0\n",
      "6.9010196 7.5 2.5\n",
      "6.1703377 5 5.0\n",
      "7.5871663 7.5 7.5\n",
      "7.388483 7.5 7.5\n",
      "9.196045 10 10.0\n",
      "7.2582064 7.5 7.5\n",
      "7.027735 7.5 7.5\n",
      "7.087882 7.5 10.0\n",
      "8.592028 7.5 10.0\n",
      "7.827072 7.5 10.0\n",
      "7.3170323 7.5 7.5\n",
      "7.033129 7.5 7.5\n",
      "6.7714667 7.5 7.5\n",
      "6.588135 7.5 2.5\n",
      "6.9748836 7.5 2.5\n",
      "8.837019 10 7.5\n",
      "7.3911443 7.5 7.5\n",
      "7.607795 7.5 10.0\n",
      "9.386492 10 10.0\n",
      "7.8328876 7.5 7.5\n",
      "7.1335373 7.5 7.5\n",
      "6.209868 5 7.5\n",
      "7.228551 7.5 7.5\n",
      "7.3156276 7.5 7.5\n",
      "7.9866543 7.5 10.0\n",
      "7.741124 7.5 7.5\n",
      "7.191593 7.5 7.5\n",
      "9.061615 10 10.0\n",
      "4.8184996 5 2.5\n",
      "7.2674165 7.5 2.5\n",
      "6.645566 7.5 10.0\n",
      "7.947404 7.5 7.5\n",
      "8.051508 7.5 10.0\n",
      "5.444333 5 2.5\n",
      "7.182348 7.5 7.5\n",
      "7.5451245 7.5 7.5\n",
      "8.9796 10 7.5\n",
      "7.307333 7.5 10.0\n",
      "8.824837 10 7.5\n",
      "8.7856865 10 7.5\n",
      "4.7115307 5 7.5\n",
      "7.3474936 7.5 0.0\n",
      "9.230823 10 10.0\n",
      "7.1721816 7.5 0.0\n",
      "9.018509 10 10.0\n",
      "6.925648 7.5 7.5\n",
      "7.803427 7.5 10.0\n",
      "9.032519 10 7.5\n",
      "6.853879 7.5 7.5\n",
      "7.3689675 7.5 10.0\n",
      "6.5305805 7.5 10.0\n",
      "7.9466605 7.5 7.5\n",
      "4.0821304 5 10.0\n",
      "5.524874 5 7.5\n",
      "6.761877 7.5 7.5\n",
      "7.3257155 7.5 10.0\n",
      "7.274838 7.5 7.5\n",
      "9.0077305 10 10.0\n",
      "5.556011 5 2.5\n",
      "7.233306 7.5 7.5\n",
      "7.492793 7.5 7.5\n",
      "9.328015 10 10.0\n",
      "5.844181 5 2.5\n",
      "7.709036 7.5 10.0\n",
      "4.6909084 5 2.5\n",
      "8.109215 7.5 7.5\n",
      "8.120611 7.5 7.5\n",
      "6.494277 7.5 10.0\n",
      "8.475326 7.5 10.0\n",
      "8.678416 7.5 10.0\n",
      "7.4901304 7.5 2.5\n",
      "7.6018887 7.5 7.5\n",
      "7.0528555 7.5 7.5\n",
      "7.511163 7.5 10.0\n",
      "6.9843717 7.5 10.0\n",
      "7.0571322 7.5 10.0\n",
      "7.2764153 7.5 5.0\n",
      "8.238143 7.5 5.0\n",
      "6.9302516 7.5 5.0\n",
      "7.0490346 7.5 10.0\n",
      "7.5759425 7.5 10.0\n",
      "7.4752707 7.5 7.5\n",
      "9.279785 10 7.5\n",
      "7.3576407 7.5 10.0\n",
      "9.222765 10 7.5\n",
      "3.7707024 5 2.5\n",
      "6.655712 7.5 2.5\n",
      "5.809638 5 10.0\n",
      "8.82486 10 7.5\n",
      "5.3256445 5 7.5\n",
      "7.6264615 7.5 10.0\n",
      "7.997728 7.5 10.0\n",
      "6.646442 7.5 7.5\n",
      "7.897709 7.5 10.0\n",
      "7.041987 7.5 7.5\n",
      "7.296846 7.5 10.0\n",
      "6.7226424 7.5 7.5\n",
      "9.206126 10 10.0\n",
      "8.828104 10 10.0\n",
      "6.2329283 5 7.5\n",
      "8.983676 10 10.0\n",
      "5.994786 5 7.5\n",
      "6.218967 5 5.0\n",
      "5.8920155 5 5.0\n",
      "6.0475736 5 10.0\n",
      "7.211736 7.5 5.0\n",
      "8.815203 10 7.5\n",
      "7.504905 7.5 7.5\n",
      "8.741962 7.5 10.0\n",
      "8.915806 10 10.0\n",
      "7.541846 7.5 7.5\n",
      "3.4106596 2.5 5.0\n",
      "8.79356 10 10.0\n",
      "8.566177 7.5 7.5\n",
      "8.124886 7.5 2.5\n",
      "6.979462 7.5 7.5\n",
      "8.853748 10 10.0\n",
      "8.997233 10 7.5\n",
      "7.0251513 7.5 7.5\n",
      "7.8392673 7.5 10.0\n",
      "7.8085976 7.5 7.5\n",
      "8.683331 7.5 10.0\n",
      "8.896036 10 7.5\n",
      "8.994874 10 10.0\n",
      "7.89607 7.5 10.0\n",
      "8.616039 7.5 10.0\n",
      "8.097696 7.5 7.5\n",
      "9.043376 10 7.5\n",
      "6.682789 7.5 5.0\n",
      "8.723237 7.5 10.0\n",
      "6.4684787 7.5 7.5\n",
      "8.265588 7.5 10.0\n",
      "6.0097704 5 2.5\n",
      "9.308809 10 10.0\n",
      "6.5025406 7.5 10.0\n",
      "6.8406534 7.5 10.0\n",
      "6.926695 7.5 7.5\n",
      "7.3717694 7.5 10.0\n",
      "6.738855 7.5 7.5\n",
      "5.3507657 5 7.5\n",
      "7.85317 7.5 7.5\n",
      "7.6980686 7.5 7.5\n",
      "6.312067 7.5 7.5\n",
      "7.1721983 7.5 10.0\n",
      "6.913116 7.5 7.5\n",
      "7.600892 7.5 10.0\n",
      "5.9748197 5 10.0\n",
      "6.718238 7.5 7.5\n",
      "9.62091 10 10.0\n",
      "7.014466 7.5 7.5\n",
      "6.4093614 7.5 5.0\n",
      "8.128167 7.5 10.0\n",
      "5.95065 5 5.0\n",
      "8.686604 7.5 7.5\n",
      "7.8931046 7.5 7.5\n",
      "7.4930286 7.5 10.0\n",
      "6.5529804 7.5 0.0\n",
      "7.9078407 7.5 5.0\n",
      "8.575612 7.5 7.5\n",
      "9.971751 10 7.5\n",
      "6.828097 7.5 10.0\n",
      "6.32053 7.5 2.5\n",
      "6.0071945 5 5.0\n",
      "9.117696 10 7.5\n",
      "6.7290273 7.5 7.5\n",
      "7.487945 7.5 10.0\n",
      "7.153184 7.5 2.5\n",
      "7.1766214 7.5 7.5\n",
      "8.006289 7.5 10.0\n",
      "8.8548975 10 10.0\n",
      "5.1826515 5 10.0\n",
      "5.557401 5 2.5\n",
      "7.505442 7.5 7.5\n",
      "8.943387 10 7.5\n",
      "7.8343396 7.5 10.0\n",
      "7.5074115 7.5 7.5\n",
      "9.099901 10 7.5\n",
      "5.911309 5 10.0\n",
      "7.029959 7.5 5.0\n",
      "9.008444 10 7.5\n",
      "7.210225 7.5 10.0\n",
      "6.657603 7.5 7.5\n",
      "8.045045 7.5 7.5\n",
      "5.7507095 5 2.5\n",
      "5.902056 5 2.5\n",
      "8.480425 7.5 7.5\n",
      "4.6460853 5 7.5\n",
      "6.4929423 7.5 7.5\n",
      "7.3816013 7.5 7.5\n",
      "8.495994 7.5 10.0\n",
      "8.137367 7.5 2.5\n",
      "7.6977563 7.5 7.5\n",
      "8.839391 10 7.5\n",
      "8.6795225 7.5 10.0\n",
      "8.643074 7.5 10.0\n",
      "7.879315 7.5 7.5\n",
      "7.0873356 7.5 5.0\n",
      "9.043024 10 10.0\n",
      "7.307547 7.5 10.0\n",
      "8.444422 7.5 7.5\n",
      "7.4380927 7.5 10.0\n",
      "8.870378 10 10.0\n",
      "5.7060328 5 2.5\n",
      "6.9695334 7.5 5.0\n",
      "8.153898 7.5 10.0\n",
      "8.310602 7.5 10.0\n",
      "8.003927 7.5 7.5\n",
      "8.020667 7.5 10.0\n",
      "8.752924 10 7.5\n",
      "7.638061 7.5 7.5\n",
      "9.11074 10 10.0\n",
      "7.2740993 7.5 5.0\n",
      "7.56591 7.5 5.0\n",
      "7.749696 7.5 10.0\n",
      "7.434558 7.5 7.5\n",
      "6.910165 7.5 7.5\n",
      "8.751173 10 7.5\n",
      "7.666991 7.5 10.0\n",
      "8.362771 7.5 7.5\n",
      "6.4933314 7.5 7.5\n",
      "8.187576 7.5 7.5\n",
      "8.396187 7.5 10.0\n",
      "6.6282578 7.5 7.5\n",
      "5.4653378 5 7.5\n",
      "6.1717305 5 7.5\n",
      "7.2601748 7.5 7.5\n",
      "8.385347 7.5 7.5\n",
      "8.917405 10 10.0\n",
      "8.489651 7.5 10.0\n",
      "8.503833 7.5 10.0\n",
      "7.7287445 7.5 7.5\n",
      "6.6385245 7.5 7.5\n",
      "6.423091 7.5 10.0\n",
      "7.3621283 7.5 7.5\n",
      "6.18691 5 7.5\n",
      "8.913301 10 10.0\n",
      "7.048974 7.5 7.5\n",
      "8.951509 10 10.0\n",
      "7.1843157 7.5 7.5\n",
      "7.048867 7.5 10.0\n",
      "8.535232 7.5 10.0\n",
      "7.9645624 7.5 7.5\n",
      "7.198618 7.5 7.5\n",
      "6.9649787 7.5 7.5\n",
      "8.590393 7.5 7.5\n",
      "8.645126 7.5 10.0\n",
      "7.3044996 7.5 7.5\n",
      "8.393788 7.5 10.0\n",
      "7.1001616 7.5 7.5\n",
      "7.4772654 7.5 10.0\n",
      "6.089533 5 2.5\n",
      "5.695056 5 0.0\n",
      "7.2276936 7.5 2.5\n",
      "7.6275587 7.5 2.5\n",
      "6.3332486 7.5 5.0\n",
      "7.011819 7.5 10.0\n",
      "6.514311 7.5 5.0\n",
      "6.4802876 7.5 5.0\n",
      "6.3746715 7.5 7.5\n",
      "6.4421344 7.5 7.5\n",
      "7.1798344 7.5 7.5\n",
      "6.9129825 7.5 7.5\n",
      "6.991682 7.5 10.0\n",
      "7.338098 7.5 5.0\n",
      "7.1576395 7.5 7.5\n",
      "8.81388 10 7.5\n",
      "8.478157 7.5 7.5\n",
      "4.0456686 5 7.5\n",
      "8.933377 10 10.0\n",
      "7.0464997 7.5 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2498374 7.5 10.0\n",
      "7.0629873 7.5 10.0\n",
      "6.8996253 7.5 7.5\n",
      "6.8121514 7.5 10.0\n",
      "7.2658896 7.5 2.5\n",
      "8.852533 10 10.0\n",
      "7.584811 7.5 5.0\n",
      "8.762749 10 10.0\n",
      "6.7032113 7.5 7.5\n",
      "7.040448 7.5 7.5\n",
      "8.731287 7.5 10.0\n",
      "8.339863 7.5 10.0\n",
      "9.299665 10 10.0\n",
      "7.84971 7.5 7.5\n",
      "5.7796865 5 7.5\n",
      "5.215879 5 2.5\n",
      "6.0454664 5 5.0\n",
      "7.069505 7.5 7.5\n",
      "7.026026 7.5 10.0\n",
      "8.7816305 10 7.5\n",
      "7.6395483 7.5 10.0\n",
      "8.811912 10 7.5\n",
      "7.073048 7.5 7.5\n",
      "6.7585797 7.5 7.5\n",
      "5.5238676 5 7.5\n",
      "7.074044 7.5 7.5\n",
      "8.605527 7.5 10.0\n",
      "4.81072 5 2.5\n",
      "6.474626 7.5 10.0\n",
      "7.489467 7.5 10.0\n",
      "6.297437 7.5 7.5\n",
      "9.015276 10 10.0\n",
      "7.1141887 7.5 2.5\n",
      "8.855669 10 7.5\n",
      "7.5748086 7.5 7.5\n",
      "7.4217353 7.5 10.0\n",
      "7.6471562 7.5 7.5\n",
      "6.816087 7.5 5.0\n",
      "8.472724 7.5 10.0\n",
      "6.552516 7.5 7.5\n",
      "7.1472735 7.5 2.5\n",
      "5.7331457 5 7.5\n",
      "6.8766747 7.5 2.5\n",
      "5.6829224 5 2.5\n",
      "9.096558 10 10.0\n",
      "7.444388 7.5 7.5\n",
      "8.846415 10 7.5\n",
      "7.449927 7.5 7.5\n",
      "7.189878 7.5 7.5\n",
      "6.0751224 5 10.0\n",
      "7.364566 7.5 10.0\n",
      "5.6063213 5 10.0\n",
      "7.286406 7.5 7.5\n",
      "7.6666327 7.5 7.5\n",
      "6.3354225 7.5 10.0\n",
      "5.25561 5 10.0\n",
      "9.825521 10 10.0\n",
      "6.786795 7.5 10.0\n",
      "7.211224 7.5 7.5\n",
      "5.1729994 5 0.0\n",
      "8.658024 7.5 7.5\n",
      "7.481276 7.5 7.5\n",
      "8.141222 7.5 10.0\n",
      "7.8352633 7.5 2.5\n",
      "7.047787 7.5 7.5\n",
      "6.354513 7.5 5.0\n",
      "7.257781 7.5 7.5\n",
      "7.370767 7.5 10.0\n",
      "9.072065 10 7.5\n",
      "9.001488 10 10.0\n",
      "7.203402 7.5 7.5\n",
      "7.442974 7.5 2.5\n",
      "7.4649825 7.5 7.5\n",
      "7.3099937 7.5 7.5\n",
      "6.758963 7.5 7.5\n",
      "7.267594 7.5 2.5\n",
      "6.822842 7.5 7.5\n",
      "7.388667 7.5 10.0\n",
      "6.7713485 7.5 7.5\n",
      "9.20234 10 7.5\n",
      "6.988487 7.5 7.5\n",
      "7.457518 7.5 7.5\n",
      "7.1103916 7.5 10.0\n",
      "9.00083 10 10.0\n",
      "6.9202895 7.5 7.5\n",
      "9.033867 10 10.0\n",
      "7.7080817 7.5 10.0\n",
      "7.770261 7.5 10.0\n",
      "6.412739 7.5 10.0\n",
      "5.156807 5 2.5\n",
      "7.8048015 7.5 7.5\n",
      "7.976662 7.5 10.0\n",
      "5.4503665 5 0.0\n",
      "7.6033726 7.5 10.0\n",
      "6.092348 5 7.5\n",
      "7.874834 7.5 2.5\n",
      "6.79322 7.5 5.0\n",
      "7.040174 7.5 7.5\n",
      "6.7235327 7.5 5.0\n",
      "5.583452 5 7.5\n",
      "7.2103567 7.5 10.0\n",
      "6.54365 7.5 7.5\n",
      "5.1156597 5 7.5\n",
      "8.544493 7.5 10.0\n",
      "5.7954426 5 7.5\n",
      "7.408787 7.5 7.5\n",
      "7.061892 7.5 5.0\n",
      "7.4255366 7.5 10.0\n",
      "7.224121 7.5 10.0\n",
      "7.383934 7.5 10.0\n",
      "7.893984 7.5 10.0\n",
      "8.617469 7.5 10.0\n",
      "7.1683226 7.5 7.5\n",
      "6.9922867 7.5 7.5\n",
      "8.941133 10 10.0\n",
      "8.846904 10 7.5\n",
      "8.689668 7.5 7.5\n",
      "9.024565 10 7.5\n",
      "7.057293 7.5 7.5\n",
      "6.706053 7.5 2.5\n",
      "7.8386283 7.5 7.5\n",
      "6.367111 7.5 7.5\n",
      "9.645114 10 10.0\n",
      "5.350004 5 7.5\n",
      "5.563779 5 7.5\n",
      "7.238351 7.5 7.5\n",
      "8.127445 7.5 7.5\n",
      "7.08908 7.5 10.0\n",
      "9.023237 10 10.0\n",
      "9.000626 10 7.5\n",
      "6.821427 7.5 7.5\n",
      "7.675 7.5 7.5\n",
      "7.2775536 7.5 10.0\n",
      "9.138244 10 10.0\n",
      "7.510306 7.5 10.0\n",
      "9.392152 10 10.0\n",
      "8.145443 7.5 10.0\n",
      "7.6661754 7.5 7.5\n",
      "8.918307 10 7.5\n",
      "6.54089 7.5 7.5\n",
      "6.3692465 7.5 10.0\n",
      "8.753905 10 10.0\n",
      "8.292461 7.5 10.0\n",
      "6.9488854 7.5 7.5\n",
      "4.5113273 5 5.0\n",
      "7.3257065 7.5 7.5\n",
      "8.623052 7.5 5.0\n",
      "3.4767556 2.5 2.5\n",
      "7.4732413 7.5 2.5\n",
      "7.4558063 7.5 7.5\n",
      "6.8179145 7.5 7.5\n",
      "8.182265 7.5 7.5\n",
      "6.3605795 7.5 7.5\n",
      "8.82775 10 2.5\n",
      "6.4925985 7.5 2.5\n",
      "9.774725 10 10.0\n",
      "9.050994 10 10.0\n",
      "7.5621967 7.5 7.5\n",
      "7.7375073 7.5 10.0\n",
      "9.538564 10 10.0\n",
      "6.7260523 7.5 7.5\n",
      "6.9928975 7.5 7.5\n",
      "4.2454185 5 2.5\n",
      "8.913458 10 10.0\n",
      "5.435524 5 2.5\n",
      "7.069144 7.5 2.5\n",
      "5.191503 5 0.0\n",
      "7.4445653 7.5 7.5\n",
      "9.248551 10 10.0\n",
      "7.5086207 7.5 7.5\n",
      "8.966882 10 10.0\n",
      "7.027886 7.5 7.5\n",
      "7.498787 7.5 7.5\n",
      "6.449946 7.5 10.0\n",
      "7.8176117 7.5 10.0\n",
      "6.509526 7.5 7.5\n",
      "6.122298 5 5.0\n",
      "7.063854 7.5 10.0\n",
      "8.963464 10 10.0\n",
      "8.021267 7.5 10.0\n",
      "7.0349474 7.5 10.0\n",
      "7.732552 7.5 10.0\n",
      "7.586988 7.5 5.0\n",
      "6.085227 5 10.0\n",
      "6.929994 7.5 7.5\n",
      "7.0557137 7.5 10.0\n",
      "8.813485 10 2.5\n",
      "7.7594194 7.5 10.0\n",
      "7.205122 7.5 10.0\n",
      "9.455564 10 10.0\n",
      "7.2847705 7.5 5.0\n",
      "6.8737597 7.5 5.0\n",
      "8.735121 7.5 10.0\n",
      "5.746553 5 2.5\n",
      "7.3846097 7.5 10.0\n",
      "5.4099116 5 7.5\n",
      "9.203973 10 10.0\n",
      "6.50757 7.5 2.5\n",
      "5.785525 5 2.5\n",
      "7.429924 7.5 5.0\n",
      "8.514276 7.5 10.0\n",
      "8.714898 7.5 10.0\n",
      "7.1421967 7.5 2.5\n",
      "8.464184 7.5 10.0\n",
      "7.187747 7.5 2.5\n",
      "8.536988 7.5 10.0\n",
      "7.54845 7.5 5.0\n",
      "8.697537 7.5 10.0\n",
      "8.607667 7.5 7.5\n",
      "7.186866 7.5 10.0\n",
      "6.663266 7.5 2.5\n",
      "6.4507785 7.5 7.5\n",
      "8.296478 7.5 7.5\n",
      "7.314121 7.5 7.5\n",
      "6.8918114 7.5 7.5\n",
      "7.044851 7.5 5.0\n",
      "7.7899666 7.5 10.0\n",
      "7.09461 7.5 7.5\n",
      "4.6186843 5 2.5\n",
      "6.355214 7.5 10.0\n",
      "9.169338 10 10.0\n",
      "8.2008 7.5 7.5\n",
      "8.376865 7.5 7.5\n",
      "6.5528026 7.5 7.5\n",
      "5.987219 5 7.5\n",
      "4.9347157 5 7.5\n",
      "7.146894 7.5 7.5\n",
      "6.811525 7.5 2.5\n",
      "7.5428085 7.5 5.0\n",
      "7.453137 7.5 7.5\n",
      "7.887602 7.5 5.0\n",
      "7.151456 7.5 7.5\n",
      "7.3123374 7.5 5.0\n",
      "8.540018 7.5 7.5\n",
      "7.2549872 7.5 7.5\n",
      "6.4958644 7.5 2.5\n",
      "6.7641068 7.5 7.5\n",
      "4.5989475 5 0.0\n",
      "7.576034 7.5 10.0\n",
      "7.593365 7.5 7.5\n",
      "8.065838 7.5 7.5\n",
      "7.4106355 7.5 10.0\n",
      "6.8438683 7.5 7.5\n",
      "7.225608 7.5 10.0\n",
      "7.512239 7.5 10.0\n",
      "7.0448594 7.5 7.5\n",
      "5.268523 5 7.5\n",
      "7.466051 7.5 7.5\n",
      "8.637916 7.5 10.0\n",
      "7.1564126 7.5 7.5\n",
      "8.812299 10 5.0\n",
      "8.743115 7.5 7.5\n",
      "9.019884 10 10.0\n",
      "7.5913563 7.5 5.0\n",
      "7.7267227 7.5 10.0\n",
      "6.4716396 7.5 7.5\n",
      "6.9944367 7.5 2.5\n",
      "7.1243243 7.5 7.5\n",
      "8.703987 7.5 7.5\n",
      "8.217157 7.5 7.5\n",
      "7.5046453 7.5 7.5\n",
      "8.315876 7.5 5.0\n",
      "5.6956534 5 10.0\n",
      "8.69694 7.5 10.0\n",
      "7.385411 7.5 10.0\n",
      "8.1806555 7.5 10.0\n",
      "8.9774475 10 10.0\n",
      "6.8783274 7.5 7.5\n",
      "9.785297 10 7.5\n",
      "6.1938806 5 7.5\n",
      "6.6089344 7.5 7.5\n",
      "8.643121 7.5 10.0\n",
      "8.680582 7.5 5.0\n",
      "8.755383 10 10.0\n",
      "6.9071403 7.5 7.5\n",
      "5.2429338 5 7.5\n",
      "8.281757 7.5 10.0\n",
      "7.5964136 7.5 2.5\n",
      "7.2373586 7.5 7.5\n",
      "6.486621 7.5 7.5\n",
      "6.771817 7.5 7.5\n",
      "8.620655 7.5 7.5\n",
      "9.175645 10 5.0\n",
      "7.187366 7.5 7.5\n",
      "7.4759254 7.5 7.5\n",
      "8.1177845 7.5 10.0\n",
      "8.611422 7.5 10.0\n",
      "8.822244 10 10.0\n",
      "7.4913416 7.5 5.0\n",
      "7.407981 7.5 7.5\n",
      "7.6483407 7.5 10.0\n",
      "7.541469 7.5 10.0\n",
      "7.109718 7.5 5.0\n",
      "7.486066 7.5 10.0\n",
      "7.994737 7.5 7.5\n",
      "7.68822 7.5 10.0\n",
      "5.6646867 5 7.5\n",
      "8.6029825 7.5 10.0\n",
      "9.483179 10 10.0\n",
      "7.295296 7.5 10.0\n",
      "9.029859 10 7.5\n",
      "5.8091884 5 0.0\n",
      "5.740032 5 7.5\n",
      "5.498538 5 5.0\n",
      "6.9687257 7.5 2.5\n",
      "9.286668 10 10.0\n",
      "7.478028 7.5 7.5\n",
      "7.220284 7.5 5.0\n",
      "6.716022 7.5 5.0\n",
      "6.6826515 7.5 5.0\n",
      "8.822994 10 10.0\n",
      "8.114517 7.5 10.0\n",
      "7.451096 7.5 10.0\n",
      "7.302082 7.5 5.0\n",
      "8.558032 7.5 7.5\n",
      "8.00451 7.5 7.5\n",
      "7.9069095 7.5 10.0\n",
      "8.974684 10 7.5\n",
      "7.373004 7.5 7.5\n",
      "7.1409616 7.5 10.0\n",
      "7.3959208 7.5 7.5\n",
      "5.6613936 5 7.5\n",
      "7.6332 7.5 7.5\n",
      "7.86587 7.5 2.5\n",
      "8.94788 10 10.0\n",
      "7.5456867 7.5 7.5\n",
      "7.745742 7.5 7.5\n",
      "8.815609 10 7.5\n",
      "7.620989 7.5 7.5\n",
      "9.196998 10 10.0\n",
      "7.2991962 7.5 5.0\n",
      "7.886896 7.5 7.5\n",
      "8.167473 7.5 2.5\n",
      "7.793927 7.5 7.5\n",
      "6.8595023 7.5 7.5\n",
      "7.9327607 7.5 5.0\n",
      "9.08575 10 10.0\n",
      "7.7906137 7.5 10.0\n",
      "8.805328 10 7.5\n",
      "7.477594 7.5 10.0\n",
      "7.3080354 7.5 10.0\n",
      "7.0417 7.5 10.0\n",
      "7.1795034 7.5 2.5\n",
      "8.952321 10 10.0\n",
      "6.2882357 7.5 7.5\n",
      "8.555668 7.5 5.0\n",
      "8.493538 7.5 7.5\n",
      "8.73978 7.5 10.0\n",
      "8.429314 7.5 10.0\n",
      "7.1374307 7.5 7.5\n",
      "8.879378 10 7.5\n",
      "7.659003 7.5 10.0\n",
      "6.3142133 7.5 2.5\n",
      "7.169751 7.5 10.0\n",
      "8.2054615 7.5 10.0\n",
      "6.8600082 7.5 10.0\n",
      "8.788044 10 10.0\n",
      "6.810656 7.5 5.0\n",
      "8.93925 10 7.5\n",
      "6.626221 7.5 7.5\n",
      "7.790435 7.5 10.0\n",
      "8.750533 10 10.0\n",
      "7.784374 7.5 10.0\n",
      "7.319374 7.5 5.0\n",
      "6.8688507 7.5 7.5\n",
      "9.553318 10 10.0\n",
      "7.1464562 7.5 7.5\n",
      "8.914801 10 10.0\n",
      "4.4226484 5 7.5\n",
      "8.526663 7.5 2.5\n",
      "9.217181 10 7.5\n",
      "8.803108 10 10.0\n",
      "7.061543 7.5 7.5\n",
      "8.6854105 7.5 10.0\n",
      "8.708967 7.5 7.5\n",
      "7.427226 7.5 10.0\n",
      "8.480953 7.5 7.5\n",
      "6.412194 7.5 7.5\n",
      "8.024704 7.5 10.0\n",
      "4.946924 5 2.5\n",
      "7.828813 7.5 10.0\n",
      "8.925004 10 10.0\n",
      "5.6424537 5 5.0\n",
      "7.219738 7.5 7.5\n",
      "7.7464285 7.5 7.5\n",
      "4.7814307 5 5.0\n",
      "6.554984 7.5 7.5\n",
      "8.494024 7.5 10.0\n",
      "6.5330257 7.5 2.5\n",
      "8.953579 10 7.5\n",
      "6.7262745 7.5 5.0\n",
      "5.8080707 5 5.0\n",
      "8.200482 7.5 10.0\n",
      "6.5908813 7.5 2.5\n",
      "7.3661475 7.5 7.5\n",
      "7.3360615 7.5 7.5\n",
      "9.13434 10 10.0\n",
      "6.7171574 7.5 7.5\n",
      "8.603332 7.5 7.5\n",
      "7.074343 7.5 5.0\n",
      "6.7384787 7.5 10.0\n",
      "5.199965 5 0.0\n",
      "9.223745 10 10.0\n",
      "7.737554 7.5 5.0\n",
      "5.234888 5 7.5\n",
      "6.2234335 5 7.5\n",
      "8.678134 7.5 7.5\n",
      "6.2208266 5 7.5\n",
      "6.7712274 7.5 10.0\n",
      "5.740088 5 2.5\n",
      "7.2667933 7.5 7.5\n",
      "7.6964865 7.5 5.0\n",
      "8.2085495 7.5 10.0\n",
      "6.1386037 5 2.5\n",
      "8.527719 7.5 10.0\n",
      "6.4446654 7.5 7.5\n",
      "7.1821866 7.5 7.5\n",
      "5.479504 5 2.5\n",
      "5.3922663 5 7.5\n",
      "8.669475 7.5 10.0\n",
      "9.067867 10 10.0\n",
      "7.5673323 7.5 2.5\n",
      "6.632557 7.5 10.0\n",
      "7.230455 7.5 5.0\n",
      "7.8837194 7.5 5.0\n",
      "8.845236 10 2.5\n",
      "6.2565565 7.5 5.0\n",
      "8.344422 7.5 7.5\n",
      "6.801099 7.5 5.0\n",
      "5.749136 5 2.5\n",
      "8.002837 7.5 10.0\n",
      "7.6359105 7.5 7.5\n",
      "6.5352516 7.5 10.0\n",
      "5.3504424 5 2.5\n",
      "7.0716796 7.5 7.5\n",
      "7.93775 7.5 10.0\n",
      "7.541265 7.5 7.5\n",
      "8.935629 10 7.5\n",
      "7.793917 7.5 10.0\n",
      "6.9183064 7.5 2.5\n",
      "7.366221 7.5 2.5\n",
      "6.8426757 7.5 7.5\n",
      "7.8274326 7.5 10.0\n",
      "5.049364 5 2.5\n",
      "7.0201197 7.5 10.0\n",
      "8.233742 7.5 7.5\n",
      "8.915218 10 10.0\n",
      "7.3247695 7.5 2.5\n",
      "9.456071 10 7.5\n",
      "6.8846717 7.5 7.5\n",
      "8.792272 10 10.0\n",
      "7.1873093 7.5 5.0\n",
      "7.7473865 7.5 7.5\n",
      "8.013124 7.5 10.0\n",
      "7.1964283 7.5 7.5\n",
      "9.183392 10 10.0\n",
      "8.739866 7.5 7.5\n",
      "7.2692833 7.5 7.5\n",
      "9.072422 10 10.0\n",
      "4.4244757 5 0.0\n",
      "7.137235 7.5 7.5\n",
      "7.0545163 7.5 7.5\n",
      "6.024472 5 5.0\n",
      "8.640497 7.5 7.5\n",
      "7.149264 7.5 10.0\n",
      "7.0813375 7.5 10.0\n",
      "7.5472527 7.5 10.0\n",
      "6.8816147 7.5 10.0\n",
      "7.1109734 7.5 7.5\n",
      "7.7418427 7.5 7.5\n",
      "7.4933615 7.5 7.5\n",
      "6.8401346 7.5 7.5\n",
      "8.641765 7.5 10.0\n",
      "8.495836 7.5 10.0\n",
      "6.913295 7.5 7.5\n",
      "9.247961 10 7.5\n",
      "7.3477445 7.5 7.5\n",
      "8.371833 7.5 7.5\n",
      "7.105676 7.5 10.0\n",
      "8.610822 7.5 7.5\n",
      "9.176532 10 10.0\n",
      "6.139636 5 7.5\n",
      "7.5413303 7.5 10.0\n",
      "8.279529 7.5 10.0\n",
      "8.737379 7.5 10.0\n",
      "7.029888 7.5 7.5\n",
      "9.3458395 10 7.5\n",
      "6.0182886 5 7.5\n",
      "6.634849 7.5 7.5\n",
      "8.545707 7.5 10.0\n",
      "7.5122757 7.5 7.5\n",
      "7.973449 7.5 0.0\n",
      "9.290523 10 7.5\n",
      "6.656411 7.5 7.5\n",
      "6.5741644 7.5 7.5\n",
      "7.302179 7.5 7.5\n",
      "6.8291636 7.5 7.5\n",
      "7.8633523 7.5 10.0\n",
      "6.7097077 7.5 5.0\n",
      "8.009538 7.5 5.0\n",
      "4.436139 5 7.5\n",
      "7.2893195 7.5 2.5\n",
      "7.7883353 7.5 7.5\n",
      "7.339655 7.5 10.0\n",
      "7.6217484 7.5 10.0\n",
      "7.738951 7.5 10.0\n",
      "6.5560365 7.5 10.0\n",
      "8.728482 7.5 7.5\n",
      "5.1010313 5 5.0\n",
      "4.3613224 5 0.0\n",
      "9.5216055 10 10.0\n",
      "9.29446 10 7.5\n",
      "8.210159 7.5 10.0\n",
      "8.984551 10 7.5\n",
      "6.139171 5 7.5\n",
      "8.1457615 7.5 7.5\n",
      "8.890227 10 10.0\n",
      "7.43087 7.5 7.5\n",
      "7.1270623 7.5 7.5\n",
      "6.802337 7.5 5.0\n",
      "7.8323064 7.5 7.5\n",
      "8.99246 10 10.0\n",
      "7.029524 7.5 7.5\n",
      "6.5357003 7.5 7.5\n",
      "7.1400647 7.5 7.5\n",
      "6.397643 7.5 7.5\n",
      "8.446936 7.5 7.5\n",
      "9.142687 10 7.5\n",
      "7.1688886 7.5 10.0\n",
      "6.255579 7.5 2.5\n",
      "6.0960407 5 10.0\n",
      "7.8559084 7.5 10.0\n",
      "5.342618 5 5.0\n",
      "8.438427 7.5 7.5\n",
      "7.3734694 7.5 10.0\n",
      "6.405296 7.5 7.5\n",
      "8.155603 7.5 10.0\n",
      "8.190871 7.5 7.5\n",
      "9.0663805 10 10.0\n",
      "7.9243712 7.5 10.0\n",
      "7.620014 7.5 7.5\n",
      "7.4874115 7.5 10.0\n",
      "8.342056 7.5 7.5\n",
      "8.776154 10 10.0\n",
      "7.26893 7.5 10.0\n",
      "9.145419 10 10.0\n",
      "8.861709 10 10.0\n",
      "7.105817 7.5 10.0\n",
      "8.636096 7.5 10.0\n",
      "6.829931 7.5 5.0\n",
      "7.282233 7.5 2.5\n",
      "8.826428 10 7.5\n",
      "8.053238 7.5 10.0\n",
      "8.7493515 7.5 10.0\n",
      "8.689772 7.5 7.5\n",
      "8.869054 10 10.0\n",
      "6.188213 5 7.5\n",
      "8.557263 7.5 10.0\n",
      "7.8925877 7.5 10.0\n",
      "8.160575 7.5 10.0\n",
      "7.78371 7.5 7.5\n",
      "7.9097896 7.5 7.5\n",
      "6.996173 7.5 7.5\n",
      "8.052032 7.5 10.0\n",
      "7.4665585 7.5 10.0\n",
      "7.224904 7.5 10.0\n",
      "6.9748864 7.5 5.0\n",
      "7.4137926 7.5 2.5\n",
      "7.2851715 7.5 7.5\n",
      "7.31 7.5 7.5\n",
      "8.6545515 7.5 10.0\n",
      "8.431164 7.5 7.5\n",
      "7.219908 7.5 10.0\n",
      "6.9951906 7.5 7.5\n",
      "9.066986 10 10.0\n",
      "7.1111197 7.5 7.5\n",
      "7.3360605 7.5 10.0\n",
      "7.63771 7.5 0.0\n",
      "7.012859 7.5 7.5\n",
      "8.961229 10 10.0\n",
      "7.000494 7.5 7.5\n",
      "6.6613817 7.5 2.5\n",
      "9.101882 10 7.5\n",
      "9.059652 10 10.0\n",
      "8.604819 7.5 10.0\n",
      "8.625079 7.5 10.0\n",
      "7.5306935 7.5 7.5\n",
      "7.304101 7.5 10.0\n",
      "6.1289907 5 7.5\n",
      "7.281407 7.5 7.5\n",
      "8.888058 10 10.0\n",
      "7.274769 7.5 7.5\n",
      "8.896404 10 10.0\n",
      "9.15768 10 10.0\n",
      "8.768877 10 10.0\n",
      "5.280571 5 2.5\n",
      "6.705205 7.5 5.0\n",
      "7.762806 7.5 10.0\n",
      "6.7312284 7.5 10.0\n",
      "7.591618 7.5 7.5\n",
      "6.308951 7.5 10.0\n",
      "7.094358 7.5 7.5\n",
      "7.978814 7.5 7.5\n",
      "6.5401406 7.5 5.0\n",
      "6.9508786 7.5 10.0\n",
      "8.48898 7.5 7.5\n",
      "8.505541 7.5 10.0\n",
      "6.6333866 7.5 2.5\n",
      "6.710438 7.5 10.0\n",
      "7.039234 7.5 7.5\n",
      "7.3088984 7.5 2.5\n",
      "7.594661 7.5 7.5\n",
      "7.799756 7.5 7.5\n",
      "7.924488 7.5 7.5\n",
      "8.130526 7.5 7.5\n",
      "7.4066944 7.5 7.5\n",
      "7.270441 7.5 2.5\n",
      "7.265235 7.5 7.5\n",
      "8.737057 7.5 10.0\n",
      "5.083915 5 7.5\n",
      "7.602276 7.5 5.0\n",
      "7.356227 7.5 10.0\n",
      "8.869089 10 7.5\n",
      "7.2095714 7.5 7.5\n",
      "8.55527 7.5 7.5\n",
      "7.8641415 7.5 10.0\n",
      "6.017965 5 2.5\n",
      "6.474202 7.5 7.5\n",
      "8.801375 10 7.5\n",
      "7.997595 7.5 10.0\n",
      "8.310228 7.5 7.5\n",
      "7.712623 7.5 10.0\n",
      "8.753038 10 10.0\n",
      "7.755875 7.5 7.5\n",
      "8.469633 7.5 10.0\n",
      "8.895757 10 7.5\n",
      "7.3946657 7.5 7.5\n",
      "6.4811864 7.5 7.5\n",
      "6.4527173 7.5 2.5\n",
      "6.9135666 7.5 7.5\n",
      "7.139869 7.5 2.5\n",
      "8.39085 7.5 7.5\n",
      "7.079531 7.5 7.5\n",
      "9.039807 10 10.0\n",
      "7.822174 7.5 7.5\n",
      "7.0947776 7.5 10.0\n",
      "8.168383 7.5 10.0\n",
      "7.177552 7.5 7.5\n",
      "5.489314 5 7.5\n",
      "4.826519 5 7.5\n",
      "6.8174458 7.5 10.0\n",
      "7.8012595 7.5 10.0\n",
      "6.06841 5 7.5\n",
      "8.877749 10 7.5\n",
      "7.951837 7.5 7.5\n",
      "5.344897 5 2.5\n",
      "8.195393 7.5 10.0\n",
      "8.40124 7.5 7.5\n",
      "7.6985817 7.5 7.5\n",
      "7.8474765 7.5 5.0\n",
      "7.2066436 7.5 7.5\n",
      "8.149211 7.5 7.5\n",
      "6.9455957 7.5 5.0\n",
      "6.3098154 7.5 2.5\n",
      "6.33211 7.5 5.0\n",
      "6.40574 7.5 7.5\n",
      "6.9030623 7.5 7.5\n",
      "3.206841 2.5 2.5\n",
      "7.447324 7.5 2.5\n",
      "7.562243 7.5 7.5\n",
      "6.3648105 7.5 10.0\n",
      "4.9486704 5 7.5\n",
      "7.817934 7.5 2.5\n",
      "8.402046 7.5 10.0\n",
      "7.7464633 7.5 2.5\n",
      "8.706513 7.5 10.0\n",
      "7.3992596 7.5 5.0\n",
      "6.945388 7.5 7.5\n",
      "8.492481 7.5 10.0\n",
      "8.299252 7.5 7.5\n",
      "7.583466 7.5 10.0\n",
      "7.2872763 7.5 7.5\n",
      "8.35582 7.5 7.5\n",
      "8.030301 7.5 7.5\n",
      "9.012908 10 10.0\n",
      "7.240848 7.5 10.0\n",
      "6.959243 7.5 5.0\n",
      "8.585435 7.5 7.5\n",
      "7.555036 7.5 7.5\n",
      "8.290573 7.5 10.0\n",
      "8.799361 10 7.5\n",
      "5.264028 5 7.5\n",
      "7.9414825 7.5 7.5\n",
      "7.856016 7.5 7.5\n",
      "9.483923 10 10.0\n",
      "6.076272 5 10.0\n",
      "7.0877542 7.5 10.0\n",
      "6.9425583 7.5 2.5\n",
      "7.468598 7.5 5.0\n",
      "7.3825173 7.5 5.0\n",
      "7.115344 7.5 7.5\n",
      "8.0335045 7.5 10.0\n",
      "8.730178 7.5 10.0\n",
      "8.419784 7.5 10.0\n",
      "7.798797 7.5 7.5\n",
      "7.6943526 7.5 7.5\n",
      "6.584841 7.5 5.0\n",
      "6.7851033 7.5 7.5\n",
      "7.1537595 7.5 10.0\n",
      "7.422084 7.5 7.5\n",
      "7.165734 7.5 7.5\n",
      "3.8009396 5 2.5\n",
      "6.9972525 7.5 10.0\n",
      "8.824984 10 10.0\n",
      "7.791033 7.5 7.5\n",
      "8.141205 7.5 10.0\n",
      "4.988617 5 2.5\n",
      "7.219178 7.5 7.5\n",
      "7.0459085 7.5 10.0\n",
      "7.070277 7.5 5.0\n",
      "8.11845 7.5 7.5\n",
      "8.998032 10 10.0\n",
      "6.8798656 7.5 7.5\n",
      "6.174459 5 5.0\n",
      "4.4020157 5 0.0\n",
      "8.0084915 7.5 10.0\n",
      "7.26875 7.5 7.5\n",
      "8.78282 10 7.5\n",
      "7.0594187 7.5 0.0\n",
      "8.089159 7.5 10.0\n",
      "7.018011 7.5 7.5\n",
      "5.6199512 5 7.5\n",
      "4.4933977 5 2.5\n",
      "7.1704116 7.5 7.5\n",
      "7.3016014 7.5 5.0\n",
      "5.169882 5 2.5\n",
      "8.3884 7.5 10.0\n",
      "4.523283 5 2.5\n",
      "7.107578 7.5 7.5\n",
      "7.3936977 7.5 7.5\n",
      "7.8517084 7.5 2.5\n",
      "7.00041 7.5 7.5\n",
      "6.455077 7.5 7.5\n",
      "7.4617457 7.5 10.0\n",
      "5.392189 5 7.5\n",
      "7.701345 7.5 7.5\n",
      "8.87136 10 7.5\n",
      "8.94487 10 7.5\n",
      "8.811584 10 10.0\n",
      "7.2529273 7.5 2.5\n",
      "5.091694 5 7.5\n",
      "9.023467 10 5.0\n",
      "8.589597 7.5 10.0\n",
      "7.219659 7.5 7.5\n",
      "8.477047 7.5 10.0\n",
      "7.1748805 7.5 2.5\n",
      "7.433496 7.5 7.5\n",
      "8.793344 10 10.0\n",
      "9.211994 10 10.0\n",
      "7.1827335 7.5 7.5\n",
      "7.5120325 7.5 7.5\n",
      "7.3371315 7.5 7.5\n",
      "6.986016 7.5 5.0\n",
      "7.859622 7.5 5.0\n",
      "6.8411217 7.5 2.5\n",
      "5.3299756 5 5.0\n",
      "5.7599874 5 2.5\n",
      "7.130823 7.5 2.5\n",
      "4.8966084 5 7.5\n",
      "7.036296 7.5 5.0\n",
      "8.859753 10 10.0\n",
      "8.998312 10 10.0\n",
      "6.9230065 7.5 2.5\n",
      "6.1667223 5 5.0\n",
      "7.46657 7.5 10.0\n",
      "7.1951647 7.5 10.0\n",
      "9.417651 10 10.0\n",
      "7.1169744 7.5 10.0\n",
      "8.759647 10 10.0\n",
      "8.686352 7.5 10.0\n",
      "7.8044577 7.5 7.5\n",
      "6.2809176 7.5 10.0\n",
      "6.733169 7.5 10.0\n",
      "6.9946346 7.5 5.0\n",
      "7.5724654 7.5 10.0\n",
      "5.876876 5 7.5\n",
      "7.2717805 7.5 7.5\n",
      "7.252929 7.5 10.0\n",
      "8.265154 7.5 7.5\n",
      "8.61026 7.5 10.0\n",
      "4.2675037 5 7.5\n",
      "8.10353 7.5 7.5\n",
      "8.166803 7.5 5.0\n",
      "8.212906 7.5 7.5\n",
      "7.3442926 7.5 7.5\n",
      "5.345816 5 2.5\n",
      "7.0297627 7.5 7.5\n",
      "8.757666 10 10.0\n",
      "6.4201317 7.5 7.5\n",
      "7.4657893 7.5 7.5\n",
      "7.800231 7.5 7.5\n",
      "8.073482 7.5 2.5\n",
      "6.745623 7.5 5.0\n",
      "5.237392 5 7.5\n",
      "7.5151434 7.5 7.5\n",
      "7.7858205 7.5 7.5\n",
      "7.201031 7.5 10.0\n",
      "7.1281676 7.5 5.0\n",
      "8.2869625 7.5 7.5\n",
      "6.612165 7.5 10.0\n",
      "7.377511 7.5 10.0\n",
      "7.099855 7.5 7.5\n",
      "7.523238 7.5 7.5\n",
      "6.3083353 7.5 7.5\n",
      "7.7223873 7.5 7.5\n",
      "7.8259206 7.5 10.0\n",
      "8.568031 7.5 10.0\n",
      "7.122948 7.5 10.0\n",
      "7.7605457 7.5 10.0\n",
      "7.4238973 7.5 7.5\n",
      "6.36018 7.5 7.5\n",
      "6.642846 7.5 7.5\n",
      "7.260721 7.5 5.0\n",
      "8.953952 10 10.0\n",
      "8.366808 7.5 7.5\n",
      "7.011583 7.5 10.0\n",
      "7.934847 7.5 10.0\n",
      "6.5885687 7.5 5.0\n",
      "6.4567766 7.5 7.5\n",
      "7.671178 7.5 5.0\n",
      "8.154356 7.5 7.5\n",
      "6.404556 7.5 2.5\n",
      "5.465638 5 2.5\n",
      "6.8559866 7.5 7.5\n",
      "6.5621066 7.5 7.5\n",
      "6.2901382 7.5 10.0\n",
      "6.9750776 7.5 10.0\n",
      "7.4078064 7.5 2.5\n",
      "8.242606 7.5 7.5\n",
      "7.745081 7.5 10.0\n",
      "7.051695 7.5 7.5\n",
      "8.875136 10 7.5\n",
      "6.3689322 7.5 2.5\n",
      "6.9917083 7.5 2.5\n",
      "8.377071 7.5 10.0\n",
      "6.3208 7.5 2.5\n",
      "6.4019732 7.5 7.5\n",
      "5.8370466 5 7.5\n",
      "6.9752703 7.5 7.5\n",
      "7.8977265 7.5 7.5\n",
      "8.067947 7.5 7.5\n",
      "9.118327 10 10.0\n",
      "7.101579 7.5 10.0\n",
      "6.7159967 7.5 2.5\n",
      "7.2055264 7.5 10.0\n",
      "7.661001 7.5 7.5\n",
      "7.2205963 7.5 5.0\n",
      "6.633061 7.5 2.5\n",
      "6.6140428 7.5 10.0\n",
      "8.52115 7.5 10.0\n",
      "7.3540564 7.5 10.0\n",
      "8.627132 7.5 10.0\n",
      "6.3774414 7.5 2.5\n",
      "8.874928 10 10.0\n",
      "6.4356565 7.5 2.5\n",
      "6.4370685 7.5 2.5\n",
      "7.2858677 7.5 7.5\n",
      "7.385181 7.5 7.5\n",
      "8.027273 7.5 10.0\n",
      "7.5243363 7.5 7.5\n",
      "6.336462 7.5 10.0\n",
      "8.3227825 7.5 10.0\n",
      "7.106969 7.5 7.5\n",
      "7.195165 7.5 7.5\n",
      "7.069553 7.5 7.5\n",
      "7.480245 7.5 2.5\n",
      "6.7298155 7.5 5.0\n",
      "5.521868 5 7.5\n",
      "6.6968417 7.5 7.5\n",
      "7.3511276 7.5 0.0\n",
      "9.303144 10 10.0\n",
      "7.4655623 7.5 7.5\n",
      "5.6219034 5 0.0\n",
      "7.111885 7.5 7.5\n",
      "7.6180983 7.5 2.5\n",
      "5.714168 5 2.5\n",
      "7.4361115 7.5 7.5\n",
      "8.853647 10 7.5\n",
      "9.173534 10 10.0\n",
      "8.322689 7.5 7.5\n",
      "7.1198945 7.5 7.5\n",
      "8.685178 7.5 10.0\n",
      "7.5461574 7.5 7.5\n",
      "7.625299 7.5 10.0\n",
      "7.795294 7.5 10.0\n",
      "8.32785 7.5 10.0\n",
      "5.0081077 5 2.5\n",
      "6.4386535 7.5 7.5\n",
      "7.0277205 7.5 7.5\n",
      "7.8231196 7.5 7.5\n",
      "7.39638 7.5 7.5\n",
      "8.520012 7.5 10.0\n",
      "8.0893 7.5 5.0\n",
      "7.013221 7.5 10.0\n",
      "5.8427258 5 2.5\n",
      "8.448505 7.5 7.5\n",
      "7.68631 7.5 10.0\n",
      "8.408602 7.5 7.5\n",
      "7.281528 7.5 10.0\n",
      "7.4973373 7.5 7.5\n",
      "9.097749 10 2.5\n",
      "8.948606 10 5.0\n",
      "6.835436 7.5 7.5\n",
      "7.6762257 7.5 10.0\n",
      "8.882473 10 10.0\n",
      "7.2579484 7.5 7.5\n",
      "7.913873 7.5 7.5\n",
      "8.181637 7.5 10.0\n",
      "7.5347548 7.5 5.0\n",
      "6.7162385 7.5 10.0\n",
      "6.5141006 7.5 10.0\n",
      "5.0072517 5 2.5\n",
      "7.319083 7.5 5.0\n",
      "7.726082 7.5 5.0\n",
      "9.070667 10 10.0\n",
      "6.9449677 7.5 7.5\n",
      "7.4241624 7.5 10.0\n",
      "8.935159 10 10.0\n",
      "9.121632 10 7.5\n",
      "9.037085 10 10.0\n",
      "9.079686 10 10.0\n",
      "5.319502 5 7.5\n",
      "7.750863 7.5 10.0\n",
      "8.297959 7.5 5.0\n",
      "7.107518 7.5 2.5\n",
      "9.366106 10 10.0\n",
      "7.842175 7.5 2.5\n",
      "7.3438187 7.5 7.5\n",
      "7.6902995 7.5 7.5\n",
      "4.9804335 5 2.5\n",
      "8.831953 10 10.0\n",
      "7.756983 7.5 2.5\n",
      "7.169433 7.5 7.5\n",
      "8.091944 7.5 10.0\n",
      "7.7673006 7.5 10.0\n",
      "8.80626 10 10.0\n",
      "8.424608 7.5 7.5\n",
      "7.9119263 7.5 7.5\n",
      "7.6256275 7.5 7.5\n",
      "8.038233 7.5 10.0\n",
      "7.2625117 7.5 5.0\n",
      "6.7822204 7.5 7.5\n",
      "7.144688 7.5 7.5\n",
      "8.487054 7.5 10.0\n",
      "8.587625 7.5 10.0\n",
      "7.0492554 7.5 7.5\n",
      "6.342285 7.5 5.0\n",
      "6.38799 7.5 10.0\n",
      "7.1295676 7.5 7.5\n",
      "7.4619455 7.5 5.0\n",
      "4.3434243 5 7.5\n",
      "9.680006 10 10.0\n",
      "6.9844713 7.5 7.5\n",
      "8.150993 7.5 2.5\n",
      "7.2638707 7.5 7.5\n",
      "7.212571 7.5 7.5\n",
      "8.798696 10 10.0\n",
      "7.992386 7.5 7.5\n",
      "8.897947 10 7.5\n",
      "6.931009 7.5 10.0\n",
      "5.980958 5 7.5\n",
      "7.5002656 7.5 7.5\n",
      "8.1958885 7.5 10.0\n",
      "8.373877 7.5 2.5\n",
      "6.0194907 5 5.0\n",
      "5.157937 5 2.5\n",
      "7.683049 7.5 7.5\n",
      "7.460378 7.5 7.5\n",
      "8.31866 7.5 10.0\n",
      "6.86084 7.5 2.5\n",
      "6.9291873 7.5 7.5\n",
      "7.3484073 7.5 7.5\n",
      "7.491715 7.5 7.5\n",
      "6.5854144 7.5 7.5\n",
      "8.226849 7.5 10.0\n",
      "7.6999984 7.5 10.0\n",
      "6.993706 7.5 7.5\n",
      "7.161355 7.5 7.5\n",
      "8.086059 7.5 7.5\n",
      "4.4511447 5 7.5\n",
      "7.724736 7.5 5.0\n",
      "6.8132577 7.5 7.5\n",
      "8.556672 7.5 7.5\n",
      "8.3048 7.5 10.0\n",
      "8.198301 7.5 10.0\n",
      "7.0581517 7.5 7.5\n",
      "8.775366 10 10.0\n",
      "9.535846 10 10.0\n",
      "6.279993 7.5 10.0\n",
      "8.58876 7.5 10.0\n",
      "8.370449 7.5 10.0\n",
      "5.8076835 5 0.0\n",
      "9.35909 10 10.0\n",
      "8.692758 7.5 10.0\n",
      "6.409334 7.5 7.5\n",
      "7.706914 7.5 7.5\n",
      "7.9264364 7.5 10.0\n",
      "8.374477 7.5 10.0\n",
      "5.5105133 5 2.5\n",
      "6.679524 7.5 7.5\n",
      "5.9542613 5 7.5\n",
      "6.602333 7.5 7.5\n",
      "5.38588 5 2.5\n",
      "7.379202 7.5 7.5\n",
      "8.2308655 7.5 10.0\n",
      "9.017106 10 10.0\n",
      "7.245659 7.5 7.5\n",
      "7.0276556 7.5 7.5\n",
      "7.7206063 7.5 10.0\n",
      "7.5445886 7.5 7.5\n",
      "8.026932 7.5 7.5\n",
      "7.314439 7.5 10.0\n",
      "8.70756 7.5 7.5\n",
      "7.4323936 7.5 7.5\n",
      "5.741646 5 7.5\n",
      "7.568746 7.5 5.0\n",
      "3.4795103 2.5 0.0\n",
      "9.297452 10 10.0\n",
      "6.5596867 7.5 7.5\n",
      "7.263273 7.5 10.0\n",
      "4.1708136 5 2.5\n",
      "8.284242 7.5 5.0\n",
      "7.6258106 7.5 2.5\n",
      "8.794491 10 10.0\n",
      "6.4097238 7.5 10.0\n",
      "6.2405357 5 7.5\n",
      "8.163931 7.5 10.0\n",
      "8.669819 7.5 7.5\n",
      "6.081125 5 2.5\n",
      "9.173985 10 10.0\n",
      "7.297164 7.5 10.0\n",
      "6.5417137 7.5 5.0\n",
      "8.056555 7.5 7.5\n",
      "8.813874 10 5.0\n",
      "7.6736975 7.5 10.0\n",
      "5.195836 5 2.5\n",
      "7.1033144 7.5 7.5\n",
      "8.408995 7.5 10.0\n",
      "7.2171135 7.5 7.5\n",
      "7.4275546 7.5 7.5\n",
      "9.351756 10 10.0\n",
      "7.830738 7.5 10.0\n",
      "6.8312693 7.5 10.0\n",
      "6.898449 7.5 2.5\n",
      "4.3234873 5 2.5\n",
      "9.103485 10 10.0\n",
      "7.1605515 7.5 5.0\n",
      "5.3991456 5 7.5\n",
      "6.0527334 5 10.0\n",
      "6.081086 5 10.0\n",
      "7.685126 7.5 2.5\n",
      "8.429449 7.5 10.0\n",
      "7.0713825 7.5 2.5\n",
      "8.441404 7.5 10.0\n",
      "9.217741 10 10.0\n",
      "6.127519 5 5.0\n",
      "8.317212 7.5 7.5\n",
      "8.196624 7.5 7.5\n",
      "7.9834213 7.5 10.0\n",
      "5.641536 5 5.0\n",
      "6.13573 5 7.5\n",
      "9.109113 10 10.0\n",
      "5.9636765 5 5.0\n",
      "6.5842867 7.5 7.5\n",
      "7.7114897 7.5 10.0\n",
      "6.721934 7.5 5.0\n",
      "7.4219737 7.5 7.5\n",
      "8.45464 7.5 10.0\n",
      "7.1086082 7.5 7.5\n",
      "6.7797236 7.5 7.5\n",
      "9.308021 10 10.0\n",
      "7.287206 7.5 10.0\n",
      "8.959152 10 10.0\n",
      "8.951061 10 10.0\n",
      "7.508816 7.5 7.5\n",
      "5.068099 5 10.0\n",
      "7.4520006 7.5 7.5\n",
      "7.061678 7.5 10.0\n",
      "7.398614 7.5 10.0\n",
      "7.470941 7.5 7.5\n",
      "6.022891 5 2.5\n",
      "6.1525383 5 5.0\n",
      "6.6300006 7.5 7.5\n",
      "7.019757 7.5 7.5\n",
      "7.284956 7.5 7.5\n",
      "8.901727 10 10.0\n",
      "8.746807 7.5 7.5\n",
      "8.050109 7.5 7.5\n",
      "6.6938796 7.5 7.5\n",
      "8.166225 7.5 10.0\n",
      "7.4254622 7.5 7.5\n",
      "7.721778 7.5 10.0\n",
      "7.1940374 7.5 7.5\n",
      "9.039702 10 10.0\n",
      "8.23031 7.5 10.0\n",
      "9.2777815 10 10.0\n",
      "9.097258 10 10.0\n",
      "7.314315 7.5 10.0\n",
      "7.57996 7.5 7.5\n",
      "6.975276 7.5 7.5\n",
      "7.7763925 7.5 2.5\n",
      "7.2128057 7.5 7.5\n",
      "7.4142804 7.5 10.0\n",
      "8.633662 7.5 7.5\n",
      "8.816249 10 7.5\n",
      "7.356138 7.5 7.5\n",
      "8.937003 10 7.5\n",
      "5.4896417 5 7.5\n",
      "8.899139 10 10.0\n",
      "7.5480833 7.5 7.5\n",
      "9.131315 10 7.5\n",
      "6.890008 7.5 7.5\n",
      "7.1961164 7.5 5.0\n",
      "7.293993 7.5 7.5\n",
      "8.294857 7.5 7.5\n",
      "8.777818 10 10.0\n",
      "9.284302 10 7.5\n",
      "8.583701 7.5 10.0\n",
      "8.726537 7.5 5.0\n",
      "6.5027018 7.5 10.0\n",
      "8.27832 7.5 10.0\n",
      "7.3361435 7.5 10.0\n",
      "4.8088937 5 7.5\n",
      "3.8102713 5 10.0\n",
      "6.2598176 7.5 10.0\n",
      "8.959952 10 5.0\n",
      "4.4287815 5 2.5\n",
      "9.2451515 10 10.0\n",
      "7.2926154 7.5 10.0\n",
      "7.317317 7.5 7.5\n",
      "7.9175944 7.5 10.0\n",
      "7.275666 7.5 2.5\n",
      "7.592629 7.5 7.5\n",
      "6.2287884 5 7.5\n",
      "7.5004053 7.5 7.5\n",
      "7.9783263 7.5 10.0\n",
      "8.9561 10 10.0\n",
      "5.882693 5 7.5\n",
      "4.985522 5 7.5\n",
      "6.6387334 7.5 10.0\n",
      "7.6975536 7.5 10.0\n",
      "8.455681 7.5 10.0\n",
      "7.876215 7.5 10.0\n",
      "8.567278 7.5 10.0\n",
      "8.6879225 7.5 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7574396 7.5 7.5\n",
      "7.146657 7.5 10.0\n",
      "8.529603 7.5 5.0\n",
      "7.1334844 7.5 7.5\n",
      "5.8378696 5 2.5\n",
      "7.2832446 7.5 7.5\n",
      "7.612223 7.5 7.5\n",
      "6.818888 7.5 7.5\n",
      "7.420518 7.5 7.5\n",
      "7.2980275 7.5 5.0\n",
      "5.7383604 5 2.5\n",
      "6.2615175 7.5 7.5\n",
      "6.6522627 7.5 7.5\n",
      "6.1226707 5 7.5\n",
      "4.436254 5 7.5\n",
      "7.765819 7.5 7.5\n",
      "7.6464105 7.5 5.0\n",
      "7.4550295 7.5 10.0\n",
      "8.247253 7.5 7.5\n",
      "7.783889 7.5 10.0\n",
      "6.8527164 7.5 7.5\n",
      "7.6722775 7.5 7.5\n",
      "7.215664 7.5 2.5\n",
      "6.639135 7.5 10.0\n",
      "7.11952 7.5 7.5\n",
      "8.538041 7.5 10.0\n",
      "9.917143 10 10.0\n",
      "7.593615 7.5 10.0\n",
      "8.31717 7.5 7.5\n",
      "7.4880567 7.5 2.5\n",
      "6.509329 7.5 7.5\n",
      "6.3432565 7.5 2.5\n",
      "8.837619 10 10.0\n",
      "7.251931 7.5 7.5\n",
      "5.1459727 5 2.5\n",
      "4.7939253 5 0.0\n",
      "7.554099 7.5 10.0\n",
      "5.7530193 5 2.5\n",
      "7.1315784 7.5 10.0\n",
      "6.6707196 7.5 7.5\n",
      "9.495126 10 10.0\n",
      "7.509618 7.5 10.0\n",
      "7.072568 7.5 10.0\n",
      "8.936038 10 10.0\n",
      "7.7594514 7.5 7.5\n",
      "7.373159 7.5 10.0\n",
      "7.533154 7.5 10.0\n",
      "9.063518 10 7.5\n",
      "6.768366 7.5 2.5\n",
      "6.259156 7.5 7.5\n",
      "7.2441187 7.5 7.5\n",
      "7.7757993 7.5 7.5\n",
      "6.8099904 7.5 5.0\n",
      "6.2015033 5 2.5\n",
      "6.786014 7.5 5.0\n",
      "8.877727 10 10.0\n",
      "8.141465 7.5 5.0\n",
      "8.738115 7.5 10.0\n",
      "7.3168907 7.5 5.0\n",
      "7.533999 7.5 7.5\n",
      "7.1918025 7.5 10.0\n",
      "9.0334425 10 7.5\n",
      "6.937531 7.5 10.0\n",
      "7.204334 7.5 10.0\n",
      "7.071659 7.5 2.5\n",
      "7.742923 7.5 7.5\n",
      "6.729344 7.5 10.0\n",
      "8.120781 7.5 10.0\n",
      "6.0358644 5 7.5\n",
      "7.355685 7.5 10.0\n",
      "6.647059 7.5 5.0\n",
      "7.568609 7.5 10.0\n",
      "7.5426946 7.5 7.5\n",
      "8.941104 10 7.5\n",
      "6.500508 7.5 5.0\n",
      "7.668667 7.5 10.0\n",
      "7.583597 7.5 5.0\n",
      "8.444164 7.5 10.0\n",
      "7.6539226 7.5 5.0\n",
      "8.852838 10 7.5\n",
      "6.603188 7.5 7.5\n",
      "6.876526 7.5 7.5\n",
      "8.750996 10 10.0\n",
      "7.1613374 7.5 7.5\n",
      "7.11142 7.5 7.5\n",
      "6.9658685 7.5 10.0\n",
      "7.299549 7.5 10.0\n",
      "8.605099 7.5 7.5\n",
      "7.939755 7.5 7.5\n",
      "8.517868 7.5 7.5\n",
      "7.1593566 7.5 10.0\n",
      "6.0412936 5 7.5\n",
      "6.973075 7.5 7.5\n",
      "6.5312505 7.5 10.0\n",
      "9.309207 10 7.5\n",
      "9.299072 10 10.0\n",
      "5.751255 5 5.0\n",
      "5.9615045 5 5.0\n",
      "8.295078 7.5 10.0\n",
      "8.866927 10 7.5\n",
      "7.134985 7.5 7.5\n",
      "8.729123 7.5 7.5\n",
      "6.3805733 7.5 5.0\n",
      "7.4307704 7.5 2.5\n",
      "7.6332393 7.5 10.0\n",
      "8.731802 7.5 10.0\n",
      "6.043547 5 7.5\n",
      "8.777002 10 10.0\n",
      "7.8185496 7.5 10.0\n",
      "8.107146 7.5 7.5\n",
      "6.249166 5 7.5\n",
      "7.0336714 7.5 7.5\n",
      "8.262865 7.5 10.0\n",
      "7.272145 7.5 7.5\n",
      "7.7072086 7.5 7.5\n",
      "3.7535827 5 0.0\n",
      "8.681874 7.5 10.0\n",
      "6.8649592 7.5 2.5\n",
      "6.7205205 7.5 5.0\n",
      "5.160978 5 2.5\n",
      "9.01724 10 10.0\n",
      "7.6697683 7.5 10.0\n",
      "7.3892393 7.5 2.5\n",
      "8.7398 7.5 10.0\n",
      "8.93222 10 10.0\n",
      "7.3687215 7.5 7.5\n",
      "6.8376613 7.5 2.5\n",
      "7.203699 7.5 10.0\n",
      "6.5606947 7.5 5.0\n",
      "6.350559 7.5 2.5\n",
      "7.1001077 7.5 7.5\n",
      "8.672239 7.5 7.5\n",
      "8.212751 7.5 5.0\n",
      "7.2803283 7.5 7.5\n",
      "7.4151154 7.5 0.0\n",
      "5.0942025 5 5.0\n",
      "6.186628 5 5.0\n",
      "6.751465 7.5 5.0\n",
      "5.196508 5 2.5\n",
      "7.063168 7.5 7.5\n",
      "7.888785 7.5 10.0\n",
      "7.8750644 7.5 10.0\n",
      "7.4212046 7.5 5.0\n",
      "7.041174 7.5 7.5\n",
      "7.1120834 7.5 5.0\n",
      "7.048967 7.5 7.5\n",
      "7.2169 7.5 5.0\n",
      "8.517978 7.5 7.5\n",
      "7.2771215 7.5 2.5\n",
      "6.7754645 7.5 7.5\n",
      "7.521382 7.5 7.5\n",
      "9.355579 10 10.0\n",
      "7.3347387 7.5 7.5\n",
      "7.4087734 7.5 7.5\n",
      "6.7626157 7.5 10.0\n",
      "3.7648726 5 10.0\n",
      "8.51007 7.5 2.5\n",
      "7.98059 7.5 10.0\n",
      "7.1871157 7.5 10.0\n",
      "7.886685 7.5 5.0\n",
      "8.61995 7.5 7.5\n",
      "6.3969207 7.5 2.5\n",
      "9.26906 10 10.0\n",
      "6.4390635 7.5 2.5\n",
      "5.612626 5 2.5\n",
      "9.184707 10 7.5\n",
      "7.366966 7.5 10.0\n",
      "6.931749 7.5 5.0\n",
      "7.1927876 7.5 5.0\n",
      "8.423054 7.5 10.0\n",
      "7.4575047 7.5 7.5\n",
      "8.372066 7.5 10.0\n",
      "7.172108 7.5 7.5\n",
      "7.591867 7.5 2.5\n",
      "7.0086107 7.5 10.0\n",
      "8.654689 7.5 10.0\n",
      "7.601871 7.5 10.0\n",
      "7.7088895 7.5 7.5\n",
      "7.0183425 7.5 7.5\n",
      "8.605385 7.5 10.0\n",
      "8.634449 7.5 10.0\n",
      "3.3498142 2.5 7.5\n",
      "6.9685354 7.5 5.0\n",
      "7.3649716 7.5 7.5\n",
      "5.3046613 5 0.0\n",
      "7.647665 7.5 10.0\n",
      "6.63456 7.5 7.5\n",
      "9.344967 10 10.0\n",
      "6.812086 7.5 5.0\n",
      "7.3582454 7.5 10.0\n",
      "6.210463 5 2.5\n",
      "6.128749 5 10.0\n",
      "8.783801 10 10.0\n",
      "5.6959405 5 0.0\n",
      "9.169274 10 10.0\n",
      "8.075753 7.5 5.0\n",
      "7.017008 7.5 7.5\n",
      "7.362904 7.5 10.0\n",
      "9.165203 10 10.0\n",
      "6.9268236 7.5 5.0\n",
      "7.5351515 7.5 7.5\n",
      "7.181576 7.5 7.5\n",
      "7.651634 7.5 7.5\n",
      "7.6909857 7.5 5.0\n",
      "8.45688 7.5 7.5\n",
      "7.5970693 7.5 2.5\n",
      "7.509553 7.5 7.5\n",
      "8.765275 10 7.5\n",
      "6.52531 7.5 5.0\n",
      "9.021553 10 7.5\n",
      "7.379155 7.5 7.5\n",
      "8.720298 7.5 10.0\n",
      "8.234053 7.5 10.0\n",
      "8.6726675 7.5 10.0\n",
      "7.9455714 7.5 2.5\n",
      "7.494399 7.5 10.0\n",
      "4.8884907 5 0.0\n",
      "8.674735 7.5 10.0\n",
      "7.2710023 7.5 10.0\n",
      "7.250939 7.5 7.5\n",
      "8.4149475 7.5 7.5\n",
      "7.2949195 7.5 5.0\n",
      "7.0001464 7.5 7.5\n",
      "9.594848 10 10.0\n",
      "9.066174 10 10.0\n",
      "7.7019243 7.5 10.0\n",
      "8.730019 7.5 10.0\n",
      "6.0210137 5 2.5\n",
      "9.244882 10 10.0\n",
      "8.176205 7.5 10.0\n",
      "7.230062 7.5 10.0\n",
      "7.140302 7.5 10.0\n",
      "6.3330617 7.5 7.5\n",
      "8.925147 10 10.0\n",
      "7.849755 7.5 7.5\n",
      "6.778028 7.5 10.0\n",
      "9.038649 10 10.0\n",
      "8.382513 7.5 7.5\n",
      "6.8663383 7.5 7.5\n",
      "9.44787 10 7.5\n",
      "6.3165092 7.5 10.0\n",
      "7.796849 7.5 5.0\n",
      "5.3964906 5 0.0\n",
      "3.043529 2.5 0.0\n",
      "8.822692 10 7.5\n",
      "6.5541563 7.5 5.0\n",
      "5.1540256 5 5.0\n",
      "8.641922 7.5 5.0\n",
      "6.859657 7.5 5.0\n",
      "7.480814 7.5 7.5\n",
      "5.4278364 5 5.0\n",
      "8.3631 7.5 10.0\n",
      "7.4739776 7.5 5.0\n",
      "5.390557 5 2.5\n",
      "4.5011883 5 2.5\n",
      "8.504404 7.5 10.0\n",
      "5.083326 5 0.0\n",
      "7.648808 7.5 2.5\n",
      "7.499165 7.5 10.0\n",
      "7.6955414 7.5 7.5\n",
      "7.681861 7.5 10.0\n",
      "6.754502 7.5 7.5\n",
      "7.2869983 7.5 7.5\n",
      "6.365996 7.5 2.5\n",
      "5.204197 5 2.5\n",
      "5.9054847 5 2.5\n",
      "7.972956 7.5 10.0\n",
      "7.422367 7.5 7.5\n",
      "8.446764 7.5 10.0\n",
      "7.7334347 7.5 5.0\n",
      "7.28498 7.5 10.0\n",
      "7.398317 7.5 5.0\n",
      "6.4745936 7.5 7.5\n",
      "9.028527 10 10.0\n",
      "8.540679 7.5 10.0\n",
      "7.104635 7.5 10.0\n",
      "7.0410643 7.5 7.5\n",
      "6.32346 7.5 5.0\n",
      "6.629197 7.5 7.5\n",
      "8.973448 10 10.0\n",
      "8.889798 10 7.5\n",
      "6.9359818 7.5 5.0\n",
      "7.9293647 7.5 7.5\n",
      "6.583788 7.5 7.5\n",
      "7.3018885 7.5 7.5\n",
      "7.6276655 7.5 5.0\n",
      "7.5687647 7.5 10.0\n",
      "6.1155944 5 7.5\n",
      "6.715773 7.5 2.5\n",
      "5.936355 5 7.5\n",
      "7.531159 7.5 10.0\n",
      "8.485824 7.5 10.0\n",
      "4.843729 5 5.0\n",
      "8.509376 7.5 10.0\n",
      "7.9991617 7.5 10.0\n",
      "9.403778 10 7.5\n",
      "10.0034485 10 7.5\n",
      "8.21 7.5 10.0\n",
      "7.479756 7.5 10.0\n",
      "7.0194397 7.5 7.5\n",
      "8.201563 7.5 7.5\n",
      "8.001001 7.5 7.5\n",
      "6.2427216 5 5.0\n",
      "6.8377757 7.5 2.5\n",
      "8.987858 10 10.0\n",
      "9.340121 10 10.0\n",
      "7.528078 7.5 5.0\n",
      "8.86362 10 10.0\n",
      "8.0806875 7.5 0.0\n",
      "7.5769277 7.5 7.5\n",
      "7.6044216 7.5 7.5\n",
      "7.4456353 7.5 10.0\n",
      "7.4248395 7.5 10.0\n",
      "8.448914 7.5 7.5\n",
      "6.783118 7.5 10.0\n",
      "7.9123955 7.5 7.5\n",
      "7.006884 7.5 7.5\n",
      "7.7470303 7.5 10.0\n",
      "7.163418 7.5 7.5\n",
      "7.277816 7.5 7.5\n",
      "8.656313 7.5 10.0\n",
      "8.476597 7.5 7.5\n",
      "7.624916 7.5 7.5\n",
      "7.606934 7.5 5.0\n",
      "8.754588 10 10.0\n",
      "8.915235 10 10.0\n",
      "7.46821 7.5 7.5\n",
      "8.009338 7.5 10.0\n",
      "7.4551687 7.5 10.0\n",
      "8.752472 10 10.0\n",
      "7.84375 7.5 7.5\n",
      "9.731726 10 7.5\n",
      "5.265014 5 2.5\n",
      "6.9478273 7.5 7.5\n",
      "7.893033 7.5 2.5\n",
      "7.1356273 7.5 10.0\n",
      "7.3350983 7.5 7.5\n",
      "7.393844 7.5 7.5\n",
      "7.138094 7.5 7.5\n",
      "7.0465016 7.5 5.0\n",
      "8.300276 7.5 7.5\n",
      "6.698205 7.5 10.0\n",
      "6.934066 7.5 7.5\n",
      "8.498011 7.5 10.0\n",
      "8.801865 10 10.0\n",
      "8.038824 7.5 10.0\n",
      "9.275744 10 10.0\n",
      "7.6378508 7.5 7.5\n",
      "9.272494 10 10.0\n",
      "6.8717723 7.5 7.5\n",
      "7.825387 7.5 2.5\n",
      "4.575383 5 2.5\n",
      "7.338511 7.5 2.5\n",
      "8.965319 10 10.0\n",
      "6.441193 7.5 7.5\n",
      "8.146828 7.5 10.0\n",
      "6.925268 7.5 2.5\n",
      "4.107786 5 2.5\n",
      "8.620431 7.5 10.0\n",
      "7.274011 7.5 7.5\n",
      "5.253542 5 2.5\n",
      "7.1724224 7.5 5.0\n",
      "8.045315 7.5 7.5\n",
      "7.221854 7.5 7.5\n",
      "6.989506 7.5 5.0\n",
      "5.474185 5 5.0\n",
      "6.8879514 7.5 7.5\n",
      "7.6981916 7.5 7.5\n",
      "6.1464844 5 5.0\n",
      "7.589906 7.5 7.5\n",
      "7.516305 7.5 2.5\n",
      "7.3983226 7.5 7.5\n",
      "8.487232 7.5 5.0\n",
      "7.326425 7.5 7.5\n",
      "5.920574 5 5.0\n",
      "7.580915 7.5 10.0\n",
      "7.974285 7.5 10.0\n",
      "7.279925 7.5 7.5\n",
      "6.843707 7.5 10.0\n",
      "8.773031 10 10.0\n",
      "6.9563394 7.5 10.0\n",
      "8.314357 7.5 10.0\n",
      "7.712937 7.5 5.0\n",
      "7.904101 7.5 10.0\n",
      "5.777071 5 2.5\n",
      "8.881493 10 7.5\n",
      "5.931883 5 2.5\n",
      "7.4885664 7.5 5.0\n",
      "7.2951126 7.5 5.0\n",
      "6.5661273 7.5 10.0\n",
      "6.993216 7.5 2.5\n",
      "7.374301 7.5 7.5\n",
      "7.5812654 7.5 5.0\n",
      "5.222502 5 0.0\n",
      "7.185099 7.5 10.0\n",
      "7.9184823 7.5 7.5\n",
      "6.4165473 7.5 5.0\n",
      "8.590414 7.5 7.5\n",
      "9.219994 10 7.5\n",
      "9.152784 10 7.5\n",
      "7.6017833 7.5 7.5\n",
      "8.836202 10 7.5\n",
      "8.775937 10 2.5\n",
      "7.610288 7.5 10.0\n",
      "7.7863674 7.5 10.0\n",
      "6.8701906 7.5 7.5\n",
      "8.082169 7.5 10.0\n",
      "7.43944 7.5 10.0\n",
      "7.8321486 7.5 0.0\n",
      "7.291096 7.5 7.5\n",
      "8.14492 7.5 10.0\n",
      "6.605267 7.5 7.5\n",
      "6.269217 7.5 7.5\n",
      "7.838585 7.5 7.5\n",
      "8.8443775 10 10.0\n",
      "6.777845 7.5 10.0\n",
      "6.5328045 7.5 7.5\n",
      "6.5589867 7.5 7.5\n",
      "8.7802925 10 7.5\n",
      "7.536606 7.5 10.0\n",
      "7.2934513 7.5 10.0\n",
      "7.374728 7.5 7.5\n",
      "6.3944173 7.5 7.5\n",
      "5.7635794 5 2.5\n",
      "3.656596 2.5 2.5\n",
      "7.4562345 7.5 10.0\n",
      "8.499607 7.5 7.5\n",
      "7.003429 7.5 2.5\n",
      "7.5013814 7.5 5.0\n",
      "6.5105658 7.5 2.5\n",
      "6.034872 5 7.5\n",
      "9.135196 10 7.5\n",
      "6.1855226 5 5.0\n",
      "6.432571 7.5 7.5\n",
      "7.159272 7.5 5.0\n",
      "7.2345076 7.5 7.5\n",
      "8.31964 7.5 10.0\n",
      "7.425407 7.5 5.0\n",
      "8.516319 7.5 10.0\n",
      "7.8409014 7.5 10.0\n",
      "7.0929847 7.5 7.5\n",
      "7.2338347 7.5 2.5\n",
      "7.4362245 7.5 10.0\n",
      "8.501143 7.5 10.0\n",
      "5.954244 5 5.0\n",
      "8.66079 7.5 10.0\n",
      "8.956649 10 10.0\n",
      "6.1084347 5 2.5\n",
      "8.614374 7.5 7.5\n",
      "8.822612 10 7.5\n",
      "7.343077 7.5 10.0\n",
      "8.150848 7.5 10.0\n",
      "6.8793154 7.5 7.5\n",
      "9.04114 10 10.0\n",
      "4.342376 5 5.0\n",
      "9.2200985 10 10.0\n",
      "8.320372 7.5 10.0\n",
      "8.98884 10 2.5\n",
      "7.4062414 7.5 7.5\n",
      "5.727801 5 2.5\n",
      "7.2629056 7.5 7.5\n",
      "7.1584306 7.5 10.0\n",
      "7.9017653 7.5 7.5\n",
      "6.979982 7.5 2.5\n",
      "4.926012 5 10.0\n",
      "9.037029 10 10.0\n",
      "5.8635283 5 10.0\n",
      "6.578788 7.5 5.0\n",
      "7.562007 7.5 7.5\n",
      "7.268746 7.5 7.5\n",
      "7.8298683 7.5 10.0\n",
      "6.9110427 7.5 10.0\n",
      "7.2487926 7.5 7.5\n",
      "7.873275 7.5 7.5\n",
      "9.161444 10 10.0\n",
      "7.1817064 7.5 10.0\n",
      "6.5394335 7.5 10.0\n",
      "7.8899946 7.5 10.0\n",
      "7.1179533 7.5 10.0\n",
      "8.062588 7.5 7.5\n",
      "7.4147215 7.5 7.5\n",
      "6.47768 7.5 7.5\n",
      "8.538068 7.5 5.0\n",
      "9.200843 10 5.0\n",
      "7.2260056 7.5 7.5\n",
      "8.386311 7.5 7.5\n",
      "7.5643725 7.5 7.5\n",
      "7.143354 7.5 7.5\n",
      "7.4040995 7.5 7.5\n",
      "7.7747183 7.5 10.0\n",
      "6.9252405 7.5 7.5\n",
      "7.499321 7.5 7.5\n",
      "7.625387 7.5 7.5\n",
      "8.492781 7.5 7.5\n",
      "7.7727137 7.5 10.0\n",
      "9.410736 10 10.0\n",
      "8.4212265 7.5 7.5\n",
      "5.0432887 5 2.5\n",
      "7.5579004 7.5 10.0\n",
      "7.3813653 7.5 10.0\n",
      "7.366298 7.5 2.5\n",
      "8.751657 10 10.0\n",
      "6.9692817 7.5 7.5\n",
      "7.3837996 7.5 10.0\n",
      "4.7128754 5 7.5\n",
      "8.59533 7.5 10.0\n",
      "8.823772 10 10.0\n",
      "8.283888 7.5 7.5\n",
      "5.4611855 5 7.5\n",
      "9.037518 10 10.0\n",
      "7.6592607 7.5 10.0\n",
      "6.630636 7.5 2.5\n",
      "5.9215016 5 7.5\n",
      "8.906701 10 7.5\n",
      "8.294857 7.5 7.5\n",
      "7.245071 7.5 7.5\n",
      "9.327529 10 10.0\n",
      "5.752332 5 7.5\n",
      "7.198105 7.5 2.5\n",
      "7.2243733 7.5 5.0\n",
      "8.646602 7.5 10.0\n",
      "9.225362 10 7.5\n",
      "5.675704 5 7.5\n",
      "7.522191 7.5 10.0\n",
      "8.761958 10 10.0\n",
      "5.250728 5 0.0\n",
      "7.241708 7.5 7.5\n",
      "7.1478324 7.5 2.5\n",
      "7.6252623 7.5 7.5\n",
      "6.9204516 7.5 7.5\n",
      "7.2942324 7.5 7.5\n",
      "7.613877 7.5 10.0\n",
      "6.9543653 7.5 7.5\n",
      "5.7603903 5 10.0\n",
      "9.71579 10 10.0\n",
      "7.1610374 7.5 7.5\n",
      "7.948576 7.5 10.0\n",
      "6.101103 5 7.5\n",
      "7.369439 7.5 10.0\n",
      "8.806883 10 10.0\n",
      "5.090892 5 2.5\n",
      "7.281867 7.5 10.0\n",
      "7.620492 7.5 7.5\n",
      "9.132525 10 10.0\n",
      "9.047476 10 10.0\n",
      "9.00143 10 10.0\n",
      "8.344004 7.5 7.5\n",
      "7.942431 7.5 10.0\n",
      "7.137034 7.5 7.5\n",
      "6.4771767 7.5 5.0\n",
      "5.3286996 5 7.5\n",
      "8.014618 7.5 7.5\n",
      "6.5817986 7.5 5.0\n",
      "8.97556 10 7.5\n",
      "8.652091 7.5 7.5\n",
      "7.585423 7.5 2.5\n",
      "6.96262 7.5 10.0\n",
      "5.509442 5 7.5\n",
      "7.354374 7.5 2.5\n",
      "7.0831857 7.5 7.5\n",
      "7.798883 7.5 5.0\n",
      "7.3192677 7.5 5.0\n",
      "6.5994096 7.5 7.5\n",
      "7.430019 7.5 7.5\n",
      "8.623701 7.5 7.5\n",
      "7.7108502 7.5 5.0\n",
      "8.494919 7.5 2.5\n",
      "3.7998834 5 0.0\n",
      "6.1068435 5 0.0\n",
      "6.4543977 7.5 5.0\n",
      "7.688884 7.5 10.0\n",
      "9.428779 10 10.0\n",
      "6.88592 7.5 7.5\n",
      "7.1319466 7.5 7.5\n",
      "8.133987 7.5 10.0\n",
      "7.638917 7.5 7.5\n",
      "8.382343 7.5 10.0\n",
      "6.763493 7.5 2.5\n",
      "6.5229025 7.5 5.0\n",
      "8.629407 7.5 7.5\n",
      "6.7921944 7.5 10.0\n",
      "6.1916733 5 10.0\n",
      "8.179028 7.5 10.0\n",
      "7.3136697 7.5 5.0\n",
      "7.456883 7.5 2.5\n",
      "7.1727877 7.5 2.5\n",
      "8.083348 7.5 10.0\n",
      "7.8969812 7.5 10.0\n",
      "6.4721923 7.5 7.5\n",
      "7.4286 7.5 7.5\n",
      "8.005686 7.5 7.5\n",
      "9.131033 10 10.0\n",
      "9.200788 10 7.5\n",
      "9.776914 10 10.0\n",
      "7.308954 7.5 7.5\n",
      "7.3787804 7.5 7.5\n",
      "7.10879 7.5 5.0\n",
      "7.5007076 7.5 7.5\n",
      "4.7373276 5 2.5\n",
      "7.698946 7.5 7.5\n",
      "7.825532 7.5 2.5\n",
      "5.112576 5 10.0\n",
      "8.71077 7.5 7.5\n",
      "8.783698 10 7.5\n",
      "8.000311 7.5 10.0\n",
      "5.8526053 5 5.0\n",
      "7.151727 7.5 10.0\n",
      "8.853235 10 10.0\n",
      "6.983809 7.5 7.5\n",
      "7.014088 7.5 10.0\n",
      "7.175038 7.5 2.5\n",
      "9.147533 10 10.0\n",
      "7.1667047 7.5 10.0\n",
      "6.9234366 7.5 7.5\n",
      "8.093098 7.5 10.0\n",
      "8.676489 7.5 7.5\n",
      "7.061639 7.5 10.0\n",
      "7.740413 7.5 5.0\n",
      "8.39974 7.5 10.0\n",
      "9.170129 10 10.0\n",
      "7.397921 7.5 7.5\n",
      "4.475643 5 5.0\n",
      "6.3607326 7.5 7.5\n",
      "8.690546 7.5 7.5\n",
      "6.9081674 7.5 7.5\n",
      "7.314212 7.5 7.5\n",
      "8.531172 7.5 10.0\n",
      "6.959191 7.5 7.5\n",
      "7.404154 7.5 10.0\n",
      "7.47721 7.5 2.5\n",
      "8.420097 7.5 7.5\n",
      "4.8955836 5 2.5\n",
      "6.703501 7.5 10.0\n",
      "6.7747555 7.5 7.5\n",
      "9.1996355 10 7.5\n",
      "7.032372 7.5 5.0\n",
      "7.9516516 7.5 10.0\n",
      "5.8556833 5 7.5\n",
      "7.3941374 7.5 5.0\n",
      "7.621516 7.5 10.0\n",
      "7.4530396 7.5 7.5\n",
      "5.3358355 5 0.0\n",
      "8.779274 10 7.5\n",
      "7.5688725 7.5 10.0\n",
      "7.018472 7.5 2.5\n",
      "6.9987335 7.5 2.5\n",
      "8.985204 10 10.0\n",
      "8.956691 10 7.5\n",
      "8.448505 7.5 10.0\n",
      "6.7558117 7.5 7.5\n",
      "8.861679 10 7.5\n",
      "8.519202 7.5 7.5\n",
      "6.765058 7.5 7.5\n",
      "7.3710456 7.5 5.0\n",
      "7.425432 7.5 7.5\n",
      "6.4374146 7.5 7.5\n",
      "5.760561 5 5.0\n",
      "6.873416 7.5 7.5\n",
      "8.750112 10 7.5\n",
      "8.54989 7.5 5.0\n",
      "7.544607 7.5 7.5\n",
      "6.992478 7.5 7.5\n",
      "7.0540113 7.5 7.5\n",
      "5.8190494 5 7.5\n",
      "7.925432 7.5 7.5\n",
      "6.305715 7.5 7.5\n",
      "8.526509 7.5 7.5\n",
      "8.55321 7.5 10.0\n",
      "6.286523 7.5 5.0\n",
      "7.367794 7.5 10.0\n",
      "6.9315166 7.5 7.5\n",
      "7.518938 7.5 7.5\n",
      "7.978758 7.5 10.0\n",
      "8.811152 10 10.0\n",
      "6.778396 7.5 7.5\n",
      "7.2507076 7.5 10.0\n",
      "8.848014 10 7.5\n",
      "7.60558 7.5 10.0\n",
      "7.777097 7.5 10.0\n",
      "9.21131 10 10.0\n",
      "7.2263703 7.5 10.0\n",
      "8.717333 7.5 7.5\n",
      "7.3780704 7.5 10.0\n",
      "8.837742 10 10.0\n",
      "6.80549 7.5 7.5\n",
      "7.434809 7.5 10.0\n",
      "5.8019896 5 10.0\n",
      "6.4198833 7.5 10.0\n",
      "6.955144 7.5 7.5\n",
      "8.399872 7.5 10.0\n",
      "7.218571 7.5 7.5\n",
      "8.315033 7.5 10.0\n",
      "7.4616976 7.5 10.0\n",
      "4.5755734 5 10.0\n",
      "8.884412 10 10.0\n",
      "7.234712 7.5 7.5\n",
      "7.2955546 7.5 7.5\n",
      "8.162269 7.5 5.0\n",
      "9.323351 10 7.5\n",
      "7.0851483 7.5 10.0\n",
      "6.8806133 7.5 7.5\n",
      "8.919209 10 10.0\n",
      "5.625055 5 0.0\n",
      "7.1418505 7.5 5.0\n",
      "6.501433 7.5 5.0\n",
      "7.3581285 7.5 7.5\n",
      "3.4804149 2.5 7.5\n",
      "6.616448 7.5 7.5\n",
      "6.812366 7.5 2.5\n",
      "5.7436852 5 7.5\n",
      "6.0842075 5 10.0\n",
      "6.2508607 7.5 2.5\n",
      "6.577914 7.5 10.0\n",
      "6.0183907 5 7.5\n",
      "8.457194 7.5 10.0\n",
      "6.610118 7.5 7.5\n",
      "8.618353 7.5 7.5\n",
      "7.341528 7.5 7.5\n",
      "6.82995 7.5 2.5\n",
      "9.439663 10 7.5\n",
      "7.582166 7.5 7.5\n",
      "6.4994745 7.5 10.0\n",
      "8.816916 10 10.0\n",
      "6.426784 7.5 7.5\n",
      "8.822032 10 7.5\n",
      "9.04423 10 7.5\n",
      "7.193652 7.5 7.5\n",
      "7.0033092 7.5 7.5\n",
      "9.108665 10 7.5\n",
      "8.007248 7.5 7.5\n",
      "8.341686 7.5 5.0\n",
      "7.6064563 7.5 7.5\n",
      "8.777297 10 7.5\n",
      "5.358725 5 10.0\n",
      "7.081816 7.5 2.5\n",
      "8.840815 10 10.0\n",
      "6.553141 7.5 7.5\n",
      "9.199583 10 10.0\n",
      "6.9609137 7.5 5.0\n",
      "7.5133815 7.5 7.5\n",
      "7.9938064 7.5 7.5\n",
      "7.693212 7.5 7.5\n",
      "7.58549 7.5 10.0\n",
      "9.619962 10 10.0\n",
      "8.799793 10 7.5\n",
      "7.9237533 7.5 10.0\n",
      "7.232435 7.5 7.5\n",
      "7.4100175 7.5 7.5\n",
      "8.078245 7.5 10.0\n",
      "5.281729 5 2.5\n",
      "8.677006 7.5 10.0\n",
      "7.1018357 7.5 5.0\n",
      "7.7431417 7.5 10.0\n",
      "7.064949 7.5 7.5\n",
      "6.4300313 7.5 7.5\n",
      "6.71622 7.5 7.5\n",
      "8.365703 7.5 10.0\n",
      "6.878198 7.5 7.5\n",
      "8.667368 7.5 10.0\n",
      "6.7442026 7.5 10.0\n",
      "6.9970465 7.5 7.5\n",
      "8.372765 7.5 10.0\n",
      "4.530624 5 2.5\n",
      "8.345398 7.5 7.5\n",
      "7.529927 7.5 10.0\n",
      "8.711141 7.5 0.0\n",
      "7.4070063 7.5 7.5\n",
      "6.7539377 7.5 7.5\n",
      "5.2200203 5 10.0\n",
      "6.1169014 5 7.5\n",
      "5.8806005 5 7.5\n",
      "9.10668 10 10.0\n",
      "9.83744 10 10.0\n",
      "5.6551857 5 2.5\n",
      "7.6088357 7.5 7.5\n",
      "8.358023 7.5 10.0\n",
      "9.011386 10 7.5\n",
      "8.831547 10 10.0\n",
      "7.501549 7.5 2.5\n",
      "6.558412 7.5 7.5\n",
      "9.609767 10 10.0\n",
      "7.427763 7.5 5.0\n",
      "7.8593307 7.5 10.0\n",
      "7.0350695 7.5 7.5\n",
      "6.939128 7.5 5.0\n",
      "7.238811 7.5 5.0\n",
      "7.340443 7.5 7.5\n",
      "7.207247 7.5 5.0\n",
      "9.123986 10 10.0\n",
      "7.595094 7.5 10.0\n",
      "8.903678 10 10.0\n",
      "7.015466 7.5 10.0\n",
      "8.799338 10 7.5\n",
      "9.80547 10 10.0\n",
      "7.1931653 7.5 10.0\n",
      "7.725206 7.5 10.0\n",
      "5.7076716 5 2.5\n",
      "7.8089876 7.5 10.0\n",
      "6.572604 7.5 7.5\n",
      "9.096749 10 10.0\n",
      "8.461212 7.5 10.0\n",
      "6.7182612 7.5 5.0\n",
      "8.312922 7.5 10.0\n",
      "8.733397 7.5 10.0\n",
      "8.481956 7.5 7.5\n",
      "7.9126725 7.5 10.0\n",
      "7.2704425 7.5 7.5\n",
      "8.283058 7.5 10.0\n",
      "8.724705 7.5 10.0\n",
      "5.45062 5 10.0\n",
      "7.4588437 7.5 7.5\n",
      "7.45834 7.5 10.0\n",
      "7.625082 7.5 5.0\n",
      "6.970528 7.5 7.5\n",
      "9.328814 10 10.0\n",
      "6.7867274 7.5 10.0\n",
      "7.290138 7.5 7.5\n",
      "8.969852 10 10.0\n",
      "7.8374104 7.5 7.5\n",
      "9.061124 10 10.0\n",
      "9.368023 10 10.0\n",
      "6.8151965 7.5 10.0\n",
      "7.1556435 7.5 7.5\n",
      "8.437529 7.5 7.5\n",
      "9.119984 10 10.0\n",
      "7.483712 7.5 10.0\n",
      "8.429295 7.5 10.0\n",
      "7.816572 7.5 7.5\n",
      "7.2241826 7.5 10.0\n",
      "7.221929 7.5 7.5\n",
      "7.3898544 7.5 5.0\n",
      "6.9354825 7.5 10.0\n",
      "7.704663 7.5 7.5\n",
      "8.569557 7.5 7.5\n",
      "7.8051343 7.5 10.0\n",
      "7.0423717 7.5 10.0\n",
      "8.97731 10 10.0\n",
      "9.129261 10 10.0\n",
      "8.682636 7.5 10.0\n",
      "9.5561695 10 10.0\n",
      "4.263068 5 0.0\n",
      "8.865366 10 5.0\n",
      "8.779697 10 7.5\n",
      "8.364222 7.5 7.5\n",
      "9.300999 10 10.0\n",
      "7.1051903 7.5 7.5\n",
      "6.7797184 7.5 2.5\n",
      "7.2157984 7.5 7.5\n",
      "8.886085 10 10.0\n",
      "7.835509 7.5 10.0\n",
      "9.084024 10 7.5\n",
      "8.840619 10 10.0\n",
      "8.607864 7.5 10.0\n",
      "8.027666 7.5 10.0\n",
      "7.9053755 7.5 10.0\n",
      "7.7568417 7.5 7.5\n",
      "8.794814 10 2.5\n",
      "5.0802674 5 2.5\n",
      "8.773797 10 7.5\n",
      "7.408327 7.5 10.0\n",
      "7.4752946 7.5 10.0\n",
      "4.1165023 5 0.0\n",
      "7.5339355 7.5 5.0\n",
      "6.3888245 7.5 7.5\n",
      "7.261553 7.5 10.0\n",
      "5.570896 5 2.5\n",
      "9.537508 10 10.0\n",
      "6.592579 7.5 10.0\n",
      "9.057636 10 7.5\n",
      "7.2703137 7.5 2.5\n",
      "5.2237864 5 7.5\n",
      "9.103315 10 10.0\n",
      "9.073639 10 7.5\n",
      "6.7119155 7.5 7.5\n",
      "7.375075 7.5 7.5\n",
      "6.2597117 7.5 2.5\n",
      "8.877202 10 10.0\n",
      "8.159154 7.5 5.0\n",
      "8.534937 7.5 10.0\n",
      "8.479141 7.5 10.0\n",
      "7.466757 7.5 10.0\n",
      "5.8907995 5 10.0\n",
      "6.0842605 5 2.5\n",
      "5.4495397 5 10.0\n",
      "5.672735 5 2.5\n",
      "7.7406306 7.5 10.0\n",
      "8.523182 7.5 10.0\n",
      "7.125222 7.5 10.0\n",
      "9.088972 10 10.0\n",
      "7.580391 7.5 10.0\n",
      "7.2912707 7.5 10.0\n",
      "7.327047 7.5 7.5\n",
      "9.027111 10 10.0\n",
      "6.8746433 7.5 2.5\n",
      "9.664983 10 10.0\n",
      "6.456794 7.5 2.5\n",
      "8.589406 7.5 10.0\n",
      "9.311261 10 10.0\n",
      "8.261053 7.5 10.0\n",
      "7.203201 7.5 7.5\n",
      "7.8879795 7.5 7.5\n",
      "9.073093 10 10.0\n",
      "7.485351 7.5 7.5\n",
      "7.0763807 7.5 2.5\n",
      "6.746741 7.5 10.0\n",
      "5.4014726 5 5.0\n",
      "9.16915 10 10.0\n",
      "7.5489464 7.5 10.0\n",
      "7.518304 7.5 7.5\n",
      "8.876097 10 5.0\n",
      "7.2474256 7.5 7.5\n",
      "8.831597 10 10.0\n",
      "7.466924 7.5 7.5\n",
      "8.799064 10 10.0\n",
      "6.8644986 7.5 10.0\n",
      "6.4735856 7.5 7.5\n",
      "5.430522 5 2.5\n",
      "5.619048 5 7.5\n",
      "6.902569 7.5 7.5\n",
      "7.1490607 7.5 7.5\n",
      "7.8805895 7.5 10.0\n",
      "9.305983 10 10.0\n",
      "8.447409 7.5 7.5\n",
      "8.568017 7.5 7.5\n",
      "6.962968 7.5 7.5\n",
      "9.044534 10 10.0\n",
      "8.634638 7.5 5.0\n",
      "6.2213807 5 7.5\n",
      "8.515125 7.5 7.5\n",
      "7.9398694 7.5 7.5\n",
      "8.781555 10 10.0\n",
      "7.0721946 7.5 5.0\n",
      "6.844661 7.5 7.5\n",
      "6.876979 7.5 7.5\n",
      "6.9269657 7.5 10.0\n",
      "7.2601304 7.5 5.0\n",
      "7.885566 7.5 7.5\n",
      "7.9265537 7.5 5.0\n",
      "7.437221 7.5 7.5\n",
      "8.811155 10 7.5\n",
      "8.558069 7.5 7.5\n",
      "7.911621 7.5 5.0\n",
      "6.879501 7.5 7.5\n",
      "9.173004 10 10.0\n",
      "7.1493964 7.5 7.5\n",
      "6.5831676 7.5 5.0\n",
      "6.375969 7.5 10.0\n",
      "4.497078 5 10.0\n",
      "7.8846903 7.5 5.0\n",
      "7.263644 7.5 7.5\n",
      "8.81542 10 10.0\n",
      "7.306118 7.5 10.0\n",
      "6.6863756 7.5 10.0\n",
      "5.8281255 5 0.0\n",
      "6.87001 7.5 7.5\n",
      "8.560222 7.5 5.0\n",
      "7.347532 7.5 2.5\n",
      "5.394078 5 2.5\n",
      "7.275878 7.5 7.5\n",
      "8.898712 10 10.0\n",
      "7.2550836 7.5 10.0\n",
      "8.904577 10 7.5\n",
      "4.0245585 5 0.0\n",
      "7.2528696 7.5 10.0\n",
      "7.7091513 7.5 2.5\n",
      "7.3640265 7.5 5.0\n",
      "7.106886 7.5 7.5\n",
      "7.56186 7.5 7.5\n",
      "7.6090803 7.5 5.0\n",
      "7.1107397 7.5 7.5\n",
      "6.525983 7.5 10.0\n",
      "6.9776464 7.5 7.5\n",
      "8.471979 7.5 10.0\n",
      "8.762306 10 10.0\n",
      "7.5732536 7.5 10.0\n",
      "6.853691 7.5 10.0\n",
      "8.944574 10 10.0\n",
      "3.8103564 5 0.0\n",
      "7.7247667 7.5 10.0\n",
      "8.806738 10 7.5\n",
      "7.6130667 7.5 10.0\n",
      "7.1254444 7.5 5.0\n",
      "7.663777 7.5 10.0\n",
      "7.0437512 7.5 7.5\n",
      "8.158699 7.5 10.0\n",
      "7.593561 7.5 7.5\n",
      "6.5909743 7.5 7.5\n",
      "6.465161 7.5 10.0\n",
      "5.2460513 5 2.5\n",
      "7.254616 7.5 7.5\n",
      "8.829225 10 10.0\n",
      "7.3770657 7.5 5.0\n",
      "8.297775 7.5 10.0\n",
      "8.31026 7.5 10.0\n",
      "7.1343074 7.5 10.0\n",
      "8.350252 7.5 7.5\n",
      "7.8289466 7.5 10.0\n",
      "8.011559 7.5 10.0\n",
      "8.526553 7.5 10.0\n",
      "5.3406863 5 7.5\n",
      "6.9610796 7.5 10.0\n",
      "8.2193365 7.5 5.0\n",
      "7.4333043 7.5 7.5\n",
      "6.4549375 7.5 7.5\n",
      "6.9679084 7.5 10.0\n",
      "7.695641 7.5 7.5\n",
      "8.809087 10 10.0\n",
      "7.0992556 7.5 7.5\n",
      "7.294381 7.5 7.5\n",
      "4.769452 5 2.5\n",
      "6.862419 7.5 10.0\n",
      "7.262173 7.5 7.5\n",
      "6.6244183 7.5 7.5\n",
      "7.735661 7.5 10.0\n",
      "7.605994 7.5 7.5\n",
      "7.215745 7.5 10.0\n",
      "4.4958534 5 7.5\n",
      "8.518737 7.5 10.0\n",
      "8.913185 10 7.5\n",
      "7.4162307 7.5 5.0\n",
      "6.533009 7.5 10.0\n",
      "9.361176 10 10.0\n",
      "7.679318 7.5 7.5\n",
      "4.874597 5 2.5\n",
      "6.890183 7.5 7.5\n",
      "7.466236 7.5 10.0\n",
      "8.607478 7.5 7.5\n",
      "7.288839 7.5 5.0\n",
      "8.019413 7.5 10.0\n",
      "6.972181 7.5 10.0\n",
      "7.856065 7.5 7.5\n",
      "4.925813 5 2.5\n",
      "8.89687 10 5.0\n",
      "7.697325 7.5 2.5\n",
      "6.339926 7.5 2.5\n",
      "7.458403 7.5 10.0\n",
      "8.886133 10 7.5\n",
      "8.156813 7.5 5.0\n",
      "4.2491355 5 10.0\n",
      "7.208546 7.5 7.5\n",
      "7.7774754 7.5 10.0\n",
      "8.901677 10 10.0\n",
      "7.411892 7.5 7.5\n",
      "7.6627693 7.5 10.0\n",
      "8.291287 7.5 7.5\n",
      "6.8754053 7.5 5.0\n",
      "7.116129 7.5 7.5\n",
      "8.923519 10 10.0\n",
      "8.903907 10 7.5\n",
      "8.551395 7.5 7.5\n",
      "6.917765 7.5 5.0\n",
      "7.658475 7.5 7.5\n",
      "6.823564 7.5 2.5\n",
      "7.212105 7.5 7.5\n",
      "8.078587 7.5 7.5\n",
      "7.2818537 7.5 2.5\n",
      "7.639511 7.5 10.0\n",
      "8.001198 7.5 10.0\n",
      "7.5388484 7.5 7.5\n",
      "8.592069 7.5 10.0\n",
      "7.282885 7.5 7.5\n",
      "6.8850355 7.5 0.0\n",
      "7.5585303 7.5 10.0\n",
      "7.4688296 7.5 7.5\n",
      "7.4883375 7.5 5.0\n",
      "6.7446547 7.5 7.5\n",
      "9.0044985 10 10.0\n",
      "8.517876 7.5 5.0\n",
      "6.8810687 7.5 2.5\n",
      "5.8312182 5 7.5\n",
      "7.5735903 7.5 10.0\n",
      "7.2877374 7.5 10.0\n",
      "8.843364 10 7.5\n",
      "6.737352 7.5 2.5\n",
      "8.75648 10 7.5\n",
      "9.401746 10 10.0\n",
      "6.4341464 7.5 2.5\n",
      "7.333438 7.5 10.0\n",
      "6.200543 5 7.5\n",
      "7.45658 7.5 7.5\n",
      "7.1498437 7.5 7.5\n",
      "8.480831 7.5 10.0\n",
      "3.9833703 5 2.5\n",
      "9.242586 10 10.0\n",
      "7.17867 7.5 10.0\n",
      "6.9658265 7.5 2.5\n",
      "8.323627 7.5 7.5\n",
      "5.8919883 5 7.5\n",
      "7.4632034 7.5 7.5\n",
      "9.369827 10 10.0\n",
      "6.642099 7.5 7.5\n",
      "7.463152 7.5 7.5\n",
      "8.962686 10 10.0\n",
      "7.239458 7.5 7.5\n",
      "8.264124 7.5 0.0\n",
      "8.264651 7.5 10.0\n",
      "9.138285 10 7.5\n",
      "7.316722 7.5 7.5\n",
      "8.802455 10 7.5\n",
      "8.807313 10 10.0\n",
      "8.62666 7.5 10.0\n",
      "7.138647 7.5 5.0\n",
      "6.3900623 7.5 5.0\n",
      "6.9531364 7.5 7.5\n",
      "7.8080053 7.5 2.5\n",
      "8.557921 7.5 7.5\n",
      "9.209425 10 10.0\n",
      "6.783761 7.5 7.5\n",
      "9.444244 10 10.0\n",
      "9.079541 10 7.5\n",
      "7.1074314 7.5 7.5\n",
      "6.1951776 5 7.5\n",
      "8.623536 7.5 7.5\n",
      "7.2252765 7.5 7.5\n",
      "7.331638 7.5 5.0\n",
      "8.6508465 7.5 10.0\n",
      "7.3306384 7.5 7.5\n",
      "7.466047 7.5 7.5\n",
      "7.7273064 7.5 10.0\n",
      "7.6848145 7.5 7.5\n",
      "7.0623646 7.5 7.5\n",
      "6.8659177 7.5 2.5\n",
      "7.2153535 7.5 2.5\n",
      "7.247919 7.5 10.0\n",
      "7.2381372 7.5 2.5\n",
      "7.190825 7.5 7.5\n",
      "10.200215 10 10.0\n",
      "6.5469565 7.5 10.0\n",
      "7.7336664 7.5 7.5\n",
      "7.7640033 7.5 0.0\n",
      "8.036396 7.5 7.5\n",
      "8.526958 7.5 10.0\n",
      "8.39823 7.5 10.0\n",
      "7.905642 7.5 10.0\n",
      "7.771483 7.5 10.0\n",
      "7.483006 7.5 7.5\n",
      "7.0927114 7.5 5.0\n",
      "7.905081 7.5 7.5\n",
      "6.9597306 7.5 10.0\n",
      "4.8576875 5 2.5\n",
      "8.352243 7.5 7.5\n",
      "6.9372787 7.5 5.0\n",
      "8.763585 10 10.0\n",
      "6.5971627 7.5 7.5\n",
      "7.6886377 7.5 7.5\n",
      "7.7117505 7.5 10.0\n",
      "3.6574373 2.5 2.5\n",
      "7.7333417 7.5 10.0\n",
      "6.842124 7.5 7.5\n",
      "9.386593 10 7.5\n",
      "9.340504 10 10.0\n",
      "6.433352 7.5 10.0\n",
      "8.676256 7.5 10.0\n",
      "5.1865845 5 2.5\n",
      "6.8302584 7.5 7.5\n",
      "9.088181 10 10.0\n",
      "7.1308208 7.5 7.5\n",
      "8.301636 7.5 2.5\n",
      "6.832227 7.5 7.5\n",
      "7.071866 7.5 10.0\n",
      "7.1162558 7.5 7.5\n",
      "7.3441596 7.5 7.5\n",
      "7.6289315 7.5 10.0\n",
      "8.030636 7.5 7.5\n",
      "8.812709 10 10.0\n",
      "7.601276 7.5 7.5\n",
      "7.531294 7.5 7.5\n",
      "8.5161 7.5 10.0\n",
      "7.8374043 7.5 5.0\n",
      "8.760788 10 7.5\n",
      "8.213942 7.5 10.0\n",
      "8.396549 7.5 10.0\n",
      "7.1626964 7.5 10.0\n",
      "9.1387615 10 10.0\n",
      "6.1683393 5 7.5\n",
      "8.980715 10 7.5\n",
      "7.755455 7.5 7.5\n",
      "8.587836 7.5 7.5\n",
      "7.688729 7.5 7.5\n",
      "8.571337 7.5 10.0\n",
      "7.275127 7.5 5.0\n",
      "6.9928136 7.5 7.5\n",
      "7.8500066 7.5 10.0\n",
      "8.157331 7.5 7.5\n",
      "8.90799 10 10.0\n",
      "7.009151 7.5 5.0\n",
      "6.3796782 7.5 2.5\n",
      "7.971824 7.5 7.5\n",
      "7.4151106 7.5 10.0\n",
      "6.0447593 5 7.5\n",
      "7.499411 7.5 7.5\n",
      "9.268566 10 7.5\n",
      "9.811992 10 10.0\n",
      "6.811767 7.5 7.5\n",
      "8.686019 7.5 7.5\n",
      "7.7176733 7.5 7.5\n",
      "8.8081455 10 10.0\n",
      "7.136611 7.5 5.0\n",
      "3.5212393 2.5 2.5\n",
      "7.2362223 7.5 7.5\n",
      "7.2695537 7.5 7.5\n",
      "7.3856254 7.5 7.5\n",
      "7.735018 7.5 10.0\n",
      "5.92856 5 0.0\n",
      "6.5153613 7.5 10.0\n",
      "7.7499266 7.5 10.0\n",
      "9.031276 10 10.0\n",
      "5.66629 5 10.0\n",
      "9.140575 10 5.0\n",
      "9.284374 10 10.0\n",
      "9.2049885 10 10.0\n",
      "8.137038 7.5 7.5\n",
      "5.0320044 5 2.5\n",
      "8.861934 10 2.5\n",
      "8.73337 7.5 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.795179 5 2.5\n",
      "8.171051 7.5 5.0\n",
      "5.4485793 5 2.5\n",
      "6.559353 7.5 10.0\n",
      "8.21508 7.5 5.0\n",
      "8.887403 10 10.0\n",
      "6.473309 7.5 5.0\n",
      "9.495146 10 10.0\n",
      "6.067431 5 7.5\n",
      "6.878742 7.5 7.5\n",
      "7.1737523 7.5 5.0\n",
      "7.470629 7.5 7.5\n",
      "7.115641 7.5 0.0\n",
      "5.6777554 5 5.0\n",
      "5.8339877 5 2.5\n",
      "7.111055 7.5 7.5\n",
      "6.7236257 7.5 10.0\n",
      "7.230857 7.5 2.5\n",
      "6.8952537 7.5 5.0\n",
      "7.876106 7.5 10.0\n",
      "9.333084 10 7.5\n",
      "6.7052875 7.5 10.0\n",
      "8.9069605 10 7.5\n",
      "9.08294 10 10.0\n",
      "8.777982 10 10.0\n",
      "8.99087 10 10.0\n",
      "7.303084 7.5 10.0\n",
      "7.020656 7.5 7.5\n",
      "5.3853273 5 5.0\n",
      "8.794083 10 10.0\n",
      "8.935527 10 10.0\n",
      "7.2178936 7.5 7.5\n",
      "8.520957 7.5 5.0\n",
      "7.0320234 7.5 2.5\n",
      "8.815841 10 7.5\n",
      "9.146775 10 10.0\n",
      "9.14814 10 10.0\n",
      "6.1299076 5 0.0\n",
      "8.279397 7.5 7.5\n",
      "8.929781 10 10.0\n",
      "7.00511 7.5 10.0\n",
      "7.3344545 7.5 10.0\n",
      "7.4628363 7.5 10.0\n",
      "6.5345902 7.5 5.0\n",
      "7.4571605 7.5 7.5\n",
      "5.4562893 5 7.5\n",
      "8.557975 7.5 7.5\n",
      "7.588536 7.5 7.5\n",
      "8.936083 10 10.0\n",
      "7.102791 7.5 5.0\n",
      "8.20962 7.5 10.0\n",
      "7.629561 7.5 10.0\n",
      "6.944566 7.5 5.0\n",
      "7.9404235 7.5 7.5\n",
      "6.6885858 7.5 7.5\n",
      "7.023529 7.5 7.5\n",
      "5.356553 5 2.5\n",
      "9.079288 10 10.0\n",
      "7.165941 7.5 7.5\n",
      "9.04088 10 10.0\n",
      "9.113746 10 10.0\n",
      "9.0373535 10 10.0\n",
      "9.040439 10 10.0\n",
      "7.365515 7.5 10.0\n",
      "7.936763 7.5 7.5\n",
      "5.763829 5 10.0\n",
      "5.2984686 5 2.5\n",
      "6.552891 7.5 2.5\n",
      "7.4260426 7.5 10.0\n",
      "9.222185 10 10.0\n",
      "9.180019 10 10.0\n",
      "6.540282 7.5 5.0\n",
      "7.7624674 7.5 7.5\n",
      "8.782645 10 10.0\n",
      "6.4901967 7.5 5.0\n",
      "6.573381 7.5 7.5\n",
      "6.1251035 5 7.5\n",
      "6.5539117 7.5 5.0\n",
      "7.323544 7.5 7.5\n",
      "7.247866 7.5 10.0\n",
      "9.540761 10 10.0\n",
      "7.534303 7.5 10.0\n",
      "8.647705 7.5 7.5\n",
      "8.689438 7.5 7.5\n",
      "8.94824 10 10.0\n",
      "8.095862 7.5 7.5\n",
      "8.199267 7.5 10.0\n",
      "7.4479475 7.5 7.5\n",
      "7.380012 7.5 7.5\n",
      "8.578756 7.5 7.5\n",
      "5.8299794 5 7.5\n",
      "7.6269054 7.5 7.5\n",
      "4.930387 5 7.5\n",
      "7.394697 7.5 7.5\n",
      "8.052896 7.5 10.0\n",
      "8.554947 7.5 7.5\n",
      "6.8885937 7.5 2.5\n",
      "6.013335 5 0.0\n",
      "8.628763 7.5 10.0\n",
      "7.947933 7.5 2.5\n",
      "7.540949 7.5 10.0\n",
      "8.549387 7.5 10.0\n",
      "7.0716825 7.5 7.5\n",
      "6.194329 5 7.5\n",
      "8.15847 7.5 10.0\n",
      "8.958982 10 10.0\n",
      "6.314321 7.5 10.0\n",
      "8.024106 7.5 7.5\n",
      "5.053256 5 7.5\n",
      "7.574957 7.5 10.0\n",
      "6.4917235 7.5 7.5\n",
      "5.65777 5 2.5\n",
      "8.955595 10 10.0\n",
      "8.564895 7.5 7.5\n",
      "7.3967366 7.5 10.0\n",
      "8.607742 7.5 10.0\n",
      "7.449849 7.5 10.0\n",
      "5.07259 5 7.5\n",
      "8.876394 10 10.0\n",
      "7.397967 7.5 5.0\n",
      "8.744714 7.5 10.0\n",
      "7.060741 7.5 7.5\n",
      "7.575723 7.5 7.5\n",
      "7.545907 7.5 7.5\n",
      "7.2055926 7.5 7.5\n",
      "6.738225 7.5 2.5\n",
      "8.813459 10 7.5\n",
      "8.636903 7.5 10.0\n",
      "8.286764 7.5 10.0\n",
      "8.45381 7.5 7.5\n",
      "6.513028 7.5 7.5\n",
      "6.888366 7.5 5.0\n",
      "6.7437277 7.5 2.5\n",
      "6.4264693 7.5 10.0\n",
      "7.00082 7.5 7.5\n",
      "9.14108 10 10.0\n",
      "6.7400637 7.5 7.5\n",
      "7.07835 7.5 10.0\n",
      "7.025781 7.5 5.0\n",
      "6.122841 5 10.0\n",
      "9.032209 10 10.0\n",
      "8.63817 7.5 10.0\n",
      "7.751196 7.5 7.5\n",
      "8.132216 7.5 10.0\n",
      "8.345111 7.5 10.0\n",
      "7.2409096 7.5 10.0\n",
      "7.7641215 7.5 5.0\n",
      "8.930135 10 10.0\n",
      "6.8128047 7.5 7.5\n",
      "7.1406965 7.5 5.0\n",
      "9.445401 10 10.0\n",
      "6.9769707 7.5 10.0\n",
      "9.237422 10 10.0\n",
      "9.022806 10 10.0\n",
      "7.376457 7.5 10.0\n",
      "8.7632065 10 7.5\n",
      "7.676879 7.5 10.0\n",
      "7.5422735 7.5 10.0\n",
      "6.6136656 7.5 7.5\n",
      "6.820296 7.5 7.5\n",
      "8.773305 10 10.0\n",
      "7.4537106 7.5 2.5\n",
      "9.2694235 10 10.0\n",
      "7.744934 7.5 7.5\n",
      "7.586595 7.5 7.5\n",
      "6.404155 7.5 7.5\n",
      "7.824445 7.5 5.0\n",
      "7.232497 7.5 7.5\n",
      "7.2573013 7.5 0.0\n",
      "7.260645 7.5 2.5\n",
      "7.3987403 7.5 7.5\n",
      "7.8917127 7.5 2.5\n",
      "8.92565 10 10.0\n",
      "9.225636 10 5.0\n",
      "8.712306 7.5 10.0\n",
      "8.084717 7.5 7.5\n",
      "5.4848557 5 2.5\n",
      "6.5518064 7.5 2.5\n",
      "8.447678 7.5 7.5\n",
      "6.9655123 7.5 10.0\n",
      "7.4844613 7.5 5.0\n",
      "8.421961 7.5 10.0\n",
      "8.54448 7.5 7.5\n",
      "7.166653 7.5 7.5\n",
      "6.6840625 7.5 10.0\n",
      "7.5627832 7.5 10.0\n",
      "4.9222913 5 2.5\n",
      "8.803404 10 10.0\n",
      "3.5585673 2.5 5.0\n",
      "8.090763 7.5 10.0\n",
      "7.197181 7.5 7.5\n",
      "7.9986105 7.5 10.0\n",
      "7.605664 7.5 10.0\n",
      "5.9690204 5 10.0\n",
      "8.735226 7.5 7.5\n",
      "6.712805 7.5 7.5\n",
      "7.831993 7.5 10.0\n",
      "9.282228 10 10.0\n",
      "8.583235 7.5 7.5\n",
      "7.603235 7.5 7.5\n",
      "8.822308 10 7.5\n",
      "7.950333 7.5 5.0\n",
      "7.733588 7.5 7.5\n",
      "7.612208 7.5 7.5\n",
      "8.970288 10 7.5\n",
      "7.5020623 7.5 10.0\n",
      "7.3014565 7.5 2.5\n",
      "7.3953776 7.5 10.0\n",
      "6.0299373 5 2.5\n",
      "8.762857 10 7.5\n",
      "6.8085504 7.5 10.0\n",
      "8.402221 7.5 7.5\n",
      "6.962987 7.5 7.5\n",
      "7.5777607 7.5 7.5\n",
      "7.6539173 7.5 7.5\n",
      "6.9473543 7.5 7.5\n",
      "8.871499 10 10.0\n",
      "8.632639 7.5 10.0\n",
      "6.6380157 7.5 7.5\n",
      "5.424932 5 0.0\n",
      "7.31108 7.5 7.5\n",
      "6.5554976 7.5 7.5\n",
      "8.790182 10 7.5\n",
      "9.272254 10 10.0\n",
      "7.0529423 7.5 7.5\n",
      "7.143752 7.5 2.5\n",
      "7.236778 7.5 7.5\n",
      "8.189236 7.5 10.0\n",
      "5.593506 5 5.0\n",
      "7.0223684 7.5 7.5\n",
      "5.939659 5 2.5\n",
      "7.982329 7.5 2.5\n",
      "7.470095 7.5 7.5\n",
      "6.68159 7.5 10.0\n",
      "7.380261 7.5 7.5\n",
      "8.832326 10 10.0\n",
      "6.773444 7.5 5.0\n",
      "6.8262787 7.5 2.5\n",
      "6.738958 7.5 7.5\n",
      "6.9315753 7.5 2.5\n",
      "7.938725 7.5 7.5\n",
      "7.5798883 7.5 10.0\n",
      "7.113123 7.5 2.5\n",
      "7.575845 7.5 10.0\n",
      "8.766823 10 7.5\n",
      "9.478572 10 10.0\n",
      "6.410552 7.5 5.0\n",
      "7.6727724 7.5 7.5\n",
      "6.707111 7.5 7.5\n",
      "7.7603555 7.5 10.0\n",
      "7.3331995 7.5 7.5\n",
      "7.392276 7.5 10.0\n",
      "7.734407 7.5 10.0\n",
      "8.350414 7.5 7.5\n",
      "8.780409 10 7.5\n",
      "9.288985 10 10.0\n",
      "7.6241884 7.5 10.0\n",
      "8.848245 10 10.0\n",
      "7.121177 7.5 7.5\n",
      "9.181227 10 10.0\n",
      "7.564501 7.5 10.0\n",
      "8.4676285 7.5 10.0\n",
      "6.508122 7.5 7.5\n",
      "7.3495307 7.5 7.5\n",
      "7.8854747 7.5 10.0\n",
      "9.050826 10 10.0\n",
      "7.4045124 7.5 7.5\n",
      "6.5935645 7.5 2.5\n",
      "8.3751745 7.5 7.5\n",
      "9.151305 10 7.5\n",
      "8.780131 10 10.0\n",
      "7.6999984 7.5 5.0\n",
      "5.535413 5 10.0\n",
      "8.099703 7.5 10.0\n",
      "7.2799983 7.5 10.0\n",
      "7.5637827 7.5 5.0\n",
      "6.69554 7.5 10.0\n",
      "8.014756 7.5 7.5\n",
      "5.6018634 5 5.0\n",
      "5.8502812 5 10.0\n",
      "7.660278 7.5 10.0\n",
      "6.363688 7.5 7.5\n",
      "7.16239 7.5 2.5\n",
      "8.888669 10 10.0\n",
      "8.793113 10 7.5\n",
      "5.2504034 5 2.5\n",
      "7.7403865 7.5 10.0\n",
      "7.2918777 7.5 5.0\n",
      "8.890551 10 7.5\n",
      "6.0898294 5 7.5\n",
      "7.0753913 7.5 7.5\n",
      "6.7912726 7.5 10.0\n",
      "6.2981052 7.5 5.0\n",
      "7.498666 7.5 10.0\n",
      "7.287884 7.5 7.5\n",
      "7.5241075 7.5 0.0\n",
      "6.6154714 7.5 2.5\n",
      "7.8933024 7.5 10.0\n",
      "7.555913 7.5 10.0\n",
      "6.595496 7.5 2.5\n",
      "8.42863 7.5 7.5\n",
      "7.307203 7.5 5.0\n",
      "7.184511 7.5 0.0\n",
      "7.0012555 7.5 10.0\n",
      "7.479455 7.5 10.0\n",
      "6.9161158 7.5 7.5\n",
      "8.029268 7.5 5.0\n",
      "8.731306 7.5 10.0\n",
      "6.884422 7.5 10.0\n",
      "6.532835 7.5 7.5\n",
      "6.432507 7.5 7.5\n",
      "9.07966 10 10.0\n",
      "7.604865 7.5 10.0\n",
      "8.08231 7.5 10.0\n",
      "6.9609394 7.5 10.0\n",
      "9.161975 10 10.0\n",
      "7.1567783 7.5 10.0\n",
      "7.4081416 7.5 7.5\n",
      "9.139743 10 10.0\n",
      "8.521601 7.5 7.5\n",
      "7.290606 7.5 7.5\n",
      "5.186452 5 2.5\n",
      "8.407731 7.5 7.5\n",
      "6.79906 7.5 7.5\n",
      "6.202064 5 10.0\n",
      "8.942495 10 10.0\n",
      "7.8363967 7.5 7.5\n",
      "9.117894 10 7.5\n",
      "7.0929956 7.5 2.5\n",
      "7.58046 7.5 5.0\n",
      "6.639838 7.5 2.5\n",
      "7.6985745 7.5 7.5\n",
      "8.985766 10 10.0\n",
      "8.577229 7.5 5.0\n",
      "7.324442 7.5 7.5\n",
      "8.544062 7.5 5.0\n",
      "8.827666 10 10.0\n",
      "6.444445 7.5 10.0\n",
      "9.051476 10 10.0\n",
      "7.9380655 7.5 10.0\n",
      "7.4969687 7.5 5.0\n",
      "6.833603 7.5 7.5\n",
      "7.971432 7.5 7.5\n",
      "7.536485 7.5 7.5\n",
      "8.43069 7.5 5.0\n",
      "7.3821015 7.5 2.5\n",
      "5.799295 5 7.5\n",
      "8.073907 7.5 7.5\n",
      "5.60116 5 7.5\n",
      "6.549524 7.5 7.5\n",
      "7.0820284 7.5 10.0\n",
      "8.597996 7.5 7.5\n",
      "6.8750105 7.5 7.5\n",
      "8.843159 10 7.5\n",
      "7.9714055 7.5 7.5\n",
      "6.813808 7.5 2.5\n",
      "7.354239 7.5 10.0\n",
      "8.172924 7.5 2.5\n",
      "5.9640074 5 7.5\n",
      "9.345592 10 10.0\n",
      "9.310735 10 10.0\n",
      "7.7087145 7.5 10.0\n",
      "7.2377157 7.5 7.5\n",
      "5.315522 5 7.5\n",
      "5.406442 5 2.5\n",
      "8.275028 7.5 10.0\n",
      "6.9613595 7.5 10.0\n",
      "8.819082 10 10.0\n",
      "7.230734 7.5 10.0\n",
      "5.4223123 5 7.5\n",
      "6.5875525 7.5 10.0\n",
      "9.070607 10 7.5\n",
      "6.310473 7.5 5.0\n",
      "7.780624 7.5 2.5\n",
      "7.170576 7.5 10.0\n",
      "6.585246 7.5 5.0\n",
      "7.83606 7.5 7.5\n",
      "6.5752416 7.5 5.0\n",
      "6.531415 7.5 7.5\n",
      "6.7328267 7.5 7.5\n",
      "8.808004 10 10.0\n",
      "6.9216685 7.5 2.5\n",
      "4.927455 5 10.0\n",
      "7.271681 7.5 2.5\n",
      "8.627091 7.5 10.0\n",
      "6.8262577 7.5 7.5\n",
      "7.181028 7.5 10.0\n",
      "6.819683 7.5 7.5\n",
      "7.0804667 7.5 7.5\n",
      "7.1746454 7.5 7.5\n",
      "6.605191 7.5 7.5\n",
      "8.671727 7.5 10.0\n",
      "8.540407 7.5 7.5\n",
      "6.381366 7.5 7.5\n",
      "9.040679 10 10.0\n",
      "7.6297555 7.5 10.0\n",
      "7.765636 7.5 7.5\n",
      "9.418956 10 10.0\n",
      "7.2643185 7.5 10.0\n",
      "7.543571 7.5 7.5\n",
      "4.5083385 5 2.5\n",
      "8.987176 10 10.0\n",
      "6.282797 7.5 10.0\n",
      "8.752212 10 7.5\n",
      "8.134048 7.5 5.0\n",
      "6.272325 7.5 7.5\n",
      "6.4707394 7.5 2.5\n",
      "8.47811 7.5 7.5\n",
      "9.198601 10 10.0\n",
      "8.891259 10 7.5\n",
      "7.4879937 7.5 2.5\n",
      "8.307059 7.5 7.5\n",
      "8.559082 7.5 7.5\n",
      "5.9692698 5 0.0\n",
      "7.7506266 7.5 5.0\n",
      "7.448652 7.5 7.5\n",
      "7.338175 7.5 7.5\n",
      "7.816957 7.5 10.0\n",
      "6.2678604 7.5 10.0\n",
      "7.2281046 7.5 7.5\n",
      "6.98469 7.5 7.5\n",
      "8.576602 7.5 7.5\n",
      "7.2163014 7.5 7.5\n",
      "7.3090806 7.5 7.5\n",
      "8.222189 7.5 10.0\n",
      "7.5153875 7.5 7.5\n",
      "8.2531595 7.5 10.0\n",
      "6.450212 7.5 7.5\n",
      "6.9856334 7.5 5.0\n",
      "8.6321125 7.5 10.0\n",
      "7.7887406 7.5 7.5\n",
      "9.742432 10 10.0\n",
      "6.501456 7.5 7.5\n",
      "7.182554 7.5 7.5\n",
      "9.5116205 10 10.0\n",
      "7.3807206 7.5 7.5\n",
      "8.575488 7.5 10.0\n",
      "9.038429 10 7.5\n",
      "9.080168 10 10.0\n",
      "7.048025 7.5 7.5\n",
      "6.602903 7.5 5.0\n",
      "7.9332724 7.5 10.0\n",
      "7.8160176 7.5 7.5\n",
      "7.9278636 7.5 10.0\n",
      "7.3710523 7.5 5.0\n",
      "8.86883 10 7.5\n",
      "8.946785 10 10.0\n",
      "5.2464566 5 2.5\n",
      "9.305518 10 7.5\n",
      "7.804692 7.5 10.0\n",
      "6.3784103 7.5 7.5\n",
      "9.54782 10 7.5\n",
      "7.4317656 7.5 7.5\n",
      "6.901681 7.5 7.5\n",
      "7.3965397 7.5 7.5\n",
      "4.2099056 5 2.5\n",
      "5.702581 5 10.0\n",
      "6.514368 7.5 7.5\n",
      "7.0762715 7.5 2.5\n",
      "8.334358 7.5 7.5\n",
      "7.3036222 7.5 10.0\n",
      "6.4931464 7.5 7.5\n",
      "6.416714 7.5 5.0\n",
      "8.737952 7.5 7.5\n",
      "5.6974754 5 2.5\n",
      "7.534326 7.5 7.5\n",
      "7.9984493 7.5 2.5\n",
      "7.301328 7.5 7.5\n",
      "7.6245074 7.5 10.0\n",
      "6.631763 7.5 2.5\n",
      "5.8321214 5 10.0\n",
      "9.06773 10 10.0\n",
      "8.647634 7.5 7.5\n",
      "6.249001 5 2.5\n",
      "7.668551 7.5 2.5\n",
      "5.7010255 5 2.5\n",
      "8.953619 10 10.0\n",
      "6.2180176 5 10.0\n",
      "7.3723426 7.5 10.0\n",
      "6.8781543 7.5 7.5\n",
      "7.8162885 7.5 10.0\n",
      "6.6770473 7.5 7.5\n",
      "6.7807345 7.5 7.5\n",
      "8.368383 7.5 10.0\n",
      "8.977012 10 7.5\n",
      "7.5830326 7.5 7.5\n",
      "7.2363696 7.5 2.5\n",
      "7.1309705 7.5 5.0\n",
      "9.395374 10 10.0\n",
      "8.418922 7.5 7.5\n",
      "7.5338683 7.5 10.0\n",
      "6.6314735 7.5 7.5\n",
      "7.156119 7.5 10.0\n",
      "4.632284 5 7.5\n",
      "7.8378553 7.5 7.5\n",
      "7.7962084 7.5 7.5\n",
      "6.6233783 7.5 2.5\n",
      "6.3846226 7.5 10.0\n",
      "9.125645 10 10.0\n",
      "9.478191 10 10.0\n",
      "7.3396754 7.5 10.0\n",
      "8.340441 7.5 7.5\n",
      "7.2170515 7.5 10.0\n",
      "8.068691 7.5 7.5\n",
      "7.6339335 7.5 10.0\n",
      "7.729588 7.5 5.0\n",
      "7.6988664 7.5 5.0\n",
      "6.897742 7.5 7.5\n",
      "7.693759 7.5 10.0\n",
      "7.8304935 7.5 7.5\n",
      "8.542388 7.5 10.0\n",
      "8.798858 10 10.0\n",
      "8.561046 7.5 7.5\n",
      "6.3286815 7.5 5.0\n",
      "8.455389 7.5 10.0\n",
      "7.117511 7.5 7.5\n",
      "8.982763 10 10.0\n",
      "7.577491 7.5 10.0\n",
      "9.262005 10 7.5\n",
      "6.569786 7.5 7.5\n",
      "7.406586 7.5 10.0\n",
      "8.255782 7.5 5.0\n",
      "7.5876536 7.5 10.0\n",
      "9.059542 10 10.0\n",
      "9.005013 10 7.5\n",
      "7.9841666 7.5 5.0\n",
      "6.2209425 5 10.0\n",
      "8.255762 7.5 10.0\n",
      "6.9165416 7.5 7.5\n",
      "6.933199 7.5 10.0\n",
      "6.7013674 7.5 10.0\n",
      "7.101739 7.5 5.0\n",
      "8.727008 7.5 10.0\n",
      "6.9873323 7.5 7.5\n",
      "7.4176683 7.5 5.0\n",
      "8.71631 7.5 7.5\n",
      "9.447727 10 10.0\n",
      "9.106267 10 10.0\n",
      "7.467645 7.5 7.5\n",
      "8.583505 7.5 7.5\n",
      "7.940151 7.5 10.0\n",
      "8.2465105 7.5 7.5\n",
      "9.016502 10 7.5\n",
      "7.649454 7.5 10.0\n",
      "7.549582 7.5 10.0\n",
      "9.270515 10 7.5\n",
      "4.552969 5 0.0\n",
      "7.605285 7.5 5.0\n",
      "6.70693 7.5 2.5\n",
      "8.519252 7.5 10.0\n",
      "7.751408 7.5 10.0\n",
      "6.514062 7.5 5.0\n",
      "8.626833 7.5 7.5\n",
      "8.701287 7.5 10.0\n",
      "6.390295 7.5 5.0\n",
      "6.985173 7.5 7.5\n",
      "6.9405117 7.5 7.5\n",
      "7.7030587 7.5 2.5\n",
      "7.601935 7.5 7.5\n",
      "7.380377 7.5 10.0\n",
      "7.207549 7.5 5.0\n",
      "5.2560205 5 2.5\n",
      "8.865373 10 7.5\n",
      "7.959296 7.5 7.5\n",
      "8.459663 7.5 10.0\n",
      "7.6938925 7.5 5.0\n",
      "7.7472315 7.5 10.0\n",
      "8.166938 7.5 5.0\n",
      "6.3575034 7.5 7.5\n",
      "7.2995877 7.5 7.5\n",
      "8.310004 7.5 5.0\n",
      "9.675833 10 10.0\n",
      "8.481352 7.5 7.5\n",
      "7.701749 7.5 7.5\n",
      "7.2444715 7.5 7.5\n",
      "7.163082 7.5 2.5\n",
      "8.7460985 7.5 7.5\n",
      "6.332188 7.5 10.0\n",
      "7.695487 7.5 7.5\n",
      "8.956744 10 7.5\n",
      "6.0311384 5 7.5\n",
      "6.792069 7.5 5.0\n",
      "5.2646055 5 2.5\n",
      "4.8947 5 2.5\n",
      "8.391121 7.5 7.5\n",
      "7.781183 7.5 10.0\n",
      "8.387264 7.5 5.0\n",
      "7.512713 7.5 5.0\n",
      "6.6981516 7.5 5.0\n",
      "7.2297783 7.5 7.5\n",
      "7.3083534 7.5 7.5\n",
      "3.7569492 5 2.5\n",
      "6.580185 7.5 7.5\n",
      "7.0869474 7.5 7.5\n",
      "8.044603 7.5 10.0\n",
      "6.600531 7.5 7.5\n",
      "8.699702 7.5 10.0\n",
      "7.774529 7.5 5.0\n",
      "6.686033 7.5 2.5\n",
      "7.706295 7.5 10.0\n",
      "7.245576 7.5 10.0\n",
      "7.6629405 7.5 7.5\n",
      "5.437481 5 5.0\n",
      "8.486286 7.5 7.5\n",
      "7.341423 7.5 7.5\n",
      "7.244211 7.5 10.0\n",
      "8.795363 10 10.0\n",
      "7.7861633 7.5 10.0\n",
      "8.75372 10 10.0\n",
      "4.447223 5 2.5\n",
      "8.098503 7.5 10.0\n",
      "8.214169 7.5 7.5\n",
      "7.165618 7.5 2.5\n",
      "6.6332064 7.5 5.0\n",
      "6.7120156 7.5 7.5\n",
      "7.2642407 7.5 5.0\n",
      "6.988785 7.5 5.0\n",
      "5.4750347 5 7.5\n",
      "7.777383 7.5 7.5\n",
      "8.971156 10 7.5\n",
      "8.806214 10 7.5\n",
      "8.319092 7.5 10.0\n",
      "7.9334025 7.5 7.5\n",
      "8.744163 7.5 7.5\n",
      "6.205485 5 7.5\n",
      "7.7057076 7.5 7.5\n",
      "9.111185 10 0.0\n",
      "8.613579 7.5 7.5\n",
      "6.9350934 7.5 5.0\n",
      "6.9429216 7.5 5.0\n",
      "6.798795 7.5 7.5\n",
      "8.676356 7.5 10.0\n",
      "8.751474 10 10.0\n",
      "4.9838586 5 0.0\n",
      "7.687613 7.5 10.0\n",
      "8.854778 10 7.5\n",
      "7.957039 7.5 5.0\n",
      "6.9394145 7.5 7.5\n",
      "8.237345 7.5 10.0\n",
      "7.3617816 7.5 10.0\n",
      "8.576541 7.5 10.0\n",
      "7.156694 7.5 7.5\n",
      "9.571813 10 10.0\n",
      "7.175396 7.5 5.0\n",
      "7.095522 7.5 10.0\n",
      "7.673754 7.5 7.5\n",
      "6.612209 7.5 7.5\n",
      "7.0314493 7.5 7.5\n",
      "6.6542187 7.5 2.5\n",
      "6.0832415 5 5.0\n",
      "8.326136 7.5 7.5\n",
      "9.324812 10 10.0\n",
      "7.313712 7.5 7.5\n",
      "6.1933355 5 2.5\n",
      "7.461219 7.5 5.0\n",
      "8.992753 10 10.0\n",
      "6.2270217 5 2.5\n",
      "6.379108 7.5 7.5\n",
      "8.720922 7.5 10.0\n",
      "6.4751725 7.5 5.0\n",
      "6.4918175 7.5 7.5\n",
      "6.598204 7.5 7.5\n",
      "8.401873 7.5 7.5\n",
      "6.512863 7.5 5.0\n",
      "7.435588 7.5 10.0\n",
      "6.938879 7.5 10.0\n",
      "6.4807773 7.5 5.0\n",
      "7.206088 7.5 7.5\n",
      "5.669739 5 7.5\n",
      "6.9036975 7.5 7.5\n",
      "9.766813 10 10.0\n",
      "5.915247 5 2.5\n",
      "6.511838 7.5 0.0\n",
      "6.8798976 7.5 7.5\n",
      "4.0228643 5 7.5\n",
      "8.412083 7.5 10.0\n",
      "6.883768 7.5 10.0\n",
      "7.151635 7.5 7.5\n",
      "8.786153 10 7.5\n",
      "8.576738 7.5 7.5\n",
      "8.997942 10 10.0\n",
      "7.5907836 7.5 7.5\n",
      "4.9446144 5 5.0\n",
      "8.61695 7.5 7.5\n",
      "8.100332 7.5 10.0\n",
      "7.7605987 7.5 10.0\n",
      "7.419445 7.5 7.5\n",
      "8.319029 7.5 7.5\n",
      "9.376163 10 10.0\n",
      "8.933031 10 7.5\n",
      "7.2321033 7.5 7.5\n",
      "6.378215 7.5 7.5\n",
      "6.398544 7.5 10.0\n",
      "7.2348213 7.5 7.5\n",
      "6.0665336 5 7.5\n",
      "7.6436553 7.5 5.0\n",
      "6.4242477 7.5 7.5\n",
      "6.5864177 7.5 7.5\n",
      "6.9929976 7.5 2.5\n",
      "7.4308586 7.5 7.5\n",
      "7.5122366 7.5 0.0\n",
      "8.338272 7.5 10.0\n",
      "7.1991534 7.5 7.5\n",
      "9.292533 10 7.5\n",
      "9.265516 10 7.5\n",
      "9.265324 10 10.0\n",
      "9.279284 10 10.0\n",
      "8.923593 10 10.0\n",
      "6.752211 7.5 5.0\n",
      "9.663937 10 10.0\n",
      "8.513506 7.5 7.5\n",
      "7.260325 7.5 7.5\n",
      "8.810713 10 7.5\n",
      "4.8796697 5 2.5\n",
      "7.3917603 7.5 10.0\n",
      "8.993802 10 10.0\n",
      "8.011976 7.5 10.0\n",
      "7.286121 7.5 5.0\n",
      "7.5255103 7.5 10.0\n",
      "9.275547 10 5.0\n",
      "7.3426614 7.5 7.5\n",
      "8.989453 10 7.5\n",
      "7.8295655 7.5 7.5\n",
      "7.0525703 7.5 2.5\n",
      "6.0915527 5 7.5\n",
      "4.912957 5 2.5\n",
      "9.574413 10 10.0\n",
      "6.402634 7.5 7.5\n",
      "9.079139 10 7.5\n",
      "7.740183 7.5 5.0\n",
      "7.620727 7.5 10.0\n",
      "8.095327 7.5 7.5\n",
      "9.134417 10 10.0\n",
      "7.545144 7.5 10.0\n",
      "7.1886134 7.5 10.0\n",
      "8.670951 7.5 10.0\n",
      "7.4531302 7.5 5.0\n",
      "7.1803293 7.5 7.5\n",
      "6.865906 7.5 5.0\n",
      "5.2394466 5 7.5\n",
      "6.990627 7.5 7.5\n",
      "6.317846 7.5 5.0\n",
      "7.521504 7.5 5.0\n",
      "8.356823 7.5 10.0\n",
      "7.337122 7.5 5.0\n",
      "6.9681034 7.5 7.5\n",
      "8.132064 7.5 10.0\n",
      "7.20198 7.5 10.0\n",
      "7.2596145 7.5 5.0\n",
      "6.8938975 7.5 7.5\n",
      "8.849633 10 7.5\n",
      "5.2152276 5 2.5\n",
      "7.1922903 7.5 7.5\n",
      "5.925305 5 5.0\n",
      "8.83126 10 10.0\n",
      "8.037479 7.5 7.5\n",
      "7.42992 7.5 7.5\n",
      "8.1327305 7.5 10.0\n",
      "7.892463 7.5 10.0\n",
      "6.946012 7.5 10.0\n",
      "7.1389556 7.5 10.0\n",
      "9.1234455 10 10.0\n",
      "7.071132 7.5 2.5\n",
      "7.69124 7.5 7.5\n",
      "7.291709 7.5 7.5\n",
      "7.9747124 7.5 10.0\n",
      "6.6424527 7.5 7.5\n",
      "8.618468 7.5 5.0\n",
      "7.699234 7.5 7.5\n",
      "6.5376515 7.5 7.5\n",
      "7.7759223 7.5 7.5\n",
      "7.5235915 7.5 7.5\n",
      "7.37816 7.5 7.5\n",
      "8.659096 7.5 7.5\n",
      "7.8772883 7.5 10.0\n",
      "7.325911 7.5 7.5\n",
      "2.848714 2.5 0.0\n",
      "6.7180777 7.5 5.0\n",
      "8.414538 7.5 7.5\n",
      "6.953184 7.5 5.0\n",
      "5.395814 5 2.5\n",
      "7.5803337 7.5 10.0\n",
      "9.489346 10 7.5\n",
      "8.6335335 7.5 10.0\n",
      "7.9350557 7.5 7.5\n",
      "9.432738 10 10.0\n",
      "6.423227 7.5 2.5\n",
      "8.856326 10 10.0\n",
      "7.8391647 7.5 10.0\n",
      "8.914419 10 10.0\n",
      "7.756202 7.5 10.0\n",
      "8.731067 7.5 5.0\n",
      "8.860134 10 7.5\n",
      "7.8849535 7.5 7.5\n",
      "9.06101 10 10.0\n",
      "8.809544 10 10.0\n",
      "7.3787103 7.5 10.0\n",
      "6.9704385 7.5 7.5\n",
      "7.158867 7.5 10.0\n",
      "5.0284066 5 2.5\n",
      "8.663938 7.5 10.0\n",
      "8.108798 7.5 7.5\n",
      "8.541402 7.5 2.5\n",
      "8.541363 7.5 10.0\n",
      "7.1693697 7.5 7.5\n",
      "7.4652405 7.5 10.0\n",
      "7.9994063 7.5 10.0\n",
      "7.520384 7.5 7.5\n",
      "6.370214 7.5 2.5\n",
      "7.507338 7.5 0.0\n",
      "8.412423 7.5 10.0\n",
      "3.2681868 2.5 2.5\n",
      "7.138706 7.5 7.5\n",
      "8.925926 10 10.0\n",
      "8.697322 7.5 10.0\n",
      "7.9604325 7.5 10.0\n",
      "8.204713 7.5 2.5\n",
      "8.400347 7.5 7.5\n",
      "6.3788147 7.5 7.5\n",
      "7.306433 7.5 7.5\n",
      "7.764073 7.5 5.0\n",
      "5.8734336 5 7.5\n",
      "6.4721055 7.5 2.5\n",
      "7.0267596 7.5 7.5\n",
      "7.4443154 7.5 10.0\n",
      "7.105748 7.5 5.0\n",
      "6.749915 7.5 7.5\n",
      "6.4740024 7.5 7.5\n",
      "8.486832 7.5 10.0\n",
      "6.4215064 7.5 10.0\n",
      "7.074429 7.5 5.0\n",
      "9.22484 10 10.0\n",
      "4.1694484 5 2.5\n",
      "7.288771 7.5 7.5\n",
      "7.4001155 7.5 5.0\n",
      "7.3550854 7.5 7.5\n",
      "8.675209 7.5 10.0\n",
      "7.4599094 7.5 5.0\n",
      "7.4428554 7.5 7.5\n",
      "7.153505 7.5 7.5\n",
      "7.4663324 7.5 10.0\n",
      "7.890716 7.5 2.5\n",
      "9.152111 10 10.0\n",
      "9.179613 10 10.0\n",
      "8.499989 7.5 10.0\n",
      "6.978427 7.5 2.5\n",
      "8.882984 10 7.5\n",
      "9.803037 10 5.0\n",
      "7.5173397 7.5 10.0\n",
      "7.946553 7.5 10.0\n",
      "5.157532 5 2.5\n",
      "8.385147 7.5 7.5\n",
      "6.8091373 7.5 7.5\n",
      "9.738599 10 10.0\n",
      "8.577357 7.5 10.0\n",
      "7.6354556 7.5 7.5\n",
      "7.944271 7.5 7.5\n",
      "7.8088984 7.5 7.5\n",
      "6.711192 7.5 5.0\n",
      "9.181415 10 10.0\n",
      "8.345118 7.5 10.0\n",
      "7.464939 7.5 2.5\n",
      "9.017062 10 10.0\n",
      "3.4188087 2.5 0.0\n",
      "8.990631 10 10.0\n",
      "6.8886046 7.5 10.0\n",
      "5.5455594 5 7.5\n",
      "5.849814 5 7.5\n",
      "6.8834105 7.5 0.0\n",
      "9.077557 10 10.0\n",
      "7.7458606 7.5 7.5\n",
      "8.170761 7.5 7.5\n",
      "4.5359063 5 2.5\n",
      "7.4548306 7.5 7.5\n",
      "7.4947147 7.5 10.0\n",
      "8.942481 10 7.5\n",
      "7.2921114 7.5 7.5\n",
      "9.10942 10 10.0\n",
      "6.4626794 7.5 7.5\n",
      "7.2657614 7.5 7.5\n",
      "7.692549 7.5 7.5\n",
      "7.803355 7.5 10.0\n",
      "6.7984285 7.5 5.0\n",
      "3.8623085 5 7.5\n",
      "8.608974 7.5 10.0\n",
      "8.99698 10 10.0\n",
      "6.342052 7.5 10.0\n",
      "7.0033474 7.5 7.5\n",
      "7.2271075 7.5 5.0\n",
      "8.703488 7.5 7.5\n",
      "7.881562 7.5 7.5\n",
      "8.665552 7.5 10.0\n",
      "7.053925 7.5 10.0\n",
      "7.779216 7.5 7.5\n",
      "5.0165305 5 10.0\n",
      "7.631777 7.5 10.0\n",
      "7.155921 7.5 10.0\n",
      "7.2695866 7.5 7.5\n",
      "7.0282784 7.5 7.5\n",
      "8.904624 10 7.5\n",
      "8.660762 7.5 5.0\n",
      "7.398917 7.5 7.5\n",
      "8.270994 7.5 7.5\n",
      "7.796476 7.5 7.5\n",
      "8.634703 7.5 10.0\n",
      "8.86881 10 10.0\n",
      "7.062053 7.5 10.0\n",
      "8.940746 10 10.0\n",
      "8.315051 7.5 10.0\n",
      "7.662619 7.5 10.0\n",
      "8.663633 7.5 10.0\n",
      "7.4767423 7.5 7.5\n",
      "7.2762866 7.5 7.5\n",
      "5.3332033 5 2.5\n",
      "6.442603 7.5 7.5\n",
      "8.949857 10 7.5\n",
      "7.00041 7.5 10.0\n",
      "4.3921757 5 0.0\n",
      "9.298478 10 10.0\n",
      "7.939052 7.5 5.0\n",
      "7.8926616 7.5 10.0\n",
      "7.360098 7.5 5.0\n",
      "8.901692 10 7.5\n",
      "6.5881624 7.5 10.0\n",
      "7.6436553 7.5 5.0\n",
      "9.26612 10 10.0\n",
      "7.279023 7.5 2.5\n",
      "7.454567 7.5 5.0\n",
      "8.84128 10 10.0\n",
      "7.154193 7.5 7.5\n",
      "7.348761 7.5 10.0\n",
      "7.0509744 7.5 10.0\n",
      "7.4109974 7.5 10.0\n",
      "7.50665 7.5 10.0\n",
      "7.6811013 7.5 10.0\n",
      "7.7428393 7.5 7.5\n",
      "9.00808 10 10.0\n",
      "7.262486 7.5 10.0\n",
      "8.888634 10 7.5\n",
      "7.2414865 7.5 7.5\n",
      "9.01813 10 10.0\n",
      "5.4588103 5 5.0\n",
      "9.536162 10 10.0\n",
      "8.924709 10 10.0\n",
      "9.236886 10 7.5\n",
      "8.050895 7.5 7.5\n",
      "5.5868134 5 2.5\n",
      "8.454868 7.5 7.5\n",
      "6.8156075 7.5 7.5\n",
      "7.3488946 7.5 5.0\n",
      "9.12472 10 10.0\n",
      "7.9694934 7.5 10.0\n",
      "8.356356 7.5 10.0\n",
      "6.3539596 7.5 5.0\n",
      "4.8942156 5 7.5\n",
      "5.792913 5 2.5\n",
      "8.34318 7.5 7.5\n",
      "6.2689314 7.5 7.5\n",
      "6.4542704 7.5 7.5\n",
      "6.0504494 5 5.0\n",
      "5.3503 5 5.0\n",
      "8.388317 7.5 7.5\n",
      "6.404294 7.5 7.5\n",
      "8.114807 7.5 7.5\n",
      "7.017598 7.5 0.0\n",
      "7.436452 7.5 7.5\n",
      "8.936677 10 10.0\n",
      "7.492207 7.5 7.5\n",
      "7.747825 7.5 5.0\n",
      "5.4058166 5 2.5\n",
      "8.482055 7.5 5.0\n",
      "7.5904565 7.5 7.5\n",
      "8.903685 10 10.0\n",
      "7.2752185 7.5 7.5\n",
      "6.237676 5 5.0\n",
      "7.296435 7.5 10.0\n",
      "6.833897 7.5 10.0\n",
      "7.549978 7.5 10.0\n",
      "7.071357 7.5 10.0\n",
      "5.4863944 5 2.5\n",
      "6.307876 7.5 7.5\n",
      "8.20893 7.5 10.0\n",
      "5.990776 5 7.5\n",
      "8.362532 7.5 10.0\n",
      "7.1043367 7.5 7.5\n",
      "7.3421392 7.5 10.0\n",
      "7.644373 7.5 10.0\n",
      "7.4476748 7.5 2.5\n",
      "8.021668 7.5 10.0\n",
      "7.874553 7.5 7.5\n",
      "9.096622 10 10.0\n",
      "7.7939878 7.5 7.5\n",
      "7.065462 7.5 7.5\n",
      "7.933445 7.5 10.0\n",
      "6.372114 7.5 0.0\n",
      "7.3497086 7.5 7.5\n",
      "9.058817 10 10.0\n",
      "7.126306 7.5 7.5\n",
      "9.141496 10 7.5\n",
      "7.120605 7.5 7.5\n",
      "7.9963956 7.5 7.5\n",
      "7.2307744 7.5 7.5\n",
      "7.8520155 7.5 7.5\n",
      "6.823829 7.5 5.0\n",
      "7.277965 7.5 10.0\n",
      "6.9042625 7.5 5.0\n",
      "7.4205875 7.5 10.0\n",
      "9.475593 10 7.5\n",
      "7.6673994 7.5 7.5\n",
      "7.582217 7.5 10.0\n",
      "7.6652284 7.5 5.0\n",
      "7.099575 7.5 10.0\n",
      "7.53591 7.5 7.5\n",
      "6.852302 7.5 7.5\n",
      "7.071714 7.5 5.0\n",
      "8.843876 10 5.0\n",
      "6.181886 5 2.5\n",
      "9.502911 10 10.0\n",
      "8.127546 7.5 7.5\n",
      "9.289203 10 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.760685 7.5 10.0\n",
      "8.821927 10 7.5\n",
      "7.4442616 7.5 7.5\n",
      "7.7990084 7.5 7.5\n",
      "6.3827243 7.5 2.5\n",
      "7.2358866 7.5 10.0\n",
      "8.875368 10 10.0\n",
      "6.5619397 7.5 5.0\n",
      "9.182947 10 10.0\n",
      "4.367136 5 7.5\n",
      "7.6697392 7.5 7.5\n",
      "7.6056943 7.5 7.5\n",
      "7.1915956 7.5 10.0\n",
      "8.1389675 7.5 10.0\n",
      "8.704581 7.5 7.5\n",
      "7.4515715 7.5 7.5\n",
      "7.3995833 7.5 2.5\n",
      "5.835661 5 2.5\n",
      "8.826144 10 10.0\n",
      "9.235827 10 7.5\n",
      "5.5191054 5 5.0\n",
      "6.203065 5 7.5\n",
      "6.5741863 7.5 7.5\n",
      "6.2972455 7.5 10.0\n",
      "7.064277 7.5 5.0\n",
      "5.743789 5 5.0\n",
      "8.2548685 7.5 10.0\n",
      "8.869461 10 10.0\n",
      "7.3615146 7.5 7.5\n",
      "6.889896 7.5 7.5\n",
      "6.8485804 7.5 7.5\n",
      "6.5264893 7.5 7.5\n",
      "6.994022 7.5 7.5\n",
      "7.7897563 7.5 10.0\n",
      "8.830721 10 7.5\n",
      "6.8106136 7.5 10.0\n",
      "7.553045 7.5 10.0\n",
      "6.657207 7.5 5.0\n",
      "7.0640388 7.5 7.5\n",
      "6.8612704 7.5 5.0\n",
      "8.883724 10 7.5\n",
      "7.7433324 7.5 7.5\n",
      "7.1755404 7.5 10.0\n",
      "7.748843 7.5 7.5\n",
      "6.334149 7.5 5.0\n",
      "9.155457 10 10.0\n",
      "8.379332 7.5 10.0\n",
      "8.09853 7.5 10.0\n",
      "8.055823 7.5 7.5\n",
      "6.5188313 7.5 10.0\n",
      "8.244404 7.5 7.5\n",
      "7.3874316 7.5 5.0\n",
      "7.6197114 7.5 7.5\n",
      "5.0924687 5 2.5\n",
      "7.3565054 7.5 7.5\n",
      "6.8516836 7.5 5.0\n",
      "7.22283 7.5 7.5\n",
      "8.544028 7.5 10.0\n",
      "8.874953 10 10.0\n",
      "7.785538 7.5 2.5\n",
      "7.615743 7.5 5.0\n",
      "6.2110815 5 7.5\n",
      "8.905908 10 7.5\n",
      "9.155115 10 7.5\n",
      "8.831339 10 10.0\n",
      "8.791692 10 10.0\n",
      "7.1740227 7.5 7.5\n",
      "7.984481 7.5 10.0\n",
      "6.8095455 7.5 7.5\n",
      "6.7658477 7.5 7.5\n",
      "4.0211477 5 0.0\n",
      "9.298213 10 10.0\n",
      "7.7640285 7.5 10.0\n",
      "7.1943264 7.5 7.5\n",
      "6.6188107 7.5 5.0\n",
      "7.418891 7.5 7.5\n",
      "9.093144 10 10.0\n",
      "6.556414 7.5 2.5\n",
      "8.967906 10 7.5\n",
      "6.96446 7.5 7.5\n",
      "9.513585 10 10.0\n",
      "6.2502117 7.5 2.5\n",
      "6.600219 7.5 7.5\n",
      "6.180531 5 7.5\n",
      "8.556815 7.5 10.0\n",
      "6.4508605 7.5 2.5\n",
      "7.747286 7.5 7.5\n",
      "8.94993 10 10.0\n",
      "7.9718065 7.5 0.0\n",
      "7.671445 7.5 7.5\n",
      "8.54826 7.5 10.0\n",
      "6.4970074 7.5 10.0\n",
      "6.2253866 5 5.0\n",
      "9.364621 10 10.0\n",
      "7.103515 7.5 7.5\n",
      "4.0923433 5 5.0\n",
      "7.1871715 7.5 10.0\n",
      "8.133171 7.5 10.0\n",
      "7.228049 7.5 7.5\n",
      "5.460142 5 0.0\n",
      "9.281177 10 10.0\n",
      "6.7303257 7.5 7.5\n",
      "9.328558 10 7.5\n",
      "7.0105066 7.5 5.0\n",
      "7.8402147 7.5 10.0\n",
      "9.561613 10 10.0\n",
      "5.0860367 5 5.0\n",
      "6.75933 7.5 5.0\n",
      "7.101638 7.5 5.0\n",
      "8.863973 10 10.0\n",
      "9.284204 10 10.0\n",
      "8.5385065 7.5 7.5\n",
      "7.055512 7.5 10.0\n",
      "8.534483 7.5 7.5\n",
      "7.2394156 7.5 7.5\n",
      "6.813231 7.5 10.0\n",
      "5.1219826 5 5.0\n",
      "8.446651 7.5 2.5\n",
      "8.489075 7.5 7.5\n",
      "6.176046 5 10.0\n",
      "7.112429 7.5 7.5\n",
      "8.769637 10 10.0\n",
      "6.7999105 7.5 7.5\n",
      "7.1541214 7.5 2.5\n",
      "7.662334 7.5 7.5\n",
      "7.457184 7.5 7.5\n",
      "8.565492 7.5 10.0\n",
      "7.406676 7.5 10.0\n",
      "8.319792 7.5 10.0\n",
      "4.7781196 5 5.0\n",
      "7.4248605 7.5 7.5\n",
      "7.2647586 7.5 7.5\n",
      "8.287544 7.5 10.0\n",
      "9.121345 10 10.0\n",
      "6.904462 7.5 7.5\n",
      "7.063353 7.5 5.0\n",
      "7.685941 7.5 10.0\n",
      "7.0683255 7.5 7.5\n",
      "9.269771 10 10.0\n",
      "6.7854 7.5 5.0\n",
      "8.355713 7.5 7.5\n",
      "8.555223 7.5 7.5\n",
      "6.920619 7.5 5.0\n",
      "7.2219195 7.5 10.0\n",
      "7.631307 7.5 7.5\n",
      "8.436543 7.5 10.0\n",
      "7.7471223 7.5 10.0\n",
      "6.6988764 7.5 7.5\n",
      "7.487588 7.5 7.5\n",
      "8.995469 10 10.0\n",
      "7.4221916 7.5 5.0\n",
      "7.378341 7.5 10.0\n",
      "6.356868 7.5 0.0\n",
      "8.7482395 7.5 7.5\n",
      "8.006449 7.5 7.5\n",
      "8.9731455 10 10.0\n",
      "8.04119 7.5 7.5\n",
      "7.2025995 7.5 7.5\n",
      "7.1456933 7.5 7.5\n",
      "8.393837 7.5 10.0\n",
      "7.091093 7.5 7.5\n",
      "7.6636677 7.5 7.5\n",
      "7.4544606 7.5 10.0\n",
      "6.9319725 7.5 7.5\n",
      "6.9912496 7.5 7.5\n",
      "5.8340125 5 7.5\n",
      "8.336481 7.5 2.5\n",
      "7.256458 7.5 10.0\n",
      "7.868079 7.5 5.0\n",
      "6.8389444 7.5 5.0\n",
      "7.5735617 7.5 2.5\n",
      "5.6374464 5 2.5\n",
      "8.234454 7.5 10.0\n",
      "7.6379957 7.5 7.5\n",
      "7.2473564 7.5 10.0\n",
      "6.423319 7.5 5.0\n",
      "6.8627553 7.5 7.5\n",
      "8.638815 7.5 10.0\n",
      "7.8739066 7.5 7.5\n",
      "7.2595453 7.5 7.5\n",
      "6.9961743 7.5 10.0\n",
      "6.727895 7.5 5.0\n",
      "7.7048035 7.5 5.0\n",
      "9.503086 10 10.0\n",
      "8.992665 10 7.5\n",
      "7.1220965 7.5 10.0\n",
      "8.152927 7.5 10.0\n",
      "6.0989876 5 7.5\n",
      "7.2947507 7.5 10.0\n",
      "7.812168 7.5 10.0\n",
      "8.249279 7.5 7.5\n",
      "9.083114 10 7.5\n",
      "6.684174 7.5 7.5\n",
      "8.27601 7.5 7.5\n",
      "7.4649386 7.5 7.5\n",
      "6.228361 5 7.5\n",
      "7.2239947 7.5 10.0\n",
      "8.472889 7.5 10.0\n",
      "7.2850413 7.5 10.0\n",
      "5.152608 5 2.5\n",
      "7.450144 7.5 10.0\n",
      "9.023595 10 10.0\n",
      "6.1205363 5 5.0\n",
      "7.088463 7.5 7.5\n",
      "8.339172 7.5 7.5\n",
      "8.894118 10 10.0\n",
      "8.418751 7.5 10.0\n",
      "7.47054 7.5 7.5\n",
      "7.6479 7.5 7.5\n",
      "8.790858 10 10.0\n",
      "5.976678 5 2.5\n",
      "6.3362617 7.5 5.0\n",
      "7.508385 7.5 7.5\n",
      "9.050475 10 10.0\n",
      "7.22314 7.5 10.0\n",
      "9.095815 10 7.5\n",
      "7.5938005 7.5 7.5\n",
      "7.402622 7.5 10.0\n",
      "8.155241 7.5 7.5\n",
      "6.7528048 7.5 5.0\n",
      "6.831529 7.5 5.0\n",
      "8.079639 7.5 7.5\n",
      "7.168214 7.5 7.5\n",
      "7.065857 7.5 7.5\n",
      "8.898822 10 7.5\n",
      "8.517264 7.5 10.0\n",
      "8.42282 7.5 10.0\n",
      "6.33531 7.5 5.0\n",
      "7.5515003 7.5 7.5\n",
      "8.382813 7.5 10.0\n",
      "9.278016 10 10.0\n",
      "6.69611 7.5 2.5\n",
      "7.9641695 7.5 7.5\n",
      "8.9510145 10 7.5\n",
      "7.120676 7.5 10.0\n",
      "8.603761 7.5 10.0\n",
      "7.2068686 7.5 2.5\n",
      "8.484365 7.5 10.0\n",
      "7.5601597 7.5 7.5\n",
      "7.4336624 7.5 10.0\n",
      "7.676981 7.5 7.5\n",
      "7.314356 7.5 7.5\n",
      "7.321901 7.5 7.5\n",
      "7.0178547 7.5 5.0\n",
      "7.8469286 7.5 7.5\n",
      "6.5889993 7.5 7.5\n",
      "6.132666 5 5.0\n",
      "9.227357 10 10.0\n",
      "7.771103 7.5 10.0\n",
      "8.806351 10 2.5\n",
      "4.484934 5 2.5\n",
      "6.7978477 7.5 7.5\n",
      "6.767732 7.5 0.0\n",
      "8.985864 10 10.0\n",
      "7.0490413 7.5 7.5\n",
      "7.362008 7.5 7.5\n",
      "8.767563 10 10.0\n",
      "8.767576 10 10.0\n",
      "7.6037 7.5 7.5\n",
      "7.472853 7.5 10.0\n",
      "7.4841633 7.5 7.5\n",
      "8.15233 7.5 10.0\n",
      "7.745507 7.5 10.0\n",
      "7.3786197 7.5 10.0\n",
      "8.100622 7.5 5.0\n",
      "7.5063143 7.5 7.5\n",
      "8.019329 7.5 7.5\n",
      "7.081466 7.5 7.5\n",
      "6.8630347 7.5 10.0\n",
      "7.892143 7.5 10.0\n",
      "6.891666 7.5 5.0\n",
      "7.5126605 7.5 10.0\n",
      "7.487547 7.5 7.5\n",
      "7.158037 7.5 5.0\n",
      "7.1660485 7.5 7.5\n",
      "7.125655 7.5 7.5\n",
      "6.889044 7.5 10.0\n",
      "9.171648 10 7.5\n",
      "6.2396994 5 7.5\n",
      "9.701401 10 10.0\n",
      "7.149961 7.5 7.5\n",
      "8.671176 7.5 10.0\n",
      "7.6878686 7.5 7.5\n",
      "7.2988453 7.5 5.0\n",
      "6.78473 7.5 0.0\n",
      "6.952039 7.5 7.5\n",
      "9.267616 10 10.0\n",
      "8.707578 7.5 7.5\n",
      "6.4654503 7.5 7.5\n",
      "7.875001 7.5 7.5\n",
      "6.2194095 5 2.5\n",
      "6.391421 7.5 7.5\n",
      "7.931196 7.5 10.0\n",
      "7.3833327 7.5 7.5\n",
      "6.3278265 7.5 7.5\n",
      "8.853412 10 10.0\n",
      "8.527034 7.5 10.0\n",
      "7.1646705 7.5 0.0\n",
      "4.830397 5 0.0\n",
      "7.9131107 7.5 7.5\n",
      "7.0594935 7.5 7.5\n",
      "6.41397 7.5 7.5\n",
      "8.766951 10 7.5\n",
      "8.48736 7.5 10.0\n",
      "7.68842 7.5 7.5\n",
      "7.4392753 7.5 10.0\n",
      "6.8414216 7.5 7.5\n",
      "8.034958 7.5 7.5\n",
      "6.0081954 5 5.0\n",
      "8.634897 7.5 10.0\n",
      "6.126692 5 10.0\n",
      "8.662507 7.5 7.5\n",
      "6.707382 7.5 7.5\n",
      "7.843692 7.5 2.5\n",
      "8.566007 7.5 10.0\n",
      "9.95166 10 7.5\n",
      "7.8053713 7.5 10.0\n",
      "3.3283925 2.5 2.5\n",
      "8.162451 7.5 10.0\n",
      "7.5280657 7.5 10.0\n",
      "7.6494412 7.5 7.5\n",
      "9.088149 10 10.0\n",
      "8.942622 10 10.0\n",
      "9.069761 10 7.5\n",
      "8.784606 10 7.5\n",
      "7.5085697 7.5 7.5\n",
      "8.459416 7.5 7.5\n",
      "9.266925 10 10.0\n",
      "6.5855036 7.5 0.0\n",
      "8.705413 7.5 7.5\n",
      "7.36313 7.5 10.0\n",
      "8.466101 7.5 10.0\n",
      "7.400836 7.5 10.0\n",
      "7.8765554 7.5 7.5\n",
      "7.7707906 7.5 5.0\n",
      "6.338151 7.5 5.0\n",
      "6.449645 7.5 7.5\n",
      "6.7081747 7.5 5.0\n",
      "6.397057 7.5 7.5\n",
      "6.9551578 7.5 10.0\n",
      "9.258585 10 10.0\n",
      "8.364756 7.5 10.0\n",
      "7.536412 7.5 7.5\n",
      "7.2656803 7.5 7.5\n",
      "7.810284 7.5 10.0\n",
      "7.5170255 7.5 7.5\n",
      "7.2494063 7.5 10.0\n",
      "7.197843 7.5 7.5\n",
      "7.7980466 7.5 10.0\n",
      "6.504983 7.5 2.5\n",
      "9.44681 10 10.0\n",
      "4.16425 5 2.5\n",
      "7.66822 7.5 7.5\n",
      "5.1666336 5 7.5\n",
      "6.283653 7.5 7.5\n",
      "8.754262 10 7.5\n",
      "7.1499963 7.5 7.5\n",
      "5.7567387 5 2.5\n",
      "6.232669 5 5.0\n",
      "8.56062 7.5 10.0\n",
      "7.4789815 7.5 10.0\n",
      "7.169029 7.5 2.5\n",
      "7.0149016 7.5 7.5\n",
      "5.8781085 5 7.5\n",
      "9.148239 10 7.5\n",
      "8.4042015 7.5 7.5\n",
      "7.6319895 7.5 10.0\n",
      "7.684509 7.5 10.0\n",
      "6.562287 7.5 7.5\n",
      "7.7269554 7.5 10.0\n",
      "8.871754 10 10.0\n",
      "7.497858 7.5 5.0\n",
      "8.635564 7.5 7.5\n",
      "7.614476 7.5 5.0\n",
      "8.73728 7.5 7.5\n",
      "7.680233 7.5 7.5\n",
      "7.3038306 7.5 5.0\n",
      "6.51153 7.5 2.5\n",
      "7.249142 7.5 5.0\n",
      "5.9831886 5 7.5\n",
      "9.194047 10 5.0\n",
      "6.564926 7.5 7.5\n",
      "7.376843 7.5 7.5\n",
      "6.883712 7.5 5.0\n",
      "7.2710114 7.5 7.5\n",
      "6.5180864 7.5 7.5\n",
      "6.8026314 7.5 7.5\n",
      "7.9298987 7.5 7.5\n",
      "5.750521 5 7.5\n",
      "3.5695658 2.5 0.0\n",
      "7.1151724 7.5 7.5\n",
      "6.5837936 7.5 7.5\n",
      "8.670176 7.5 7.5\n",
      "8.762258 10 10.0\n",
      "7.7187757 7.5 2.5\n",
      "7.1892815 7.5 7.5\n",
      "9.041867 10 10.0\n",
      "7.552977 7.5 7.5\n",
      "7.5985346 7.5 10.0\n",
      "9.450669 10 10.0\n",
      "5.1497116 5 7.5\n",
      "7.0983987 7.5 10.0\n",
      "7.4697337 7.5 7.5\n",
      "8.99073 10 10.0\n",
      "7.088537 7.5 7.5\n",
      "7.4016585 7.5 7.5\n",
      "5.7633333 5 7.5\n",
      "9.429383 10 10.0\n",
      "6.74521 7.5 7.5\n",
      "8.124723 7.5 7.5\n",
      "5.767807 5 0.0\n",
      "8.250881 7.5 7.5\n",
      "9.027729 10 7.5\n",
      "7.931411 7.5 10.0\n",
      "4.4305305 5 0.0\n",
      "7.7821355 7.5 10.0\n",
      "8.188417 7.5 10.0\n",
      "6.294384 7.5 7.5\n",
      "7.5833473 7.5 7.5\n",
      "8.190156 7.5 7.5\n",
      "7.5552173 7.5 2.5\n",
      "5.401988 5 10.0\n",
      "8.687737 7.5 7.5\n",
      "7.3829203 7.5 7.5\n",
      "4.9184823 5 7.5\n",
      "4.795736 5 10.0\n",
      "8.450025 7.5 7.5\n",
      "6.302373 7.5 10.0\n",
      "7.9600043 7.5 10.0\n",
      "7.285608 7.5 2.5\n",
      "7.430115 7.5 7.5\n",
      "8.461951 7.5 10.0\n",
      "8.900803 10 10.0\n",
      "9.764553 10 10.0\n",
      "7.173943 7.5 10.0\n",
      "7.2012124 7.5 5.0\n",
      "9.271759 10 10.0\n",
      "8.847291 10 10.0\n",
      "7.331409 7.5 7.5\n",
      "7.6099057 7.5 7.5\n",
      "6.362331 7.5 7.5\n",
      "6.9939804 7.5 2.5\n",
      "7.1794066 7.5 10.0\n",
      "8.91889 10 10.0\n",
      "7.495342 7.5 10.0\n",
      "5.962276 5 7.5\n",
      "6.79363 7.5 7.5\n",
      "7.3363185 7.5 10.0\n",
      "6.842632 7.5 5.0\n",
      "9.456772 10 2.5\n",
      "7.6076565 7.5 7.5\n",
      "8.131601 7.5 7.5\n",
      "5.491631 5 2.5\n",
      "8.915633 10 7.5\n",
      "7.686285 7.5 7.5\n",
      "9.151863 10 7.5\n",
      "6.7845774 7.5 7.5\n",
      "6.9657335 7.5 7.5\n",
      "6.9048076 7.5 7.5\n",
      "7.1704164 7.5 7.5\n",
      "6.575851 7.5 7.5\n",
      "8.08417 7.5 10.0\n",
      "8.502848 7.5 10.0\n",
      "6.927402 7.5 10.0\n",
      "7.3492827 7.5 5.0\n",
      "8.512946 7.5 7.5\n",
      "8.936766 10 10.0\n",
      "8.954133 10 10.0\n",
      "8.521378 7.5 7.5\n",
      "7.0609393 7.5 7.5\n",
      "7.061174 7.5 7.5\n",
      "8.530084 7.5 7.5\n",
      "7.4564056 7.5 5.0\n",
      "7.1120663 7.5 7.5\n",
      "9.085295 10 10.0\n",
      "9.576993 10 10.0\n",
      "9.058344 10 2.5\n",
      "6.1162314 5 7.5\n",
      "7.615408 7.5 2.5\n",
      "6.636728 7.5 10.0\n",
      "7.300126 7.5 7.5\n",
      "7.492826 7.5 7.5\n",
      "7.9226766 7.5 10.0\n",
      "9.098399 10 10.0\n",
      "7.315274 7.5 7.5\n",
      "7.2308707 7.5 10.0\n",
      "8.218155 7.5 7.5\n",
      "8.825605 10 10.0\n",
      "9.131255 10 10.0\n",
      "6.3436623 7.5 0.0\n",
      "7.1296115 7.5 10.0\n",
      "6.2182455 5 10.0\n",
      "7.571516 7.5 7.5\n",
      "7.8731775 7.5 10.0\n",
      "6.3650527 7.5 10.0\n",
      "7.4471903 7.5 5.0\n",
      "7.588214 7.5 10.0\n",
      "6.9339223 7.5 5.0\n",
      "7.271678 7.5 7.5\n",
      "8.605566 7.5 10.0\n",
      "6.868173 7.5 7.5\n",
      "8.517467 7.5 7.5\n",
      "6.343595 7.5 10.0\n",
      "7.0638437 7.5 7.5\n",
      "9.584772 10 10.0\n",
      "5.2647486 5 5.0\n",
      "7.063435 7.5 2.5\n",
      "7.6944933 7.5 7.5\n",
      "6.9750166 7.5 2.5\n",
      "7.5036335 7.5 10.0\n",
      "8.626322 7.5 7.5\n",
      "7.160359 7.5 7.5\n",
      "6.7259126 7.5 2.5\n",
      "8.633618 7.5 10.0\n",
      "7.1803737 7.5 10.0\n",
      "8.456575 7.5 7.5\n",
      "8.528995 7.5 10.0\n",
      "6.9848337 7.5 10.0\n",
      "8.582359 7.5 10.0\n",
      "7.6636477 7.5 5.0\n",
      "7.5601425 7.5 7.5\n"
     ]
    }
   ],
   "source": [
    "# for pred, clipped, actual in zip(xgb_preds, clipS(xgb_copy), y_test ):\n",
    "#     print (pred, clipped, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35883188889119\n"
     ]
    }
   ],
   "source": [
    "print (mean_squared_error(y_test,clipS(xgb_preds))**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shrikar/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import theano\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)\n",
    "np.random.seed(123)  # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11202/11202 [==============================] - 2s 185us/step - loss: 41.4869\n",
      "Epoch 2/200\n",
      "11202/11202 [==============================] - 2s 178us/step - loss: 22.5995\n",
      "Epoch 3/200\n",
      "11202/11202 [==============================] - 2s 165us/step - loss: 12.4291\n",
      "Epoch 4/200\n",
      "11202/11202 [==============================] - 2s 158us/step - loss: 7.9893\n",
      "Epoch 5/200\n",
      "11202/11202 [==============================] - 1s 113us/step - loss: 6.6835\n",
      "Epoch 6/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4924\n",
      "Epoch 7/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4853\n",
      "Epoch 8/200\n",
      "11202/11202 [==============================] - 1s 120us/step - loss: 6.4852\n",
      "Epoch 9/200\n",
      "11202/11202 [==============================] - 1s 108us/step - loss: 6.4849\n",
      "Epoch 10/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4851\n",
      "Epoch 11/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4850\n",
      "Epoch 12/200\n",
      "11202/11202 [==============================] - 2s 159us/step - loss: 6.4851\n",
      "Epoch 13/200\n",
      "11202/11202 [==============================] - 2s 201us/step - loss: 6.4852\n",
      "Epoch 14/200\n",
      "11202/11202 [==============================] - 2s 184us/step - loss: 6.4849\n",
      "Epoch 15/200\n",
      "11202/11202 [==============================] - 2s 179us/step - loss: 6.4854\n",
      "Epoch 16/200\n",
      "11202/11202 [==============================] - 2s 175us/step - loss: 6.4855\n",
      "Epoch 17/200\n",
      "11202/11202 [==============================] - 2s 177us/step - loss: 6.4850\n",
      "Epoch 18/200\n",
      "11202/11202 [==============================] - 2s 175us/step - loss: 6.4849\n",
      "Epoch 19/200\n",
      "11202/11202 [==============================] - 2s 192us/step - loss: 6.4850\n",
      "Epoch 20/200\n",
      "11202/11202 [==============================] - 2s 186us/step - loss: 6.4851\n",
      "Epoch 21/200\n",
      "11202/11202 [==============================] - 2s 187us/step - loss: 6.4846\n",
      "Epoch 22/200\n",
      "11202/11202 [==============================] - 2s 179us/step - loss: 6.4850\n",
      "Epoch 23/200\n",
      "11202/11202 [==============================] - 2s 178us/step - loss: 6.4842\n",
      "Epoch 24/200\n",
      "11202/11202 [==============================] - 2s 203us/step - loss: 6.4853\n",
      "Epoch 25/200\n",
      "11202/11202 [==============================] - 1s 128us/step - loss: 6.4851\n",
      "Epoch 26/200\n",
      "11202/11202 [==============================] - 1s 111us/step - loss: 6.4850\n",
      "Epoch 27/200\n",
      "11202/11202 [==============================] - 1s 109us/step - loss: 6.4841\n",
      "Epoch 28/200\n",
      "11202/11202 [==============================] - 1s 114us/step - loss: 6.4857\n",
      "Epoch 29/200\n",
      "11202/11202 [==============================] - 2s 151us/step - loss: 6.4851\n",
      "Epoch 30/200\n",
      "11202/11202 [==============================] - 1s 119us/step - loss: 6.4850 0s - loss: \n",
      "Epoch 31/200\n",
      "11202/11202 [==============================] - 1s 133us/step - loss: 6.4846\n",
      "Epoch 32/200\n",
      "11202/11202 [==============================] - 2s 204us/step - loss: 6.4853\n",
      "Epoch 33/200\n",
      "11202/11202 [==============================] - 3s 223us/step - loss: 6.4853\n",
      "Epoch 34/200\n",
      "11202/11202 [==============================] - 2s 188us/step - loss: 6.4857\n",
      "Epoch 35/200\n",
      "11202/11202 [==============================] - 2s 172us/step - loss: 6.4852\n",
      "Epoch 36/200\n",
      "11202/11202 [==============================] - 2s 134us/step - loss: 6.4853\n",
      "Epoch 37/200\n",
      "11202/11202 [==============================] - 2s 153us/step - loss: 6.4850\n",
      "Epoch 38/200\n",
      "11202/11202 [==============================] - 1s 113us/step - loss: 6.4852\n",
      "Epoch 39/200\n",
      "11202/11202 [==============================] - 1s 112us/step - loss: 6.4849\n",
      "Epoch 40/200\n",
      "11202/11202 [==============================] - 1s 115us/step - loss: 6.4851\n",
      "Epoch 41/200\n",
      "11202/11202 [==============================] - 1s 110us/step - loss: 6.4855\n",
      "Epoch 42/200\n",
      "11202/11202 [==============================] - 1s 119us/step - loss: 6.4850\n",
      "Epoch 43/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4854\n",
      "Epoch 44/200\n",
      "11202/11202 [==============================] - 1s 109us/step - loss: 6.4856\n",
      "Epoch 45/200\n",
      "11202/11202 [==============================] - 1s 116us/step - loss: 6.4848\n",
      "Epoch 46/200\n",
      "11202/11202 [==============================] - 1s 123us/step - loss: 6.4850\n",
      "Epoch 47/200\n",
      "11202/11202 [==============================] - 1s 116us/step - loss: 6.4851\n",
      "Epoch 48/200\n",
      "11202/11202 [==============================] - 1s 120us/step - loss: 6.4850\n",
      "Epoch 49/200\n",
      "11202/11202 [==============================] - 1s 123us/step - loss: 6.4848\n",
      "Epoch 50/200\n",
      "11202/11202 [==============================] - 1s 127us/step - loss: 6.4851\n",
      "Epoch 51/200\n",
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4850\n",
      "Epoch 52/200\n",
      "11202/11202 [==============================] - 1s 124us/step - loss: 6.4846\n",
      "Epoch 53/200\n",
      "11202/11202 [==============================] - 2s 154us/step - loss: 6.4852\n",
      "Epoch 54/200\n",
      "11202/11202 [==============================] - 2s 143us/step - loss: 6.4848\n",
      "Epoch 55/200\n",
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4850\n",
      "Epoch 56/200\n",
      "11202/11202 [==============================] - 2s 154us/step - loss: 6.4852\n",
      "Epoch 57/200\n",
      "11202/11202 [==============================] - 2s 143us/step - loss: 6.4852\n",
      "Epoch 58/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4851\n",
      "Epoch 59/200\n",
      "11202/11202 [==============================] - 1s 134us/step - loss: 6.4852\n",
      "Epoch 60/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4854\n",
      "Epoch 61/200\n",
      "11202/11202 [==============================] - 2s 148us/step - loss: 6.4852\n",
      "Epoch 62/200\n",
      "11202/11202 [==============================] - 2s 144us/step - loss: 6.4853\n",
      "Epoch 63/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4853\n",
      "Epoch 64/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4854\n",
      "Epoch 65/200\n",
      "11202/11202 [==============================] - 1s 121us/step - loss: 6.4850\n",
      "Epoch 66/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4850\n",
      "Epoch 67/200\n",
      "11202/11202 [==============================] - 1s 132us/step - loss: 6.4848\n",
      "Epoch 68/200\n",
      "11202/11202 [==============================] - 2s 207us/step - loss: 6.4851\n",
      "Epoch 69/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4846\n",
      "Epoch 70/200\n",
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4847\n",
      "Epoch 71/200\n",
      "11202/11202 [==============================] - 1s 121us/step - loss: 6.4850\n",
      "Epoch 72/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4851\n",
      "Epoch 73/200\n",
      "11202/11202 [==============================] - 1s 129us/step - loss: 6.4850\n",
      "Epoch 74/200\n",
      "11202/11202 [==============================] - 1s 129us/step - loss: 6.4853\n",
      "Epoch 75/200\n",
      "11202/11202 [==============================] - 1s 127us/step - loss: 6.4848\n",
      "Epoch 76/200\n",
      "11202/11202 [==============================] - 1s 121us/step - loss: 6.4847\n",
      "Epoch 77/200\n",
      "11202/11202 [==============================] - 1s 132us/step - loss: 6.4841\n",
      "Epoch 78/200\n",
      "11202/11202 [==============================] - 1s 112us/step - loss: 6.4854\n",
      "Epoch 79/200\n",
      "11202/11202 [==============================] - 1s 118us/step - loss: 6.4846\n",
      "Epoch 80/200\n",
      "11202/11202 [==============================] - 1s 134us/step - loss: 6.4845\n",
      "Epoch 81/200\n",
      "11202/11202 [==============================] - 1s 130us/step - loss: 6.4853\n",
      "Epoch 82/200\n",
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4848\n",
      "Epoch 83/200\n",
      "11202/11202 [==============================] - 1s 127us/step - loss: 6.4850\n",
      "Epoch 84/200\n",
      "11202/11202 [==============================] - 1s 129us/step - loss: 6.4851\n",
      "Epoch 85/200\n",
      "11202/11202 [==============================] - 1s 119us/step - loss: 6.4851\n",
      "Epoch 86/200\n",
      "11202/11202 [==============================] - 1s 126us/step - loss: 6.4852\n",
      "Epoch 87/200\n",
      "11202/11202 [==============================] - 1s 124us/step - loss: 6.4850\n",
      "Epoch 88/200\n",
      "11202/11202 [==============================] - 1s 126us/step - loss: 6.4849\n",
      "Epoch 89/200\n",
      "11202/11202 [==============================] - 1s 133us/step - loss: 6.4849\n",
      "Epoch 90/200\n",
      "11202/11202 [==============================] - 1s 114us/step - loss: 6.4849\n",
      "Epoch 91/200\n",
      "11202/11202 [==============================] - 2s 139us/step - loss: 6.4851\n",
      "Epoch 92/200\n",
      "11202/11202 [==============================] - 1s 119us/step - loss: 6.4854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "11202/11202 [==============================] - 1s 133us/step - loss: 6.4853\n",
      "Epoch 94/200\n",
      "11202/11202 [==============================] - 1s 115us/step - loss: 6.4850\n",
      "Epoch 95/200\n",
      "11202/11202 [==============================] - 1s 108us/step - loss: 6.4843\n",
      "Epoch 96/200\n",
      "11202/11202 [==============================] - 1s 116us/step - loss: 6.4840\n",
      "Epoch 97/200\n",
      "11202/11202 [==============================] - 1s 109us/step - loss: 6.4848\n",
      "Epoch 98/200\n",
      "11202/11202 [==============================] - 1s 130us/step - loss: 6.4852\n",
      "Epoch 99/200\n",
      "11202/11202 [==============================] - 2s 149us/step - loss: 6.4845\n",
      "Epoch 100/200\n",
      "11202/11202 [==============================] - 2s 171us/step - loss: 6.4856\n",
      "Epoch 101/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4848\n",
      "Epoch 102/200\n",
      "11202/11202 [==============================] - 2s 175us/step - loss: 6.4850\n",
      "Epoch 103/200\n",
      "11202/11202 [==============================] - 1s 129us/step - loss: 6.4841\n",
      "Epoch 104/200\n",
      "11202/11202 [==============================] - 2s 135us/step - loss: 6.4848\n",
      "Epoch 105/200\n",
      "11202/11202 [==============================] - 1s 133us/step - loss: 6.4849\n",
      "Epoch 106/200\n",
      "11202/11202 [==============================] - 1s 111us/step - loss: 6.4853\n",
      "Epoch 107/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4850\n",
      "Epoch 108/200\n",
      "11202/11202 [==============================] - 1s 108us/step - loss: 6.4850\n",
      "Epoch 109/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4852\n",
      "Epoch 110/200\n",
      "11202/11202 [==============================] - 1s 114us/step - loss: 6.4852\n",
      "Epoch 111/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4851\n",
      "Epoch 112/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4850\n",
      "Epoch 113/200\n",
      "11202/11202 [==============================] - 1s 111us/step - loss: 6.4852\n",
      "Epoch 114/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4850\n",
      "Epoch 115/200\n",
      "11202/11202 [==============================] - 1s 105us/step - loss: 6.4853\n",
      "Epoch 116/200\n",
      "11202/11202 [==============================] - 1s 108us/step - loss: 6.4846\n",
      "Epoch 117/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4852\n",
      "Epoch 118/200\n",
      "11202/11202 [==============================] - 2s 134us/step - loss: 6.4848\n",
      "Epoch 119/200\n",
      "11202/11202 [==============================] - 1s 114us/step - loss: 6.4852\n",
      "Epoch 120/200\n",
      "11202/11202 [==============================] - 1s 113us/step - loss: 6.4852\n",
      "Epoch 121/200\n",
      "11202/11202 [==============================] - 1s 112us/step - loss: 6.4847\n",
      "Epoch 122/200\n",
      "11202/11202 [==============================] - 1s 110us/step - loss: 6.4853\n",
      "Epoch 123/200\n",
      "11202/11202 [==============================] - 1s 113us/step - loss: 6.4851\n",
      "Epoch 124/200\n",
      "11202/11202 [==============================] - 1s 120us/step - loss: 6.4853\n",
      "Epoch 125/200\n",
      "11202/11202 [==============================] - 1s 130us/step - loss: 6.4851\n",
      "Epoch 126/200\n",
      "11202/11202 [==============================] - 1s 111us/step - loss: 6.4852\n",
      "Epoch 127/200\n",
      "11202/11202 [==============================] - 1s 116us/step - loss: 6.4849\n",
      "Epoch 128/200\n",
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4848\n",
      "Epoch 129/200\n",
      "11202/11202 [==============================] - ETA: 0s - loss: 6.480 - 1s 122us/step - loss: 6.4850\n",
      "Epoch 130/200\n",
      "11202/11202 [==============================] - 2s 169us/step - loss: 6.4841\n",
      "Epoch 131/200\n",
      "11202/11202 [==============================] - 1s 128us/step - loss: 6.4848\n",
      "Epoch 132/200\n",
      "11202/11202 [==============================] - 2s 174us/step - loss: 6.4842\n",
      "Epoch 133/200\n",
      "11202/11202 [==============================] - 1s 112us/step - loss: 6.4851\n",
      "Epoch 134/200\n",
      "11202/11202 [==============================] - 1s 115us/step - loss: 6.4849\n",
      "Epoch 135/200\n",
      "11202/11202 [==============================] - 1s 130us/step - loss: 6.4843\n",
      "Epoch 136/200\n",
      "11202/11202 [==============================] - 2s 147us/step - loss: 6.4851\n",
      "Epoch 137/200\n",
      "11202/11202 [==============================] - 1s 121us/step - loss: 6.4852\n",
      "Epoch 138/200\n",
      "11202/11202 [==============================] - 2s 176us/step - loss: 6.4843\n",
      "Epoch 139/200\n",
      "11202/11202 [==============================] - 2s 158us/step - loss: 6.4853\n",
      "Epoch 140/200\n",
      "11202/11202 [==============================] - 2s 146us/step - loss: 6.4849\n",
      "Epoch 141/200\n",
      "11202/11202 [==============================] - 1s 118us/step - loss: 6.4846\n",
      "Epoch 142/200\n",
      "11202/11202 [==============================] - 1s 112us/step - loss: 6.4846\n",
      "Epoch 143/200\n",
      "11202/11202 [==============================] - 1s 123us/step - loss: 6.4850\n",
      "Epoch 144/200\n",
      "11202/11202 [==============================] - 2s 166us/step - loss: 6.4850\n",
      "Epoch 145/200\n",
      "11202/11202 [==============================] - 1s 113us/step - loss: 6.4850\n",
      "Epoch 146/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4843\n",
      "Epoch 147/200\n",
      "11202/11202 [==============================] - 1s 107us/step - loss: 6.4841\n",
      "Epoch 148/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4850\n",
      "Epoch 149/200\n",
      "11202/11202 [==============================] - 1s 105us/step - loss: 6.4842\n",
      "Epoch 150/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4852\n",
      "Epoch 151/200\n",
      "11202/11202 [==============================] - 1s 109us/step - loss: 6.4847\n",
      "Epoch 152/200\n",
      "11202/11202 [==============================] - 1s 105us/step - loss: 6.4852\n",
      "Epoch 153/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4850\n",
      "Epoch 154/200\n",
      "11202/11202 [==============================] - 1s 105us/step - loss: 6.4847\n",
      "Epoch 155/200\n",
      "11202/11202 [==============================] - 1s 123us/step - loss: 6.4839\n",
      "Epoch 156/200\n",
      "11202/11202 [==============================] - 2s 139us/step - loss: 6.4857\n",
      "Epoch 157/200\n",
      "11202/11202 [==============================] - 1s 105us/step - loss: 6.4849\n",
      "Epoch 158/200\n",
      "11202/11202 [==============================] - 1s 109us/step - loss: 6.4851\n",
      "Epoch 159/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4850\n",
      "Epoch 160/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4852\n",
      "Epoch 161/200\n",
      "11202/11202 [==============================] - 1s 115us/step - loss: 6.4848\n",
      "Epoch 162/200\n",
      "11202/11202 [==============================] - 1s 106us/step - loss: 6.4852\n",
      "Epoch 163/200\n",
      "11202/11202 [==============================] - 1s 128us/step - loss: 6.4853\n",
      "Epoch 164/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4845\n",
      "Epoch 165/200\n",
      "11202/11202 [==============================] - 2s 150us/step - loss: 6.4845\n",
      "Epoch 166/200\n",
      "11202/11202 [==============================] - 2s 172us/step - loss: 6.4847\n",
      "Epoch 167/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4854\n",
      "Epoch 168/200\n",
      "11202/11202 [==============================] - 2s 158us/step - loss: 6.4850\n",
      "Epoch 169/200\n",
      "11202/11202 [==============================] - 2s 134us/step - loss: 6.4852\n",
      "Epoch 170/200\n",
      "11202/11202 [==============================] - 1s 133us/step - loss: 6.4851\n",
      "Epoch 171/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4849\n",
      "Epoch 172/200\n",
      "11202/11202 [==============================] - 2s 146us/step - loss: 6.4852\n",
      "Epoch 173/200\n",
      "11202/11202 [==============================] - 1s 116us/step - loss: 6.4851\n",
      "Epoch 174/200\n",
      "11202/11202 [==============================] - 2s 161us/step - loss: 6.4847\n",
      "Epoch 175/200\n",
      "11202/11202 [==============================] - 2s 138us/step - loss: 6.4851\n",
      "Epoch 176/200\n",
      "11202/11202 [==============================] - 2s 139us/step - loss: 6.4850\n",
      "Epoch 177/200\n",
      "11202/11202 [==============================] - 1s 124us/step - loss: 6.4849\n",
      "Epoch 178/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4841\n",
      "Epoch 179/200\n",
      "11202/11202 [==============================] - 1s 129us/step - loss: 6.4852\n",
      "Epoch 180/200\n",
      "11202/11202 [==============================] - 1s 131us/step - loss: 6.4849\n",
      "Epoch 181/200\n",
      "11202/11202 [==============================] - 1s 124us/step - loss: 6.4849\n",
      "Epoch 182/200\n",
      "11202/11202 [==============================] - 1s 119us/step - loss: 6.4851\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11202/11202 [==============================] - 1s 122us/step - loss: 6.4849\n",
      "Epoch 184/200\n",
      "11202/11202 [==============================] - 1s 128us/step - loss: 6.4849\n",
      "Epoch 185/200\n",
      "11202/11202 [==============================] - 1s 125us/step - loss: 6.4851\n",
      "Epoch 186/200\n",
      "11202/11202 [==============================] - 2s 138us/step - loss: 6.4842\n",
      "Epoch 187/200\n",
      "11202/11202 [==============================] - 2s 136us/step - loss: 6.4849\n",
      "Epoch 188/200\n",
      "11202/11202 [==============================] - 2s 140us/step - loss: 6.4843\n",
      "Epoch 189/200\n",
      "11202/11202 [==============================] - 2s 159us/step - loss: 6.4849\n",
      "Epoch 190/200\n",
      "11202/11202 [==============================] - 2s 163us/step - loss: 6.4851\n",
      "Epoch 191/200\n",
      "11202/11202 [==============================] - 2s 157us/step - loss: 6.4847\n",
      "Epoch 192/200\n",
      "11202/11202 [==============================] - 1s 114us/step - loss: 6.4853\n",
      "Epoch 193/200\n",
      "11202/11202 [==============================] - 1s 117us/step - loss: 6.4852\n",
      "Epoch 194/200\n",
      "11202/11202 [==============================] - 3s 251us/step - loss: 6.4846\n",
      "Epoch 195/200\n",
      "11202/11202 [==============================] - 2s 219us/step - loss: 6.4853\n",
      "Epoch 196/200\n",
      "11202/11202 [==============================] - 3s 282us/step - loss: 6.4853\n",
      "Epoch 197/200\n",
      "11202/11202 [==============================] - 2s 171us/step - loss: 6.4851\n",
      "Epoch 198/200\n",
      "11202/11202 [==============================] - 1s 127us/step - loss: 6.4853\n",
      "Epoch 199/200\n",
      "11202/11202 [==============================] - 1s 121us/step - loss: 6.4849\n",
      "Epoch 200/200\n",
      "11202/11202 [==============================] - 2s 151us/step - loss: 6.4849\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=4, activation='relu'))\n",
    "#model.add(Dense(200, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='hard_sigmoid'))\n",
    "#model.add(Dense(50, activation='hard_sigmoid'))\n",
    "#model.add(Dense(40, activation='sigmoid'))\n",
    "#model.add(Dense(10, activation='sigmoid'))\n",
    "#model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=.001))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=10)\n",
    "\n",
    "nn_preds = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-35-236c77614555>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mprint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmean_squared_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnn_preds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0;36m.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'nn_preds' is not defined"
     ]
    }
   ],
   "source": [
    "print (mean_squared_error(y_test,nn_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.918158279204034\n"
     ]
    }
   ],
   "source": [
    "print (mean_absolute_error(y_test,nn_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n",
      "Hello World!\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['C20D1B75A4164F2493A4698E035E1B98']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['C20D1B75A4164F2493A4698E035E1B98'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.FunctionDef object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, ...], cell_name='<ipython-input-10-f68cdd6908ba>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        result = <ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/home/shrikar/Documents/pythonStuff/dsfinalproject/<ipython-input-10-f68cdd6908ba> in <module>()\n     51 batch_size = [20,50,100] # add 5, 10, 20, 40, 60, 80, 100 etc\n     52 param_grid = dict(epochs=epochs, batch_size=batch_size, activation=activations )\n     53 \n     54 #gridSearch\n     55 grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, verbose = 1)\n---> 56 grid_result = grid.fit(X_test, y_test) \n     57 \n     58 \n     59 # summarize results\n     60 print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=1), X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method KFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X =              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns]\n        y = 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed May  2 00:53:55 2018\nPID: 6680                 Python 2.7.14: /home/shrikar/anaconda2/bin/python\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasRegressor object>, X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([1601, 1602, 1603, ..., 4799, 4800, 4801]), test=array([   0,    1,    2, ..., 1598, 1599, 1600]), verbose=1, parameters={'activation': 'relu', 'batch_size': 20, 'epochs': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method KerasRegressor.set_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        parameters = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in set_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, **params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n    108             **params: Dictionary of parameter names mapped to their values.\n    109 \n    110         # Returns\n    111             self\n    112         \"\"\"\n--> 113         self.check_params(params)\n        self.check_params = <bound method KerasRegressor.check_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        params = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    114         self.sk_params.update(params)\n    115         return self\n    116 \n    117     def fit(self, x, y, **kwargs):\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in check_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n     84                 if has_arg(fn, params_name):\n     85                     break\n     86             else:\n     87                 if params_name != 'nb_epoch':\n     88                     raise ValueError(\n---> 89                         '{} is not a legal parameter'.format(params_name))\n        params_name = 'activation'\n     90 \n     91     def get_params(self, **params):\n     92         \"\"\"Gets parameters for this estimator.\n     93 \n\nValueError: activation is not a legal parameter\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJoblibValueError\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-f68cdd6908ba>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;31m#gridSearch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[0mgrid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_grid\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 56\u001B[0;31m \u001B[0mgrid_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    637\u001B[0m                                   error_score=self.error_score)\n\u001B[1;32m    638\u001B[0m           for parameters, (train, test) in product(candidate_params,\n\u001B[0;32m--> 639\u001B[0;31m                                                    cv.split(X, y, groups)))\n\u001B[0m\u001B[1;32m    640\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    641\u001B[0m         \u001B[0;31m# if one choose to see train score, \"out\" will contain train score info\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m    787\u001B[0m                 \u001B[0;31m# consumption.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    788\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 789\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    790\u001B[0m             \u001B[0;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    791\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001B[0m in \u001B[0;36mretrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    738\u001B[0m                     \u001B[0mexception\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexception_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreport\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    739\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 740\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mexception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    741\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    742\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mJoblibValueError\u001B[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['C20D1B75A4164F2493A4698E035E1B98']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['C20D1B75A4164F2493A4698E035E1B98'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.FunctionDef object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, ...], cell_name='<ipython-input-10-f68cdd6908ba>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        result = <ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/home/shrikar/Documents/pythonStuff/dsfinalproject/<ipython-input-10-f68cdd6908ba> in <module>()\n     51 batch_size = [20,50,100] # add 5, 10, 20, 40, 60, 80, 100 etc\n     52 param_grid = dict(epochs=epochs, batch_size=batch_size, activation=activations )\n     53 \n     54 #gridSearch\n     55 grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, verbose = 1)\n---> 56 grid_result = grid.fit(X_test, y_test) \n     57 \n     58 \n     59 # summarize results\n     60 print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=1), X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method KFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X =              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns]\n        y = 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed May  2 00:53:55 2018\nPID: 6680                 Python 2.7.14: /home/shrikar/anaconda2/bin/python\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasRegressor object>, X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([1601, 1602, 1603, ..., 4799, 4800, 4801]), test=array([   0,    1,    2, ..., 1598, 1599, 1600]), verbose=1, parameters={'activation': 'relu', 'batch_size': 20, 'epochs': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method KerasRegressor.set_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        parameters = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in set_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, **params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n    108             **params: Dictionary of parameter names mapped to their values.\n    109 \n    110         # Returns\n    111             self\n    112         \"\"\"\n--> 113         self.check_params(params)\n        self.check_params = <bound method KerasRegressor.check_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        params = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    114         self.sk_params.update(params)\n    115         return self\n    116 \n    117     def fit(self, x, y, **kwargs):\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in check_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n     84                 if has_arg(fn, params_name):\n     85                     break\n     86             else:\n     87                 if params_name != 'nb_epoch':\n     88                     raise ValueError(\n---> 89                         '{} is not a legal parameter'.format(params_name))\n        params_name = 'activation'\n     90 \n     91     def get_params(self, **params):\n     92         \"\"\"Gets parameters for this estimator.\n     93 \n\nValueError: activation is not a legal parameter\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# Refer https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "# Refer https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# Aim of this is to show case use of keras and grid search libraries\n",
    "print(\"Hello World!\")\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "##############################################################\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(346, input_dim=346, activation='relu'))\n",
    "    model.add(Dense(200, activation=activation))\n",
    "    model.add(Dense(100, activation=activation))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "print(\"Hello World!\")\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=1)\n",
    "\n",
    "# Use scikit-learn to grid search \n",
    "#activation =  ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'softsign'] # softmax, softplus, softsign \n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "learn_rate = [.00001,.0001,0.001, 0.01, 0.1, 0.3]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "weight_constraint=[1, 2, 3, 4, 5]\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "init = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "optimizer = [ 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "\n",
    "# grid search epochs, batch size\n",
    "#learn_rate = [.00001,.0001, 0.001]\n",
    "activations =  ['relu', 'hard_sigmoid', 'softsign'] # softmax, softplus, softsign \n",
    "#dropout_rate = [0.0, 0.3, 0.7,]\n",
    "epochs = [1, 10,50,150] # add 50, 100, 150 etc\n",
    "batch_size = [20,50,100] # add 5, 10, 20, 40, 60, 80, 100 etc\n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size, activation=activations )\n",
    "\n",
    "#gridSearch\n",
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, verbose = 1)\n",
    "grid_result = grid.fit(X_test, y_test) \n",
    "\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-52-4157204f298c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mprint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mgrid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_params_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mngrid_preds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mprint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmean_squared_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mngrid_preds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0;36m.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'grid' is not defined"
     ]
    }
   ],
   "source": [
    "print (grid.best_params_)\n",
    "ngrid_preds = grid.predict(X_test)\n",
    "print (mean_squared_error(y_test,ngrid_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1.1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=1.1, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=1.1, total=   1.2s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=1.1, total=   1.2s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=1e-05, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=1e-05, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=1e-05, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=100, epsilon=2, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=100, epsilon=2, total=   1.1s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=100, epsilon=2, total=   1.5s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=1000, epsilon=2, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=1000, epsilon=2, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=1000, epsilon=2, total=   2.2s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10000, epsilon=2, total=   1.6s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10000, epsilon=2, total=   2.2s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=1e-05, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=100, epsilon=10, total=   1.4s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=100, epsilon=10, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=1000, epsilon=10, total=   1.6s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=1000, epsilon=10, total=   3.2s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=1000, epsilon=10, total=   1.6s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10000, epsilon=10, total=   1.9s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10000, epsilon=10, total=   4.2s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10000, epsilon=10, total=   1.2s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1e-05, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=100, epsilon=100, total=   1.4s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=100, total=   1.5s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=100, total=   4.0s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=1000, epsilon=100, total=   1.6s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=100, total=   2.0s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=100, total=   4.1s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=10000, epsilon=100, total=   1.6s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1e-05, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=100, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=100, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=100, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=1000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=1000, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=1000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=1e-05, max_iter=10000, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=1e-05, max_iter=10000, epsilon=1000, total=   1.9s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=1000 .......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=1e-05, max_iter=10000, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1e-05, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=1e-05, max_iter=10, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=100, epsilon=10000, total=   1.7s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=100, epsilon=10000, total=   2.3s\n",
      "[CV] alpha=1e-05, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1e-05, max_iter=100, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1e-05, max_iter=1000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1e-05, max_iter=1000, epsilon=10000, total=   3.0s\n",
      "[CV] alpha=1e-05, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1e-05, max_iter=1000, epsilon=10000, total=   2.0s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=1e-05, max_iter=10000, epsilon=10000, total=   1.7s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=1e-05, max_iter=10000, epsilon=10000, total=   1.8s\n",
      "[CV] alpha=1e-05, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=1e-05, max_iter=10000, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=1.1, total=   0.2s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=1.1, total=   1.6s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=1.1, total=   1.4s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1.1 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1.1 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1.1 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=1.1, total=   1.5s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.0001, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.0001, max_iter=10, epsilon=2, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.0001, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=100, epsilon=2, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=100, epsilon=2, total=   1.9s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=100, epsilon=2, total=   1.4s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=1000, epsilon=2, total=   2.3s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=1000, epsilon=2, total=   1.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=2 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=2 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10000, epsilon=2, total=   3.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=2 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10000, epsilon=2, total=   1.2s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.0001, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=100, epsilon=10, total=   1.7s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=100, epsilon=10, total=   1.4s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=100, epsilon=10, total=   1.1s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=1000, epsilon=10, total=   1.9s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=1000, epsilon=10, total=   2.7s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=1000, epsilon=10, total=   2.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10000, epsilon=10, total=   2.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10000, epsilon=10, total=   3.6s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.0001, max_iter=10, epsilon=100, total=   0.6s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=100, total=   2.6s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=100, epsilon=100, total=   1.9s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=100, total=   1.7s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=1000, epsilon=100, total=   3.8s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=100 .......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=100, total=   1.7s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=100 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=100 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=10000, epsilon=100, total=   2.8s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10, epsilon=1000, total=   0.6s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10, epsilon=1000, total=   0.7s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.0001, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=100, epsilon=1000, total=   2.8s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=100, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=100, epsilon=1000, total=   2.4s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=1000, epsilon=1000, total=   2.2s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=1000, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=1000, epsilon=1000, total=   1.9s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=10000, epsilon=1000, total=   2.4s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=10000, epsilon=1000, total=   1.1s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=1000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=10000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.0001, max_iter=10, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.0001, max_iter=10, epsilon=10000, total=   0.5s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=100, epsilon=10000, total=   1.7s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=100, epsilon=10000, total=   1.8s\n",
      "[CV] alpha=0.0001, max_iter=100, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.0001, max_iter=100, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=1000, epsilon=10000, total=   3.5s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=1000, epsilon=10000, total=   3.5s\n",
      "[CV] alpha=0.0001, max_iter=1000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.0001, max_iter=1000, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10000 .....................\n",
      "[CV] ...... alpha=0.0001, max_iter=10000, epsilon=10000, total=   2.2s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10000 .....................\n",
      "[CV] ...... alpha=0.0001, max_iter=10000, epsilon=10000, total=   2.0s\n",
      "[CV] alpha=0.0001, max_iter=10000, epsilon=10000 .....................\n",
      "[CV] ...... alpha=0.0001, max_iter=10000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=1.1, total=   2.1s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=1.1, total=   1.6s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1.1 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=1.1, total=   1.7s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.001, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.001, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.001, max_iter=10, epsilon=2, total=   0.2s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=100, epsilon=2, total=   0.7s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=100, epsilon=2, total=   1.7s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=100, epsilon=2, total=   1.9s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=1000, epsilon=2, total=   1.8s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=1000, epsilon=2, total=   2.7s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10000, epsilon=2, total=   1.7s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=2 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10000, epsilon=2, total=   2.6s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.001, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=100, epsilon=10, total=   1.2s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=1000, epsilon=10, total=   3.2s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10 ..........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... alpha=0.001, max_iter=1000, epsilon=10, total=   2.1s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=1000, epsilon=10, total=   1.3s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10000, epsilon=10, total=   3.5s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10000, epsilon=10, total=   2.5s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10000, epsilon=10, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.001, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=100, epsilon=100, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=100, total=   1.7s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=1000, epsilon=100, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=100, total=   1.6s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=100 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=10000, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.001, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=100, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=100, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=100, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=1000, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=1000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=1000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=10000, epsilon=1000, total=   1.5s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=10000, epsilon=1000, total=   1.9s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=1000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=10000, epsilon=1000, total=   1.9s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=10, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.001, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=100, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=100, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=0.001, max_iter=100, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.001, max_iter=100, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=1000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=1000, epsilon=10000, total=   2.2s\n",
      "[CV] alpha=0.001, max_iter=1000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.001, max_iter=1000, epsilon=10000, total=   0.7s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.001, max_iter=10000, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.001, max_iter=10000, epsilon=10000, total=   2.0s\n",
      "[CV] alpha=0.001, max_iter=10000, epsilon=10000 ......................\n",
      "[CV] ....... alpha=0.001, max_iter=10000, epsilon=10000, total=   1.1s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=1.1, total=   1.8s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=1.1, total=   0.9s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=1.1, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=1.1, total=   2.9s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.01, max_iter=10, epsilon=2, total=   0.2s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.01, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.01, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.01, max_iter=100, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.01, max_iter=100, epsilon=2, total=   2.2s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=2 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=0.01, max_iter=100, epsilon=2, total=   1.9s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=1000, epsilon=2, total=   1.7s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=1000, epsilon=2, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10000, epsilon=2, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10000, epsilon=2, total=   1.2s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10000, epsilon=2, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.01, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.01, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.01, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=100, epsilon=10, total=   1.3s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=100, epsilon=10, total=   1.7s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=100, epsilon=10, total=   1.0s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=1000, epsilon=10, total=   2.0s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=1000, epsilon=10, total=   1.6s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=1000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10000, epsilon=10, total=   2.0s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10000, epsilon=10, total=   1.6s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10000, epsilon=10, total=   1.0s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.01, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=100, epsilon=100, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=100, total=   1.7s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=100, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=1000, epsilon=100, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=100, total=   1.8s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=100, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=10000, epsilon=100, total=   2.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10, epsilon=1000, total=   0.5s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.01, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=100, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=100, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=100, epsilon=1000, total=   1.6s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=1000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=1000, epsilon=1000, total=   1.1s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=1000, epsilon=1000, total=   2.1s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=10000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=10000, epsilon=1000, total=   1.1s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=10000, epsilon=1000, total=   2.1s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.01, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=100, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=100, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=100, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.01, max_iter=100, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=1000, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=1000, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.01, max_iter=1000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.01, max_iter=10000, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.01, max_iter=10000, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=0.01, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=0.01, max_iter=10000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1.1 ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=1.1, total=   0.9s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=1.1, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=1.1, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=1.1, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=0.1, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=0.1, max_iter=10, epsilon=2, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=0.1, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=100, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=100, epsilon=2, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=100, epsilon=2, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=1000, epsilon=2, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=2 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=1000, epsilon=2, total=   1.7s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10000, epsilon=2, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10000, epsilon=2, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=0.1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=100, epsilon=10, total=   1.0s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=100, epsilon=10, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=1000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=1000, epsilon=10, total=   2.2s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=1000, epsilon=10, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=10000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=10000, epsilon=10, total=   2.4s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=10000, epsilon=10, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=0.1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=100, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=100, epsilon=100, total=   0.8s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=100, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=1000, epsilon=100, total=   0.8s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=100, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=100, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=10000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=0.1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=100, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=100, epsilon=1000, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=100, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=1000, epsilon=1000, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=1000, epsilon=1000, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=1000, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=10000, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=10000, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=10000, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10000 ...........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ alpha=0.1, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=0.1, max_iter=10, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=0.1, max_iter=10, epsilon=10000, total=   0.5s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=100, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=100, epsilon=10000, total=   1.6s\n",
      "[CV] alpha=0.1, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=0.1, max_iter=100, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=1000, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=1000, epsilon=10000, total=   3.4s\n",
      "[CV] alpha=0.1, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=0.1, max_iter=1000, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.1, max_iter=10000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.1, max_iter=10000, epsilon=10000, total=   3.0s\n",
      "[CV] alpha=0.1, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=0.1, max_iter=10000, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1.1 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1.1 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1.1 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=1.1, total=   1.7s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=1.1, total=   2.2s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1, max_iter=10000, epsilon=1.1, total=   0.9s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1, max_iter=10000, epsilon=1.1, total=   2.2s\n",
      "[CV] alpha=1, max_iter=10, epsilon=2 .................................\n",
      "[CV] .................. alpha=1, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1, max_iter=10, epsilon=2 .................................\n",
      "[CV] .................. alpha=1, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1, max_iter=10, epsilon=2 .................................\n",
      "[CV] .................. alpha=1, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1, max_iter=100, epsilon=2 ................................\n",
      "[CV] ................. alpha=1, max_iter=100, epsilon=2, total=   0.5s\n",
      "[CV] alpha=1, max_iter=100, epsilon=2 ................................\n",
      "[CV] ................. alpha=1, max_iter=100, epsilon=2, total=   1.5s\n",
      "[CV] alpha=1, max_iter=100, epsilon=2 ................................\n",
      "[CV] ................. alpha=1, max_iter=100, epsilon=2, total=   1.8s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=2 ...............................\n",
      "[CV] ................ alpha=1, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=2 ...............................\n",
      "[CV] ................ alpha=1, max_iter=1000, epsilon=2, total=   1.2s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=2 ...............................\n",
      "[CV] ................ alpha=1, max_iter=1000, epsilon=2, total=   2.3s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10000, epsilon=2, total=   1.3s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10000, epsilon=2, total=   2.1s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10 ................................\n",
      "[CV] ................. alpha=1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10 ................................\n",
      "[CV] ................. alpha=1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10 ................................\n",
      "[CV] ................. alpha=1, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10 ...............................\n",
      "[CV] ................ alpha=1, max_iter=100, epsilon=10, total=   1.2s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10 ...............................\n",
      "[CV] ................ alpha=1, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10 ...............................\n",
      "[CV] ................ alpha=1, max_iter=100, epsilon=10, total=   1.2s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10 ..............................\n",
      "[CV] ............... alpha=1, max_iter=1000, epsilon=10, total=   1.2s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10 ..............................\n",
      "[CV] ............... alpha=1, max_iter=1000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10 ..............................\n",
      "[CV] ............... alpha=1, max_iter=1000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10 .............................\n",
      "[CV] .............. alpha=1, max_iter=10000, epsilon=10, total=   1.2s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10 .............................\n",
      "[CV] .............. alpha=1, max_iter=10000, epsilon=10, total=   1.7s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10 .............................\n",
      "[CV] .............. alpha=1, max_iter=10000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=1, max_iter=10, epsilon=100 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=100 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=100 ...............................\n",
      "[CV] ................ alpha=1, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=1, max_iter=100, epsilon=100 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=100, total=   2.1s\n",
      "[CV] alpha=1, max_iter=100, epsilon=100 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=100, total=   3.2s\n",
      "[CV] alpha=1, max_iter=100, epsilon=100 ..............................\n",
      "[CV] ............... alpha=1, max_iter=100, epsilon=100, total=   2.2s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=100 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=100, total=   2.2s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=100 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=100, total=   1.8s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=100 .............................\n",
      "[CV] .............. alpha=1, max_iter=1000, epsilon=100, total=   1.7s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=100 ............................\n",
      "[CV] ............. alpha=1, max_iter=10000, epsilon=100, total=   1.8s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=100 ............................\n",
      "[CV] ............. alpha=1, max_iter=10000, epsilon=100, total=   1.8s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=100 ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=1, max_iter=10000, epsilon=100, total=   1.6s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1000 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1000 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=1000 ..............................\n",
      "[CV] ............... alpha=1, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1000 .............................\n",
      "[CV] .............. alpha=1, max_iter=100, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1000 .............................\n",
      "[CV] .............. alpha=1, max_iter=100, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=1, max_iter=100, epsilon=1000 .............................\n",
      "[CV] .............. alpha=1, max_iter=100, epsilon=1000, total=   1.7s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1000 ............................\n",
      "[CV] ............. alpha=1, max_iter=1000, epsilon=1000, total=   1.9s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1000 ............................\n",
      "[CV] ............. alpha=1, max_iter=1000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=1000 ............................\n",
      "[CV] ............. alpha=1, max_iter=1000, epsilon=1000, total=   2.1s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=10000, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=10000, epsilon=1000, total=   2.4s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=10000, epsilon=1000, total=   2.2s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10000 .............................\n",
      "[CV] .............. alpha=1, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10000 .............................\n",
      "[CV] .............. alpha=1, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=10, epsilon=10000 .............................\n",
      "[CV] .............. alpha=1, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10000 ............................\n",
      "[CV] ............. alpha=1, max_iter=100, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10000 ............................\n",
      "[CV] ............. alpha=1, max_iter=100, epsilon=10000, total=   1.8s\n",
      "[CV] alpha=1, max_iter=100, epsilon=10000 ............................\n",
      "[CV] ............. alpha=1, max_iter=100, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=1000, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=1000, epsilon=10000, total=   2.1s\n",
      "[CV] alpha=1, max_iter=1000, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=1, max_iter=1000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1, max_iter=10000, epsilon=10000, total=   1.2s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1, max_iter=10000, epsilon=10000, total=   2.1s\n",
      "[CV] alpha=1, max_iter=10000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1, max_iter=10000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1.1 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=1.1, total=   0.9s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10, epsilon=2 ................................\n",
      "[CV] ................. alpha=10, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=10, max_iter=10, epsilon=2 ................................\n",
      "[CV] ................. alpha=10, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=10, max_iter=10, epsilon=2 ................................\n",
      "[CV] ................. alpha=10, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=10, max_iter=100, epsilon=2 ...............................\n",
      "[CV] ................ alpha=10, max_iter=100, epsilon=2, total=   0.6s\n",
      "[CV] alpha=10, max_iter=100, epsilon=2 ...............................\n",
      "[CV] ................ alpha=10, max_iter=100, epsilon=2, total=   1.7s\n",
      "[CV] alpha=10, max_iter=100, epsilon=2 ...............................\n",
      "[CV] ................ alpha=10, max_iter=100, epsilon=2, total=   1.7s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=10, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=10, max_iter=1000, epsilon=2, total=   1.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=2 ..............................\n",
      "[CV] ............... alpha=10, max_iter=1000, epsilon=2, total=   1.8s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=2 .............................\n",
      "[CV] .............. alpha=10, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=2 .............................\n",
      "[CV] .............. alpha=10, max_iter=10000, epsilon=2, total=   1.7s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=2 .............................\n",
      "[CV] .............. alpha=10, max_iter=10000, epsilon=2, total=   1.8s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10 ...............................\n",
      "[CV] ................ alpha=10, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10 ...............................\n",
      "[CV] ................ alpha=10, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10 ...............................\n",
      "[CV] ................ alpha=10, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10 ..............................\n",
      "[CV] ............... alpha=10, max_iter=100, epsilon=10, total=   1.3s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10 ..............................\n",
      "[CV] ............... alpha=10, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10 ..............................\n",
      "[CV] ............... alpha=10, max_iter=100, epsilon=10, total=   1.1s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10 .............................\n",
      "[CV] .............. alpha=10, max_iter=1000, epsilon=10, total=   1.3s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10 .............................\n",
      "[CV] .............. alpha=10, max_iter=1000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10 .............................\n",
      "[CV] .............. alpha=10, max_iter=1000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10 ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=10, max_iter=10000, epsilon=10, total=   1.4s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10 ............................\n",
      "[CV] ............. alpha=10, max_iter=10000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10 ............................\n",
      "[CV] ............. alpha=10, max_iter=10000, epsilon=10, total=   1.1s\n",
      "[CV] alpha=10, max_iter=10, epsilon=100 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=100 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=100 ..............................\n",
      "[CV] ............... alpha=10, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=10, max_iter=100, epsilon=100 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=100, total=   1.0s\n",
      "[CV] alpha=10, max_iter=100, epsilon=100 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=100, total=   1.7s\n",
      "[CV] alpha=10, max_iter=100, epsilon=100 .............................\n",
      "[CV] .............. alpha=10, max_iter=100, epsilon=100, total=   0.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=100 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=100 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=100, total=   2.0s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=100 ............................\n",
      "[CV] ............. alpha=10, max_iter=1000, epsilon=100, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=100, total=   2.1s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=10, max_iter=10000, epsilon=100, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1000 .............................\n",
      "[CV] .............. alpha=10, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1000 .............................\n",
      "[CV] .............. alpha=10, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=1000 .............................\n",
      "[CV] .............. alpha=10, max_iter=10, epsilon=1000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1000 ............................\n",
      "[CV] ............. alpha=10, max_iter=100, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1000 ............................\n",
      "[CV] ............. alpha=10, max_iter=100, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=10, max_iter=100, epsilon=1000 ............................\n",
      "[CV] ............. alpha=10, max_iter=100, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=1000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=1000, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=1000, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=10000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=10000, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=10000, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10000 ............................\n",
      "[CV] ............. alpha=10, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10000 ............................\n",
      "[CV] ............. alpha=10, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=10, epsilon=10000 ............................\n",
      "[CV] ............. alpha=10, max_iter=10, epsilon=10000, total=   0.4s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=100, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=100, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=10, max_iter=100, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=10, max_iter=100, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=1000, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=1000, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=10, max_iter=1000, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=10, max_iter=1000, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=10, max_iter=10000, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=10, max_iter=10000, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=10, max_iter=10000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=10, max_iter=10000, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1.1 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=1.1, total=   0.3s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=1.1, total=   0.5s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=1.1, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=100, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=100, max_iter=10, epsilon=2, total=   0.4s\n",
      "[CV] alpha=100, max_iter=10, epsilon=2 ...............................\n",
      "[CV] ................ alpha=100, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=100, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=100, max_iter=100, epsilon=2, total=   0.5s\n",
      "[CV] alpha=100, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=100, max_iter=100, epsilon=2, total=   1.6s\n",
      "[CV] alpha=100, max_iter=100, epsilon=2 ..............................\n",
      "[CV] ............... alpha=100, max_iter=100, epsilon=2, total=   0.9s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=2 .............................\n",
      "[CV] .............. alpha=100, max_iter=1000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=2 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=100, max_iter=1000, epsilon=2, total=   1.5s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=2 .............................\n",
      "[CV] .............. alpha=100, max_iter=1000, epsilon=2, total=   0.9s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=100, max_iter=10000, epsilon=2, total=   0.5s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=100, max_iter=10000, epsilon=2, total=   1.5s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=2 ............................\n",
      "[CV] ............. alpha=100, max_iter=10000, epsilon=2, total=   0.9s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=100, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=100, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10 ..............................\n",
      "[CV] ............... alpha=100, max_iter=10, epsilon=10, total=   0.3s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=100, max_iter=100, epsilon=10, total=   1.5s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=100, max_iter=100, epsilon=10, total=   1.4s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10 .............................\n",
      "[CV] .............. alpha=100, max_iter=100, epsilon=10, total=   1.4s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=100, max_iter=1000, epsilon=10, total=   2.1s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=100, max_iter=1000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10 ............................\n",
      "[CV] ............. alpha=100, max_iter=1000, epsilon=10, total=   1.4s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10000, epsilon=10, total=   2.1s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10000, epsilon=10, total=   1.5s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10000, epsilon=10, total=   1.4s\n",
      "[CV] alpha=100, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=100, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=100, max_iter=10, epsilon=100 .............................\n",
      "[CV] .............. alpha=100, max_iter=10, epsilon=100, total=   0.4s\n",
      "[CV] alpha=100, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=100, total=   1.1s\n",
      "[CV] alpha=100, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=100, total=   1.8s\n",
      "[CV] alpha=100, max_iter=100, epsilon=100 ............................\n",
      "[CV] ............. alpha=100, max_iter=100, epsilon=100, total=   0.9s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=100, total=   1.6s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=100 ...........................\n",
      "[CV] ............ alpha=100, max_iter=1000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=100, total=   1.1s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=100, total=   1.4s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=100, max_iter=10000, epsilon=100, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=100, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=100, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=1000 ............................\n",
      "[CV] ............. alpha=100, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=100, epsilon=1000, total=   1.5s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=100, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=100, max_iter=100, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=100, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=1000, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=1000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=1000, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=100, max_iter=10000, epsilon=1000, total=   1.8s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=100, max_iter=10000, epsilon=1000, total=   1.3s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=100, max_iter=10000, epsilon=1000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=10, epsilon=10000 ...........................\n",
      "[CV] ............ alpha=100, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=100, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=100, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=100, max_iter=100, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=100, max_iter=100, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=100, max_iter=1000, epsilon=10000, total=   1.0s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=100, max_iter=1000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=100, max_iter=1000, epsilon=10000 .........................\n",
      "[CV] .......... alpha=100, max_iter=1000, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=100, max_iter=10000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=100, max_iter=10000, epsilon=10000, total=   0.9s\n",
      "[CV] alpha=100, max_iter=10000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=100, max_iter=10000, epsilon=10000, total=   0.8s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=1.1, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=1.1, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1.1 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=1.1, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=100, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1.1 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=100, epsilon=1.1, total=   1.2s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1.1 ...........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ alpha=1000, max_iter=100, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=1.1, total=   1.2s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1.1 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=1.1, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=1.1, total=   1.4s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1.1 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=1.1, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1000, max_iter=10, epsilon=2, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1000, max_iter=10, epsilon=2, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=2 ..............................\n",
      "[CV] ............... alpha=1000, max_iter=10, epsilon=2, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=2 .............................\n",
      "[CV] .............. alpha=1000, max_iter=100, epsilon=2, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=2 .............................\n",
      "[CV] .............. alpha=1000, max_iter=100, epsilon=2, total=   1.6s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=2 .............................\n",
      "[CV] .............. alpha=1000, max_iter=100, epsilon=2, total=   1.3s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=1000, max_iter=1000, epsilon=2, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=1000, max_iter=1000, epsilon=2, total=   1.6s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=2 ............................\n",
      "[CV] ............. alpha=1000, max_iter=1000, epsilon=2, total=   1.3s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10000, epsilon=2, total=   0.4s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10000, epsilon=2, total=   1.6s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=2 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10000, epsilon=2, total=   1.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=1000, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=1000, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10 .............................\n",
      "[CV] .............. alpha=1000, max_iter=10, epsilon=10, total=   0.2s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=1000, max_iter=100, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=1000, max_iter=100, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10 ............................\n",
      "[CV] ............. alpha=1000, max_iter=100, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=1000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=1000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=1000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10000, epsilon=10, total=   0.7s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=100 ............................\n",
      "[CV] ............. alpha=1000, max_iter=10, epsilon=100, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=100, epsilon=100, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=100, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=100 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=100, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=100, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=100 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=1000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=100, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=100 .........................\n",
      "[CV] .......... alpha=1000, max_iter=10000, epsilon=100, total=   0.9s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=1000 ...........................\n",
      "[CV] ............ alpha=1000, max_iter=10, epsilon=1000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=100, epsilon=1000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=100, epsilon=1000, total=   1.2s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=1000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=100, epsilon=1000, total=   1.4s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1000, max_iter=1000, epsilon=1000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1000, max_iter=1000, epsilon=1000, total=   1.1s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=1000 .........................\n",
      "[CV] .......... alpha=1000, max_iter=1000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=10000, epsilon=1000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=10000, epsilon=1000, total=   1.1s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=1000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=10000, epsilon=1000, total=   2.0s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=10, epsilon=10000 ..........................\n",
      "[CV] ........... alpha=1000, max_iter=10, epsilon=10000, total=   0.3s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10000 .........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... alpha=1000, max_iter=100, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10000 .........................\n",
      "[CV] .......... alpha=1000, max_iter=100, epsilon=10000, total=   1.1s\n",
      "[CV] alpha=1000, max_iter=100, epsilon=10000 .........................\n",
      "[CV] .......... alpha=1000, max_iter=100, epsilon=10000, total=   1.4s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=1000, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=1000, epsilon=10000, total=   1.1s\n",
      "[CV] alpha=1000, max_iter=1000, epsilon=10000 ........................\n",
      "[CV] ......... alpha=1000, max_iter=1000, epsilon=10000, total=   1.5s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1000, max_iter=10000, epsilon=10000, total=   0.6s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1000, max_iter=10000, epsilon=10000, total=   1.3s\n",
      "[CV] alpha=1000, max_iter=10000, epsilon=10000 .......................\n",
      "[CV] ........ alpha=1000, max_iter=10000, epsilon=10000, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 648 out of 648 | elapsed: 12.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.710401073583229\n"
     ]
    }
   ],
   "source": [
    "parameters = { #when use hyperthread, xgboost may become slower\n",
    "              'epsilon':[1.1,2,10,100,1000,10000],# dart is nice but far too slow\n",
    "              'max_iter':[10,100,1000,10000],\n",
    "              'alpha':[.00001,.0001,.001,.01,.1,1,10,100,1000],\n",
    "}\n",
    "hr_model = HuberRegressor()\n",
    "\n",
    "gridHR = GridSearchCV(hr_model, param_grid=parameters,scoring = scoring, cv=3, verbose=2, refit = 'mean')\n",
    "gridHR.fit(X_train,y_train)\n",
    "hr_preds = gridHR.predict(X_test)\n",
    "print (mean_squared_error(y_test,hr_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}